%% ------------------------------------------------------------------------- %%
\chapter{Introdução} \label{cap:introducao}

Para atender centenas de milhares de usuários ininterruptamente em sistemas web
de larga escala, dados são replicados em milhares de servidores distribuídos em
múltiplos centros de processamento de dados em diferentes localizações
geográficas. A replicação de dados objetiva a redução da latência, o aumento da
vazão e/ou disponibilidade \cite{Saito2005}. O tempo de resposta de requisições
torna-se menor devido à localidade dos dados, pois a réplica usada para fornecer
a resposta é a mais próxima do usuário que faz a requisição. A vazão aumenta
pois o sistema é capaz de receber uma quantidade maior de requisições
simultâneas para o mesmo dado já que há mais servidores disponíveis para
atendê-las. A disponibilidade aumenta pois caso um servidor ou até um centro de
processamento de dados inteiro fique indisponível, outros ainda podem atender
requisições. A durabilidade também é mais alta, pois os dados não se perdem no
caso em que um nó fique permanentemente indisponível, o que pode acontecer
devido a uma falha em um disco rígido ou até mesmo a destruição de um centro de
processamento de dados inteiro.

O principal problema do uso de replicação em redes de longa distância
(\emph{Wide Area Network} -- WAN) é que manter as réplicas sempre consistentes
entre si tipicamente implica em sacrificar outros requisitos também importantes,
como desempenho ou disponibilidade. Um motivo para divergência entre réplicas é
que a replicação entre centros de processamento de dados pode apresentar
centenas de milissegundos de latência, período durante o qual as réplicas podem
divergir.  Essa latência é resultado não só das distâncias físicas entre os nós,
mas também de limitações na largura de banda disponível, congestionamento de
rede e perda de pacotes. Outro motivo de divergência entre réplicas é a falha
temporária de um nó, que deixa de receber atualizações por um período de tempo.
Um terceiro motivo é a falha em um equipamento ou enlace de rede que impeça a
comunicação entre réplicas.

Com isso, desenvolvedores e administradores de sistemas web de larga escala
buscam um balanço entre disponibilidade, desempenho e consistência dos dados.
Uma decisão comum em vários desses sistemas é o relaxamento da consistência em
troca de alta disponibilidade e baixa latência. Há diversos modelos de
consistência propostos na literatura, cada um com diferentes garantias e
condições em que as réplicas dos dados podem ficar inconsistentes.  Os modelos
mais rígidos, que oferecem mais garantias, são mais simples de serem usados
pelos desenvolvedores. Modelos que oferecem menos garantias de consistência
possibilitam réplicas com dados desatualizados e/ou o aparecimento de
divergências e conflitos entre elas. Com isso, esses conflitos precisam ser
detectados e corrigidos e ações de compensação podem ser necessárias devido a
ações no sistema tomadas a partir de dados inconsistentes. Isso afeta
negativamente a manutenibilidade do sistema, já que sua lógica torna-se mais
complexa. Por outro lado, quanto mais garantias um modelo oferece, mais
comunicação e estruturas de sincronização são necessárias entre as réplicas. Por
isso, quanto mais rígido um modelo de consistência, mais baixo é o seu
desempenho.

A consistência forte (linearibilidade) \cite{Herlihy1990} garante que todas as
réplicas são idênticas a qualquer momento. O problema desse modelo de
consistência é que ele é pouco escalável. Por isso, os desenvolvedores dos
sistemas web de larga escala georeplicados passaram a abrir mão de consistência
forte em seus sistemas, e essa prática resultou em padrões arquiteturais
baseados nesse relaxamento de consistência
\cite{Gilbert2002,Brewer2000,Vogels2009,Helland2009,DeCandia2007}.

A consistência em momento indeterminado (\emph{eventual consistency}\footnote{O
termo \emph{eventual consistency} às vezes é erroneamente traduzido para o
português como consistência eventual. Mas \emph{eventual} é um falso cognato: o
dicionário de inglês Cambridge define essa palavra como ``happening or existing
at a later time or at the end, especially after a lot of effort, problems,
etc.'', cuja tradução para o português é ``acontecendo ou existindo em um
instante mais tarde ou ao fim, especialmente depois de muito esforço, problemas,
etc.''
(\url{http://dictionary.cambridge.org/dictionary/british/eventual?q=eventual}).
O dicionário de português Michaelis usa a definição como ``dependente de evento
incerto, casual, fortuito, variável''
(\url{http://michaelis.uol.com.br/moderno/portugues/index.php?lingua=portugues-portugues&palavra=eventual}).
Portanto, neste trabalho é usada a tradução ``em momento indeterminado''.}) é um
modelo mais relaxado e se tornou especialmente popular após a publicação sobre o
Dynamo \cite{DeCandia2007}, sistema de armazenamento chave-valor usado tanto
pela loja virtual quanto pela estrutura de computação em nuvem da
Amazon\footnote{\url{http://www.amazon.com/} e \url{http://aws.amazon.com/}}
\cite{Vogels2007}. A consistência em momento indeterminado garante que as
réplicas vão sempre convergir em algum momento no futuro desde que novas
atualizações cessem. Enquanto atualizações estiverem acontecendo, existe a
possibilidade de surgirem inconsistências entre as réplicas. Como a consistência
em momento indeterminado permite conflitos entre réplicas, clientes podem
acessar dados desatualizados ou divergentes dependendo da réplica acessada. Os
conflitos que surgem precisam ser resolvidos por algoritmos de detecção e
resolução de conflitos e caso ações tenham sido tomadas com base em valores
inconsistentes, ações de compensação são necessárias. O uso de consistência em
momento indeterminado em um sistema georeplicado resulta em baixa latência e
alta disponibilidade, tendo como contraponto uma maior complexidade no
desenvolvimento da aplicação, que precisa estar preparada para lidar com
inconsistências. Após o Dynamo, diversos sistemas de armazenamento que lidam com
consistência em momento indeterminado foram implementados e colocados em
produção, como Cassandra \cite{Lakshman2010} e Voldemort \cite{Voldemort},
implementados respectivamente pelo
Facebook\footnote{\url{http://www.facebook.com/}} e
LinkedIn\footnote{\url{http://www.linkedin.com/}}. Outras empresas web de larga
escala utilizando Cassandra são Twitter\footnote{\url{http://twitter.com/}}
\cite{King2010}, Reddit\footnote{\url{http://www.reddit.com/}} \cite{King2010a}
e Rackspace\footnote{\url{http://www.rackspace.com/}} \cite{Hood2010}.

Para algumas aplicações web, é importante que os usuários sempre encontrem a
aplicação disponível, mesmo que isso cause algum tipo de inconveniente. Os
sistema de armazenamento usado pela loja virtual Amazon apresenta
disponibilidade de 99,995\% \cite{DeCandia2007}. A Amazon almeja esse nível de
disponibilidade pois considera fundamental que seus usuários consigam adicionar
itens em seus carrinhos de compras, mesmo que isso implique em problemas que
precisem ser corrigidos depois, como itens previamente removidos do carrinho
ressurgirem -- algo que pode acontecer ao usar o Dynamo como sistema de
armazenamento \cite{DeCandia2007}.

Entretanto, nem todas as aplicações web de larga escala podem usar consistência
em momento indeterminado. Existem aplicações que necessitam de modelos de
consistência mais rígidos, embora não necessariamente consistência forte, para
funcionar corretamente. Por exemplo, uma aplicação de leilão não pode permitir
conflitos no histórico de lances de um produto. Num sistema que usa consistência
em momento indeterminado, no caso de uma falha que divida a rede em duas
partições, usuários em cada partição têm uma visão própria do histórico de
lances. Isso seria equivalente a dois leilões simultâneos sobre o mesmo item,
conflito que não tem como ser resolvido depois sem desprezar lances. Outro
exemplo é um usuário de uma aplicação web de planilha, que não pode ver um valor
que acabou de ser inserido desaparecer espontaneamente, mesmo que
temporariamente -- algo que pode acontecer em um sistema usando consistência em
momento indeterminado.

Além disso, existem aplicações que não precisam apresentar índices de
disponibilidade tão altos. Em uma aplicação de rede social, por exemplo, uma
indisponibilidade curta pode ser tolerada pelos usuários. Um exemplo dessa
tolerância é percebida nos usuários do Twitter -- segundo o serviço de
monitoramento Pingdom, a disponibilidade do serviço em outubro de 2011 foi de
98,83\% \cite{Pingdom2010}.

Um modelo de consistência para sistemas georeplicados que busca um meio termo
entre consistência forte e consistência em momento indeterminado é a
consistência na linha do tempo, usada no PNUTS do Yahoo! \cite{Cooper2008}. Para
cada objeto armazenado, esse modelo de consistência permite atualizações em
apenas uma de suas réplicas, evitando assim a possibilidade de conflitos ao
mesmo tempo em que evita o uso de bloqueios (\emph{locks}) e propagação de
atualizações síncrona. Com a propagação assíncrona, réplicas podem ter valores
desatualizados devido à latência de rede ou falhas, mas a qualquer instante
sabe-se qual é a réplica com o valor mais recente. Os clientes escolhem em cada
acesso se aceitam como resposta apenas o valor mais recente ou se aceitam
valores desatualizados. A principal desvantagem da consistência na linha do
tempo é que a existência de uma réplica mestre implica que escritas e leituras
consistentes (leituras do valor mais recente) ficam indisponíveis em caso de uma
falha que impeça um cliente de acessar essa réplica.

Portanto, um modelo de consistência oferece um balanço entre desempenho,
disponibilidade e consistência. Considerando que usuários de algumas aplicações
web toleram indisponibilidades, a consistência na linha do tempo pode ser uma
opção interessante por oferecer um modelo de programação mais simples, desde que
seu desempenho seja aceitável. O maior fator de impacto no desempenho da
consistência na linha do tempo é o fato de que todas as escritas e leituras
consistentes que não são feitas no centro de processamento de dados em que está
a réplica mestre incorrem no custo de latência da WAN.  Entretanto, em
aplicações como redes sociais, por exemplo, é de se esperar que haja uma grande
quantidade de acessos locais (a maioria dos usuários acessa o sistema de um
único país e tem a maioria de seus contatos no mesmo país) e que a relação
escrita/leitura seja baixa (cada item criado, como uma postagem ou um
comentário, seja lido diversas vezes). De fato, os autores do PNUTS indicam que
em sua rede social 60\% dos acessos é local e a relação escrita/leitura
observada é de 0,06 \cite{Kadambi2011}. Eles indicam também que outras
aplicações chegam a ter 85\% dos acessos locais \cite{Cooper2008}. Dado isso,
eles usam a estratégia de sempre mover dinamicamente a réplica mestre para o
centro de processamento de dados que processa a maior quantidade de requisições
para dado objeto.  Com isso, em uma aplicação na qual a quantidade de leituras é
muito maior do que a quantidade de escritas, o custo de latência pode ser baixo,
em especial se as leituras não precisarem necessariamente do valor mais recente.

Consistência em momento indeterminado é bastante difundida em sistemas web de
larga escala. Ela é item de destaque em padrões arquiteturais usados por esse
tipo de sistema \cite{Vogels2009,Helland2009}, e é possível encontrá-la em
vários sistemas de armazenamento apresentados na literatura e em projetos de
software livre \cite{DeCandia2007,Lakshman2010,Voldemort,Riak,Carstoiu2010}.
Enquanto isso, a consistência na linha do tempo é pouco usada e reconhecida
\cite{Abadi2010} -- em julho de 2012, foram encontrados apenas dois sistemas na
literatura e nenhum projeto de software livre usando esse tipo de consistência
\cite{Cooper2008,Rao2011}. Mas a consistência na linha do tempo pode ser uma
opção interessante por oferecer um modelo de programação mais simples, desde que
seu desempenho seja próximo ao da consistência em momento indeterminado e a
aplicação tolere níveis mais baixos de disponibilidade.

Há diversos estudos experimentais sobre desempenho de modelos de consistência
\cite{DeCandia2007,Cooper2008,Lloyd2011,Beyer2011}, mas não foi encontrada uma
comparação quantitativa entre esses dois modelos mostrando como cada um se
comporta em diferentes condições de latência de rede e carga de trabalho. Dados
sobre essa comparação são úteis para desenvolvedores e administradores de
sistemas estimarem melhor os custos de desenvolvimento e fazerem um planejamento
de capacidade mais eficaz.

%% ------------------------------------------------------------------------- %%
\section{Organização do Trabalho} \label{sec:organizacao_trabalho}

Este trabalho está dividido em cinco capítulos. O
Capítulo~\ref{cap:consistencia_em_sistemas_georeplicados} apresenta os
fundamentos para o entendimento da motivação, dos problemas e das soluções
oferecidas pela replicação de dados em sistemas georeplicados. Os três capítulos
seguintes seguem a ordem em que as atividades do estudo experimental foram
realizadas. O Capítulo~\ref{cap:planejamento_e_aspectos_tecnicos} contempla o
planejamento dos experimentos e os aspectos técnicos de sua implementação. A
seguir, o Capítulo~\ref{cap:parametros_e_fatores} descreve o processo usado para
definir quais características do sistema, do ambiente e da carga de trabalho
foram consideradas e quais foram desconsideradas no estudo.  O
Capítulo~\ref{cap:analise_dos_resultados} aborda a análise dos resultados
obtidos nos experimentos. Por fim, o Capítulo~\ref{cap:conclusoes} traz as
conclusões deste trabalho.
