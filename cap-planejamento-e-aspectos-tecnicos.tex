%% ------------------------------------------------------------------------- %%
\chapter{Planejamento e Aspectos Técnicos}
\label{cap:planejamento_e_aspectos_tecnicos}

Este trabalho usa como principal referência metodológica o livro \emph{The Art
of Computer Systems Performance Analysis} (A Arte da Análise de Desempenho de
Sistemas de Computação) \cite{Jain1991}, de Raj Jain. Esse livro trata da
análise de desempenho de sistemas de software e/ou hardware, e apresenta
conceitos de estudos experimentais e o ferramental estatístico necessário nesse
tipo de estudo. Além disso, ele propõe uma abordagem sistemática para fazer um
estudo experimental. A segunda referência usada sobre análise de desempenho foi
\cite{Lilja2005}.

As definições das metas, métricas e técnica de avaliação do estudo se encontram
na Seção~\ref{sec:definicao_do_estudo}. As descrições do sistema de
armazenamento e do \emph{benchmark} usados, bem como do ambiente em que operaram
nos experimentos, se encontram na Seção~\ref{sec:aspectos_tecnicos}.

%% ------------------------------------------------------------------------- %%
\section{Definição do Estudo} \label{sec:definicao_do_estudo}

A definição do estudo seguiu os passos da abordagem de Jain em \cite{Jain1991},
com exceção do levantamento de parâmetros e a seleção de fatores, que ocorreram
após a definição da técnica de avaliação. Isso foi feito pois essa foi a fase de
maior complexidade do estudo e está descrita no
Capítulo~\ref{cap:parametros_e_fatores}.

%% ------------------------------------------------------------------------- %%
\subsection{Nomenclatura} \label{sec:nomenclatura}

A literatura sobre experimentos apresenta alguns termos importantes para a
comunicação de objetivos, procedimentos e resultados \cite{Jain1991}. Termos
usados frequentemente neste e nos próximos capítulos são:

\paragraph{Estudo:} Um conjunto de experimentos relacionados. O plural
``experimentos'' também é usado no lugar de ``estudo'' ao longo deste trabalho.

\paragraph{Variáveis de resposta:} Resultados de um experimento (variáveis
dependentes). No caso deste estudo, as variáveis de resposta são as métricas de
desempenho.

\paragraph{Parâmetros:} Características do sistema (hardware e software) e da
carga de trabalho (requisições para o sistema) que afetam o desempenho do
sistema.  Exemplos de parâmetros são CPU, latência da rede e relação
leitura/escrita.

\paragraph{Fatores:} Parâmetros que são variados nos experimentos (variáveis
independentes) e cujo efeito no desempenho é analisado. Parâmetros que não são
fatores possuem um único valor em todos os experimentos (variáveis fixas e
constantes).

\paragraph{Níveis:} Valores assumidos pelos fatores nos experimentos.

\paragraph{Interação entre fatores:} Dois ou mais fatores interagem se a
influência que um deles tem no desempenho depende do nível dos outros. Por
exemplo, um software é testado nas combinações das CPUs A e B e 4 GB e 8 GB de
memória. Se ao mudar a CPU de A para B o desempenho sempre aumenta em 10\%, por
exemplo, independente do tamanho da memória, é dito que CPU e memória não
interagem. Mas se ao mudar a CPU de A para B o desempenho aumenta em 10\% quando
o sistema tem 4 GB, mas 30\% quando tem 8 GB, é dito que CPU e memória
interagem.

\paragraph{Ordem de uma interação entre fatores:} A quantidade de fatores
envolvidos na interação -- por exemplo, uma interação de terceira ordem é uma
interação entre três fatores.

\paragraph{Projeto dos experimentos:} Especificação do número de experimentos e
das combinações de fatores e níveis usados.

%% ------------------------------------------------------------------------- %%
\subsection{Metas do estudo} \label{sec:metas_do_estudo}

A meta deste estudo foi comparar o desempenho de um sistema de armazenamento
georeplicado usando consistência em momento indeterminado e consistência na
linha do tempo. A hipótese era que um sistema usando consistência na linha do
tempo apresenta desempenho igual ou superior a um usando consistência em momento
indeterminado para cargas de trabalho específicas, apesar de ser um modelo
baseado em cópia primária.

Por limitações de escopo e recurso, este estudo analisa o sistema apenas do
ponto de vista do desempenho. Isso significa que o estudo não considera outros
requisitos como disponibilidade e manutenibilidade. Por isso, o comportamento do
sistema não foi estudado com relação a presença de falhas em nós, por exemplo.
Além disso, também foi considerada a operação do sistema em estado estacionário,
sua operação em sobrecarga não foi estudada. Essas outras condições de operação
podem ser estudadas em trabalho futuros (Seção \ref{sec:trabalhos_futuros}).

%% ------------------------------------------------------------------------- %%
\subsection{Métricas} \label{sec:metricas}

A principal métrica é o tempo de resposta das requisições (em s). Quanto menor o
tempo de resposta, melhor é o desempenho de um modelo de consistência. Além do
tempo de resposta, outras métricas observadas foram quantidade de migrações e
quantidade de conflitos (ambas dadas pela porcentagem com relação ao total de
operações do experimento). A quantidade de migrações, exclusiva da consistência
na linha do tempo, oferece uma visão da dinâmica de um sistema usando esse
modelo de consistência. A quantidade de conflitos proporciona uma noção da
frequência com que cliente acessam valores desatualizados.  Uma diferença entre
conflitos nos dois modelos é que na consistência na linha do tempo eles são
causados apenas por atualizações que ainda não chegaram a todas as réplicas,
portanto serão automaticamente resolvidos em algum momento no futuro. Já na
consistência em momento indeterminado eles podem ser mais graves, dado que esse
modelo permite que duas atualizações simultâneas ocorram em réplicas diferentes,
criando assim uma situação em que um mecanismo de resolução de conflitos precisa
atuar.

%% ------------------------------------------------------------------------- %%
\subsection{Técnica de avaliação} \label{sec:tecnica_de_avaliacao}

A escolha da técnica de avaliação depende em parte dos parâmetros e fatores
\cite{Jain1991}. Apesar de o levantamento de parâmetros e a seleção de fatores
terem sido completados depois desse passo, a escolha da técnica de avaliação foi
feita com base em uma lista preliminar. Essa lista era composta por parâmetros
diretamente ligados à meta deste trabalho, como os relacionados a carga de
trabalho e rede.

Três técnicas são comumente usadas na análise de desempenho de sistemas:
simulação, modelagem analítica e medição \cite{Jain1991}. Dada a complexidade
dos sistemas considerados neste estudo e do ambiente em que operam, é difícil
criar simuladores ou modelos que considerem muitos dos parâmetros que afetam seu
desempenho. Para serem viáveis nesse contexto, essas técnicas fazem uso de
diversas simplificações que afetam a precisão dos resultados do estudo. Por
outro lado, as principais dificuldades para o uso de medição são a necessidade
de um sistema pronto para ser usado, o tempo disponível para o estudo e as
ferramentas disponíveis. No caso deste estudo, nenhum dos três representava
empecilho, portanto medição foi escolhida.

%% ------------------------------------------------------------------------- %%
\subsection{Experimentos Fatoriais} \label{sec:experimentos_fatoriais}

São alguns os tipos de experimentos usados em um estudo experimental. A escolha
entre eles se dá principalmente pelo balanço entre recursos utilizados na sua
execução (tempo, dinheiro, energia, etc.) e quantidade de informação adquirida.

Experimentos fatoriais consistem da combinação de dois ou mais fatores em cada
experimento que compõe o estudo. Um projeto que considere todos os fatores em
todos os níveis é chamado completo, caso contrário é chamado fracionado
\cite{Jain1991}.

Um projeto de experimentos fatoriais completo é constituído por experimentos com
todas as combinações possíveis de fatores e seus níveis. Assim, a quantidade
total de experimentos é dada por:

$n = \prod_{i=1}^k{n_i}$,

onde k é o número de fatores e $n_i$ é a quantidade de níveis do
i$^{\textrm{\'esimo}}$ fator.

Esse tipo de projeto de experimentos tem a vantagem de identificar com precisão
a influência de todos os fatores e suas interações nas variáveis de resposta.
Mas quanto maior a quantidade de fatores e de níveis em um estudo experimental,
maior a quantidade de recursos necessários para sua execução. Normalmente os
fatores não afetam igualmente as variáveis de resposta, pelo contrário, é comum
alguns poucos fatores explicarem a maior parte dos efeitos na resposta
\cite{Jain1991}. Para esses casos, um projeto de experimentos fatoriais
2\textsuperscript{k}, que é um tipo de projeto de experimentos completo, é
utilizado para fazer uma triagem dos fatores, identificando quais deles são os
mais influentes.

Em um projeto de experimentos fatoriais 2\textsuperscript{k}, todos os fatores
inicialmente selecionados são usados, mas apenas com dois níveis cada
(normalmente o mínimo e o máximo), resultando em um total de
2\textsuperscript{k} experimentos. O desempenho em função dos fatores é expresso
por um modelo de regressão não-linear da forma:

$y = q_0 + q_Ax_A + q_Bx_B + q_Cx_C + ... + q_{AB}x_Ax_B + q_{AC}x_Ax_C +
q_{BC}x_Bx_C... + q_{ABC}x_Ax_Bx_C + ...$,

onde $y$ é o desempenho medido, $q_0$, $q_A$, $q_B$, etc. são os coeficientes do
modelo e $x_A$, $x_B$, $x_C$, etc. representam respectivamente os níveis dos
fatores A, B, C, etc. Os termos compostos pela multiplicação de dois ou mais
fatores representam as interações entre eles.

Usando as respostas dos 2\textsuperscript{k} experimentos, é possível calcular o
valor dos coeficientes por meio de um sistema de 2\textsuperscript{k} equações
em que os 2\textsuperscript{k} coeficientes são as variáveis. Para tal,
define-se uma relação entre os níveis dos fatores e os valores -1 ou 1.  Por
exemplo, pode-se definir que a latência de 100 ms valerá -1 e a latência de 300
ms valerá 1.

Com os coeficientes, é possível fazer a alocação de variação dos fatores, que é
o cálculo da importância de cada um deles na resposta. A importância de cada um
é dada pela proporção da variação total pela qual ele é responsável. A variação
total da resposta (ou soma total dos quadrados) é dada por:

$STQ = \sum_{i = 1}^{n} (y_i - \bar{y})^2$,

onde $n$ é a quantidade de respostas, $y_i$ é resposta medida e $\bar{y}$ é a
média das respostas.

Para um projeto de experimentos 2\textsuperscript{k}, a soma total dos quadrados
é dada por (para a derivação dessa equação a partir da anterior, ver
\cite{Jain1991}):

$STQ = SQA + SQB + SQC + ... + SQAB + SQAC + SQBC + ... + SQABC + ...$,

onde cada $SQX$ é dado por:

$SQX = 2^kq_X$

Cada $SQX$ é a porção da variação total explicada pelo fator ou pela interação
entre fatores X. A partir disso, é possível finalmente calcular a fração da
variação explicada por cada X por:

$FSQX = SQX / STQ$

Ordenando os $FSQX$s é possível descobrir quais são os fatores e interações
entre eles que mais afetam os resultados dos experimentos.

%% ------------------------------------------------------------------------- %%
\section{Aspectos Técnicos} \label{sec:aspectos_tecnicos}

Uma vez que medição foi escolhida como técnica de avaliação de desempenho para o
estudo, o passo seguinte foi a preparação técnica dos experimentos. Essa
preparação envolveu predominantemente atividades de programação e administração
de sistemas, como implementação da consistência na linha do tempo e preparação
de scripts para a execução dos experimentos.

%% ------------------------------------------------------------------------- %%
\subsection{Sistema de armazenamento} \label{sec:sistema_de_armazenamento}

Uma opção para a comparação dos dois modelos de consistência seria o uso de um
sistema de armazenamento já existente que implementasse ambos, mas tal sistema
não foi encontrado. A partir disso, outra opção seria o uso de sistemas
diferentes, cada um implementando um modelo de consistência. Apesar de existirem
experimentos que fizeram essa opção \cite{Cooper2008,Stonebraker2007,Pavlo2009},
dois problemas foram identificados.  O primeiro é que o desempenho de cada
sistema é afetado por parâmetros particulares do sistema que não o modelo de
consistência, como a tecnologia utilizada, detalhes de configuração, entre
outros. No caso de uso de mais de um sistema, esses fatores, pouco importantes
para este estudo, precisariam ser levados em conta. O segundo problema é que
apesar de existirem sistemas de armazenamento de software livre que implementam
consistência em momento indeterminado, não foram encontrados sistemas que
implementassem consistência na linha do tempo.

Assim, decidiu-se usar um único sistema para os experimentos. Uma opção para tal
era implementar um sistema de armazenamento distribuído específico para os
experimentos. O problema é que esse tipo de sistema é bastante complexo, já que
precisa prover funcionalidades como controle de entrada e saída dos nós no
aglomerado, algoritmos de particionamento, etc.

Para evitar a implementação completa de um sistema de armazenamento e tornar
este trabalho mais realista, algumas opções de software livre foram analisadas.
A seleção das opções foi feita considerando modelos de consistência,
estabilidade da solução e simplicidade de desenvolvimento. Como não foram
encontrados sistemas de armazenamento de software livre que implementavam
consistência na linha do tempo, as soluções avaliadas foram aquelas que
implementavam consistência em momento indeterminado. Os sistemas encontrados
foram Dynomite \cite{Dynomite}, Cassandra \cite{Lakshman2010}, Voldemort
\cite{Voldemort} e Riak \cite{Riak}. Todos eles usam basicamente a mesma
arquitetura do Dynamo, provendo gerenciamento de entrada e saída de nós no
aglomerado, relógios vetorais para identificação e resolução de conflitos entre
diferentes réplicas dos objetos \cite{Lamport1978} e espalhamento consistente
para o particionamento dos objetos \cite{Karger1997a}.

O Dynomite foi descartado pois o projeto foi abandonado pela comunidade em um
estado ainda instável. O Cassandra por outro lado possui estabilidade e uma
comunidade bastante ativa, mas é mais complexo que os outros sistemas dado que
também implementa características de SGBDs orientados a colunas
\cite{Chang2006}. Dos dois sistemas restantes, o Riak foi escolhido por ser
implementado em Erlang, linguagem voltada para o desenvolvimento de sistemas
distribuídos, apresentando assim maior facilidade para o desenvolvimento do
modelo de consistência na linha do tempo. Um indício dessa facilidade é que o
riak\_kv, o módulo do Riak usado na implementação do novo modelo de
consistência, apresenta aproximadamente 20 mil linhas de código contra
aproximadamente 85 mil do Voldemort.

%% ------------------------------------------------------------------------- %%
\subsubsection{Implementação da consistência na linha do tempo no Riak}

Consistência na linha do tempo foi implementada no Riak pelo autor deste
trabalho, no módulo riak\_kv. Para os experimentos, a distinção entre leituras e
escritas era importante. Mas a distinção entre os tipos de escrita (inserção,
atualização ou remoção) não era tão importante dado que eles se comportam
basicamente da mesma forma do ponto de vista de tráfego de rede local versus
remoto. Assim, apenas atualizações foram implementadas de forma completa e
eficiente, distinguindo a localização de cada nó com relação aos centros de
processamento de dados. As inserções para uma dada chave ocorrem sempre pela
mesma réplica, mesmo que isso signifique encaminhar para outro centro de
processamento de dados uma requisição que, em princípio, poderia ser tratada
localmente. Esse procedimento eliminou a necessidade de implementação de um
mecanismo para evitar conflitos de inserção.  Apesar de inserções serem
ineficientes, isso não afetou os resultados, dado que os experimentos usam
inserção apenas na carga e aquecimento do sistema (ver o fluxo de trabalho na
Subseção~\ref{sec:execucao_e_analise_dos_experimentos}).  Remoções não foram
implementadas.

O PNUTS conta com uma heurística que explora a localidade de requisições,
simples mas importante para o desempenho da consistência na linha do tempo: a
réplica mestre migra para o centro de processamento de dados de onde vieram as
últimas escritas. Essa heurística foi implementada no Riak para este estudo.

A implementação da consistência na linha do tempo foi baseada na da consistência
em momento indeterminado já disponível no Riak. Durante a implementação houve a
preocupação em manter o código das duas o mais próximo possível de forma a
eliminar diferenças dos tempos de execução dos dois modelos.

Por último, outras alterações menores no riak\_kv foram o tratamento de
parâmetros extras na interface HTTP, necessários para a consistência na linha do
tempo, e a implementação de estatísticas de migrações.

A versão do riak\_kv usada como base foi a 1.1. Durante a fase inicial de
desenvolvimento as modificações feitas não estavam em um sistema de controle de
versão. A partir do momento em que o git passou a ser usado, foram 2011 linhas
inseridas e 222 removidas nos seguintes 11 arquivos:

% git log --author="mdediana" --pretty=tformat: --numstat | awk '{ add += $1;
% del += $2 } END { print add, del }

%git shortlog --author="mdediana" --numbered --summary

\begin{itemize}

\item \emph{riak\_client.erl}

\item \emph{riak\_kv\_get\_fsm.erl}

\item \emph{riak\_kv\_get\_fsm\_sup.erl}

\item \emph{riak\_kv\_put\_fsm\_sup.erl}

\item \emph{riak\_kv\_put\_fsm.erl}

\item \emph{riak\_kv\_stat.erl}

\item \emph{riak\_kv\_timeline\_get\_core.erl}

\item \emph{riak\_kv\_timeline\_get\_fsm.erl}

\item \emph{riak\_kv\_timeline\_put\_fsm.erl}

\item \emph{riak\_kv\_wm\_raw.hrl}

\item \emph{riak\_kv\_wm\_worker.erl}

\end{itemize}

Desses arquivos, os únicos que não estavam originalmente no riak\_kv são os três
com a implementação da consistência na linha do tempo:
\emph{riak\_kv\_timeline\_get\_core.erl} (237 linhas),\\
\emph{riak\_kv\_timeline\_get\_fsm.erl} (528 linhas) e
\emph{riak\_kv\_timeline\_put\_fsm.erl} (900 linhas). A maior parte dessas
linhas foi retirada da implementação original da consistência em momento
indeterminado. As modificações feitas no riak\_kv se encontram em
\url{https://github.com/mdediana/riak\_kv.git}.

%% ------------------------------------------------------------------------- %%
\subsubsection{Implementação de algoritmo de particionamento para centros de
processamento de dados}

Além do riak\_kv, outro módulo alterado foi o riak\_core, responsável pelo
roteamento de re-quisições em um aglomerado de Riak. Quando o Riak recebe uma
requisição, ele define qual o nó responsável por tratá-la por meio do algoritmo
de espalhamento consistente, que se baseia no valor da chave do objeto. O Riak
foi projetado para ser implantado em um único centro de processamento de
dados\footnote{A versão Enterprise do Riak implementa replicação entre centros
de processamento de dados, mas é paga.}, portanto o algoritmo não leva em
consideração os centros de processamento de dados no momento de decidir para
qual das réplicas a requisição deve seguir. Dessa forma, algumas modificações
foram necessárias no riak\_core para que ele priorizasse nós do mesmo centro de
processamento de dados em que a requisição chegou. Além disso, modificações
foram feitas para garantir que existisse ao menos uma réplica de cada objeto em
cada centro de processamento de dados. A implementação é muito simples e pouco
versátil, funcionando apenas para o cenário do estudo, de apenas dois centros de
processamento de dados (ver seção \ref{sec:parametros_fixados}) e baseada nos
nomes dos nós para saber em qual centro de processamento de dados cada um deles
se encontra.

A partir do momento em que o git passou a ser usado para controle de versão,
foram 106 linhas inseridas e 17 removidas nos seguintes 3 arquivos:

\begin{itemize}

\item \emph{riak\_core.app} (diretório \emph{ebin})

\item \emph{riak\_core\_apl.erl}

\item \emph{riak\_core\_claim\_2\_dcs.erl}

\end{itemize}

As modificações feitas no riak\_core se encontram em
\url{https://github.com/mdediana/riak\_core.git}.

%% ------------------------------------------------------------------------- %%
\subsubsection{Testes da implementação}

Os testes foram executados manualmente. Os principais cenários testados (CPD se
refere a centro de processamento de dados):

\begin{itemize}

\item Requisição de inserção a partir do CPD1 ocorrendo no CPD1

\item Requisição de inserção a partir do CPD1 sendo redirecionada para o CPD2

\item Verificação de que inserções resultavam em ao menos uma réplica em cada
centro de processamento de dados

\item Requisição de leitura/atualização a partir do CPD1 sempre ocorrendo no
CPD1 para consistência em momento indeterminado (local)

\item Requisição de leitura de ``qualquer versão'' a partir do CPD1 sempre
ocorrendo no CPD1 para consistência na linha do tempo (local)

\item Requisição de leitura da ``versão mais recente''/atualização a partir do
CPD1 sendo redirecionada para a réplica mestre no CPD1 para consistência na
linha do tempo (local)

\item Requisição de leitura da ``versão mais recente''/atualização a partir do
CPD1 sendo redirecionada para a réplica mestre no CPD2 para consistência na
linha do tempo (remota)

\item \emph{LM} requisições de atualização a partir do CPD1 de um objeto no CPD2
resultando em migração da réplica mestre para o CPD2, onde \emph{LM} é o limiar
de migração

\item Requisição de atualização sendo redirecionada para uma réplica mestre ao
mesmo tempo em que a réplica mestre migra (a requisição é redirecionada para a
nova réplica mestre)

\end{itemize}

%% ------------------------------------------------------------------------- %%
\subsection{\emph{Benchmark}} \label{sec:benchmark}

O \emph{benchmark} usado foi o Basho Bench \cite{Basho}, específico para o Riak.
Ele provê configurações para quantidade de clientes concorrentes (threads),
relação leitura/escrita, popularidade dos objetos acessados, entre outras. O
\emph{benchmark} originalmente não era distribuído, portanto foi modificado pois
mais de uma instância precisava ser executada simultaneamente nos experimentos.
Além de evitar gargalos no \emph{benchmark}, isso era importante para a
implementação de localidade. Além disso, foi necessária a implementação de um
pequeno programa em Erlang (basho\_bench\_dist) para a consolidação dos dados
obtidos pelas diversas instâncias do Basho Bench. Parte dessa consolidação
envolveu a fusão de histogramas usados pelo Basho Bench, que por sua vez usavam
o projeto basho\_stats, que também precisou ser modificado.

Outro \emph{benchmark} considerado foi o
YCSB\footnote{\url{git://github.com/brianfrankcooper/YCSB.git}}
\cite{Cooper2010}.  Apesar de possuir mais flexibilidade que o Basho Bench nas
suas configurações, ele não estava preparado para acessar o Riak, acesso esse
que precisaria ser implementado. Além disso, ele também não oferecia muitas das
funcionalidades necessárias para os experimentos, que precisariam ser
implementadas.

% desconsidera 23 linhas de examples/locality.config
A partir do momento em que o git passou a ser usado para controle de versão,
foram 90 linhas inseridas e 17 removidas nos seguintes 3 arquivos do Basho
Bench:

\begin{itemize}

\item \emph{basho\_bench.app.src}

\item \emph{basho\_bench\_driver\_http\_raw.erl}

\item \emph{basho\_bench\_keygen.erl}

\item \emph{basho\_bench\_stats.erl}

\item \emph{basho\_bench\_worker.erl}

\end{itemize}

No basho\_stats, foram 77 linhas inseridas e 35 removidas nos seguintes 2
arquivos:

\begin{itemize}

\item \emph{basho\_stats\_histogram.erl}

\item \emph{basho\_stats\_sample.erl}

\end{itemize}

Por último, o basho\_bench\_dist é composto por um único arquivo
(\emph{basho\_bench\_dist.erl}) de 149 linhas, muitas das quais foram copiadas
do Basho Bench.

As alteração feitas no Basho Bench estão em
\url{https://github.com/mdediana/basho\_bench.git}, o basho\_bench\_dist se
encontra em \url{https://github.com/mdediana/basho\_bench\_dist.git} e as
modificações do basho\_stats em
\url{https://github.com/mdediana/basho\_stats.git}.

%% ------------------------------------------------------------------------- %%
\subsection{Ambiente} \label{sec:ambiente}

Os experimentos foram executados no
Grid5000\footnote{\url{http://www.grid5000.fr/}}, uma plataforma para criação,
execução e monitoramento de experimentos de sistemas paralelos e distribuídos.
Em janeiro de 2013, a plataforma possuía mais de 5000 núcleos de processamento
distribuídos em 10 sítios na França e um no Brasil.

Outras plataformas como o OpenCirrus\footnote{\url{http://opencirrus.org/}} e
PlanetLab\footnote{\url{http://www.planet-lab.org/}} também foram consideradas,
mas foram descartadas por uma questão de conveniência, já que o autor deste
trabalho utilizou o Grid5000 em dois estágios de mestrado de respectivamente
quatro meses e um mês pelo INRIA na França. A experiência no ambiente adquirida
nesse período foi reutilizada neste trabalho, tornando o projeto e a execução
dos experimentos mais produtivos. O Amazon Web Services (AWS)
\footnote{\url{http://aws.amazon.com/}} também foi considerado, mas foi
descartado por se tratar de ambiente virtualizado, o que dificultaria a análise
dos resultados e a reprodutibilidade dos experimentos.

A operação no Grid5000 se dá através do acesso ssh ao frontend de cada sítio.
Nele o usuário encontra seu diretório home, onde ele armazena seus scripts e
dados dos experimentos, e tem acesso a ferramentas específicas da
infraestrutura. Como o Grid5000 é compartilhado por diversos pesquisadores, ele
oferece um conjunto de ferramentas (OAR\footnote{\url{http://oar.imag.fr/}}) e
regras para que um pesquisador reserve nós para seu uso exclusivo por um
determinado período de tempo. Além dos nós, é possível reservar IPs para compor
sub-redes, recurso utilizado nos experimentos (ver Subseção~\ref{sec:rede}).
Outra ferramenta bastante utilizada é o
kadeploy\footnote{\url{http://kadeploy.imag.fr/}}, responsável pela implantação
de imagens nos nós reservados pelo usuário.

%% ------------------------------------------------------------------------- %%
\subsubsection{Imagem}

A imagem usada nos experimentos foi um Debian GNU/Linux 6.0 (Squeeze) com kernel
2.6.32-5-amd64 baseado em uma imagem pré-configurada disponibilizada pelo
Grid5000 (squeeze-x64-base). Além do conteúdo da imagem base, a imagem usada nos
experimentos possui o Erlang R14B04 instalado a partir do fonte, o Riak e o
Basho Bench modificados e algumas ferramentas de monitoração e análise de
desempenho como
sysstat\footnote{\url{http://sebastien.godard.pagesperso-orange.fr/}},
bwm-ng\footnote{\url{http://www.gropp.org/?id=projects&sub=bwm-ng}} e
iperf\footnote{\url{http://iperf.sourceforge.net/}}. Uma única imagem foi usada,
sendo que a distinção entre nós executando instâncias do Riak ou do Basho Bench
foi feita pelos scripts que gerenciam os experimentos (subseção
\ref{sec:execucao_e_analise_dos_experimentos}).

Pesquisadores com acesso ao Grid5000 podem acessar essa imagem, que se encontra
no sítio Sophia em \emph{/home/madediana/images/squeeze-x64-riak.tgz}.

%% ------------------------------------------------------------------------- %%
\subsection{Rede} \label{sec:rede}

Os sítios do Grid5000 são conectados por redes de alta velocidade. Suas redes
apresentam latências da ordem de centenas de microssegundos entre nós de um
mesmo aglomerado e da ordem de 20 ms entre sítios, e portanto não caracterizam
uma WAN. De qualquer forma, mesmo que caracterizassem, ter controle sobre esses
valores era necessário para medir o desempenho do sistema em diferentes
condições de rede e possibilitar a reprodutibilidade dos experimentos.

Por isso, os experimentos emularam uma WAN pelo uso da ferramenta traffic
control\footnote{\url{http://linux.die.net/man/8/tc}} (tc). Essa ferramenta é
usada para manipulação das filas de saída de pacotes de uma interface de rede em
sistemas Linux, priorizando um determinado tipo de tráfego, por exemplo. Mais
especificamente para emulação da WAN, o
netem\footnote{\url{http://www.linuxfoundation.org/collaborate/workgroups/networking/}}
foi usado. Ele provê funcionalidade para inserção de latência de rede, variação
da latência, perda de pacotes, pacotes duplicados, corrompidos e/ou fora de
ordem. Outras ferramentas, como o
dummynet\footnote{\url{http://info.iet.unipi.it/~luigi/dummynet/}}
\cite{Carbone2010} e o
NISTNet\footnote{\url{http://snad.ncsl.nist.gov/itg/nistnet/}}, foram
desconsideradas dado que o netem já vem integrado ao tc e satisfazia os
requisitos funcionais dos experimentos.

Existem recomendações sobre otimizações de sistemas Linux para quando esses se
comunicam por meio de WANs \cite{Jones2006,ESNet2012}. Durante os experimentos,
sempre que os parâmetros da WAN foram alterados, um script para ajuste da pilha
TCP foi usado (para mais detalhes, ver Seção~\ref{sec:fatores_de_rede}).

%% ------------------------------------------------------------------------- %%
\subsubsection{Centros de processamento de dados}

Os experimentos foram planejados para usar dois centros de processamento de
dados simulados (ver Seção~\ref{sec:parametros_fixados}). Para simular os
centros de processamento de dados, em cada experimento os nós que compunham o
sistema eram divididos em dois conjuntos CPD1 e CPD2, cada um representando um
centro de processamento de dados. Além dos nós, duas sub-redes SR1 e SR2 eram
reservadas. Cada nó de CPD1 recebia, além de seu IP da rede do Grid5000, um IP
de SR1, o mesmo valendo para CPD2 e SR2.

Sistemas Linux usam o arquivo \emph{/etc/hosts} como fonte primária para
resolução de nomes, consultando um DNS apenas quando não encontram um nome
definido ali (o que é a situação mais comum). Todos os nós no Grid5000 possuem
um nome registrado no DNS que aponta para o seu IP da rede do Grid5000. Nos
experimentos, dois arquivos \emph{hosts1} e \emph{hosts2} eram criados e
substituíam o \emph{/etc/hosts} dos nós de CPD1 e CPD2 respectivamente. O
conteúdo de \emph{hosts1} eram os nomes dos nós de CPD2 sendo resolvidos para os
IPs de SR2, o mesmo valendo para \emph{hosts2}, CPD1 e SR1. Com isso, os nós de
CPD1 resolviam os nomes dos nós de CPD2 para os IPs de SR2 e vice-versa. O
resultado dessa configuração é que todas as requisições que saíam de um centro
de processamento de dados para o outro usavam o IP da sub-rede de destino,
enquanto as requisições para o mesmo centro de processamento de dados usavam o
IP da rede do Grid5000.

A partir dessa configuração foi possível adicionar um filtro baseado em
sub-redes ao tc de modo que as características de WAN eram aplicadas às
requisições que saíam para o outro centro de processamento de dados, enquanto as
requisições para o mesmo centro de processamento de dados saíam inalteradas.
Esse processo é executado pelo script net (ver Subseção
\ref{sec:execucao_e_analise_dos_experimentos}).

%% ------------------------------------------------------------------------- %%
\subsection{Execução e análise dos experimentos}
\label{sec:execucao_e_analise_dos_experimentos}

A automatização dos experimentos foi feita com dois conjuntos de scripts. O
primeiro (cmb) foi usado para gerenciamento e execução dos experimentos --
reserva de nós, implantação da imagem, gerenciamento do sistema de
armazenamento, configuração e execução do \emph{benchmark} e coleta dos
resultados. Os scripts se localizavam no frontend do Grid5000 e foram escritos
em bash. Esses scripts implementavam o fluxo de trabalho do estudo, descrito a
seguir. O segundo conjunto (cmb-local) foi usado na análise dos dados, se
localizava no computador do autor deste trabalho e era composto por scripts em
bash, Ruby e R.

Os scripts em cmb se encontram em \url{https://github.com/mdediana/cmb.git} e os
em cmb-local se encontram em \url{https://github.com/mdediana/cmb-local.git}.

%% ------------------------------------------------------------------------- %%
\subsubsection{Fluxo de trabalho dos experimentos}

A execução de um estudo compreendia diversas etapas, com um script
correspondendo a cada uma delas. O fluxo de trabalho propriamente dito também
estava definido em um script, que executava os outros, e é apresentado na Figura
\ref{fig:fluxo_de_trabalho_da_execucao_do_estudo}. Cada etapa presente no
fluxograma está descrita a seguir com o nome do script responsável entre
parênteses.

\begin{figure}[!htb] \centering

\begin{tikzpicture}[node distance = 2cm, auto]
    % Place nodes
    \node [block] (reserve) {Reserva dos nós};

    \node [block, right of=reserve, node distance=8em] (deploy) {Implantação da
imagem nos nós};

    \node [block, below of=deploy] (srvs) {Configuração dos nós};

    \node [block, below of=srvs] (riak) {Configuração do Riak};

    \node [block, below of=riak] (start) {Inicialização do Riak};

    \node [block, below of=start] (load) {Carga e aquecimento do sistema};

    \node [block, below of=load] (wan) {Configuração da WAN emulada};

    \node [block, below of=wan, node distance=10em] (run) {Execução de um
experimento};

    \node [decision, right of=run, node distance=10em] (loop) {Último
experimento?};
    
    \node [decision, above of=loop, node distance=10em] (reconf) {Consistência
ou localidade mudaram?};

    \node [block, right of=loop, node distance=10em] (stop1) {Término do Riak};

    \node [block, right of=riak, node distance=10em] (stop2) {Término do Riak};

    \node [block, right of=stop1, node distance=8em] (end) {Fim};

    % Draw edges
    \path [line] (reserve) -- (deploy);

    \path [line] (deploy) -- (srvs);

    \path [line] (srvs) -- (riak);

    \path [line] (riak) -- (start);

    \path [line] (start) -- (load);

    \path [line] (load) -- (wan);

    \path [line] (wan) -- (run);

    \path [line] (run) -- (loop);

    \path [line] (loop) -- node [near start] {não} (reconf);

    \path [line] (loop) -- node [near start] {sim}(stop1);

    \path [line] (reconf) -- node [near start] {não} (wan);

    \path [line] (reconf) -- node [near start] {sim}(stop2);

    \path [line] (stop2) -- (riak);

    \path [line] (stop1) -- (end);

\end{tikzpicture}

\caption{Fluxo de trabalho da execução do estudo.}
\label{fig:fluxo_de_trabalho_da_execucao_do_estudo} \end{figure}

\paragraph{Reserva dos nós (reserve)}Nessa etapa, escolhe-se o aglomerado, a
quantidade de nós, o período da reserva e o instante em que ela ocorrerá (pode
ser imediatamente ou em algum momento futuro). O script basicamente é uma forma
mais simples de executar o oarsub, ferramenta de reserva de nós do Grid5000. O
Grid5000 disponibiliza uma aplicação web em que é possível ver as reservas de
nós atuais em cada aglomerado.

\paragraph{Implantação da imagem nos nós (deploy)}Essa etapa usa a lista de nós
definida na reserva e lida com situações em que os nós não foram corretamente
implantados, algo relativamente comum. Se não fosse esse tratamento, o script
seria apenas uma forma mais simples de usar o kadeploy, ferramenta para
implantação de imagens do Grid5000.

\paragraph{Configuração dos nós (srvs)}Essa etapa consiste em separar os nós
reservados entre nós de Riak e instâncias do \emph{benchmark}, a partir das
quantidades de cada um definidas para o estudo. Nesse momento, os nós de Riak
também são dividos entre os centros de processamento de dados a serem usados e
os IPs das sub-redes são alocados (script net).

\paragraph{Configuração do Riak (riak)}Essa etapa consiste no envio dos arquivos
de configuração do Riak para cada nó. Nesse momento ocorre a configuração do
modelo de consistência a ser usado em um dado experimento.

\paragraph{Inicialização do Riak (start)}Essa etapa corresponde à inicialização
das instâncias de Riak em cada nó e à entrada de cada uma no aglomerado de
Riaks.

\paragraph{Carga e aquecimento do sistema (load)}Essa etapa consiste em popular
o banco de dados do Riak antes dos experimentos. Para a consistência na linha do
tempo, a fase de aquecimento do sistema é necessária (detalhes na subseção
\ref{sec:aquecimento}).

\paragraph{Configuração da WAN emulada (wan)}Nessa etapa as interfaces de rede
dos nós são configuradas com latência de rede, perda de pacotes, etc. Além
disso, as otimizações para WAN são aplicadas (script tune-tcp).

\paragraph{Execução de um experimento (run)}Essa etapa começa pela aquisição de
informações do sistema, como as condições de memória e disco dos nós e latência
da LAN. Após isso, a execução do \emph{benchmark} propriamente dita ocorre. Por
fim, arquivos com os resultados dos experimentos, logs e arquivos de
configuração são salvos para serem usados na análise dos resultados
posteriormente.

\paragraph{Término do Riak (stop)}Essa etapa é responsável por encerrar o Riak.
