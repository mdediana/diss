%% ------------------------------------------------------------------------- %%
\chapter{Projeto dos experimentos} \label{cap:projeto_dos_experimentos}

Este estudo teve por objetivo comparar, através de medição, o desempenho da
consistência em momento indeterminado e da consistência na linha do tempo em um
sistema de armazenamento geo-replicado. Para testar os modelos em diferentes
condições de rede, os experimentos usaram uma WAN emulada. Os nós do sistema
foram agrupados como se estivessem em centros de dados diferentes, ligados pela
WAN emulada. A carga de trabalho foi executada por uma aplicação de execução de
testes que simulava clientes localizados em cada um dos centros de dados. Cada
experimento era definido por um modelo de consistência, uma configuração de rede
(latência, perda de pacotes, etc) e uma carga de trabalho (relação
leitura/escrita, localidade, etc).

São alguns os tipos de projetos de experimentos que podem ser usados em um
estudo. A escolha entre eles se deve principalmente pelo balanço entre recursos
utilizados (tempo, energia, etc) e quantidade de informação -- quando mais
recursos gastos, maior a quantidade de informação adquirida. Este trabalho usou
dois tipos de experimentos fatoriais, um para a seleção final de fatores e outro
no estudo final. Esses tipos estão descritos na seção
\ref{sec:projeto_de_experimentos_fatoriais}.

A primeira etapa do projeto dos experimentos definiu aspectos técnicos dos
experimentos, considerando o objetivo do estudo, as limitações de recursos e o
ambiente disponível. Essa etapa envolveu predominantemente atividades de
programação e administração de sistemas, como implementação da consistência na
linha do tempo e preparação de scripts para a execução dos experimentos. Os
resultados dessa etapa estão descritos na seção \ref{sec:aspectos_tecnicos}.

A segunda etapa do projeto dos experimentos definiu o valor dos parâmetros que
não eram fatores, o resultado se encontra na seção \ref{sec:parametros_fixados}.
Além disso, a seleção inicial de fatores era grande e não havia recursos
suficientes para considerar todos no estudo final, por isso a segunda etapa do
projeto dos experimentos também envolveu a execução de experimentos para
identificar os fatores mais relevantes. Esses fatores compõem a seleção final de
fatores, enquanto os fatores menos relevantes passaram a ser tratados como
parâmetros fixados. Os resultados dessa etapa estão descritos na seção
\ref{sec:selecao_final_de_fatores}.

% ------------------------------------------------------------------------- %%
\section{Projeto de experimentos fatoriais}
\label{sec:projeto_de_experimentos_fatoriais}

%TODO: talvez citar o outro livro de performance
Um projeto de experimento fatorial consiste da combinação de dois ou mais
fatores em cada experimento que compõe o estudo. Existem dois tipos principais
de projetos de experimentos fatoriais: completo e fracionado \cite{Jain1991}.

Um projeto de experimento fatorial completo é constituído por todas as
combinações possíveis de todos os níveis de todos os fatores. Assim, a
quantidade total de experimentos é dada por:

$n = \prod_{i=1}^k{n_i}$,

onde k é o número de fatores e $n_i$ é a quantidade de níveis do
i$^{\textrm{\'esimo}}$ fator.

Esse tipo de projeto de experimento tem a vantagem de identificar com precisão a
influência de todos os fatores e suas interações no resultado. Mas quanto maior
a quantidade de fatores e de níveis em um estudo experimental, maior a
quantidade de recursos necessários para sua execução. Normalmente os fatores não
afetam igualmente os resultados. Pelo contrário, é comum alguns poucos fatores
explicarem a maior parte dos efeitos nos resultados.

Para esses casos, utiliza-se o projeto de experimentos fatoriais fracionado para
fazer a triagem dos fatores, identificando quais são os mais influentes.  Nesse
tipo de experimento, utiliza-se apenas uma parte de todos os experimentos
definidos no projeto de experimentos fatoriais completo. Um tipo particular de
projeto de experimentos fatoriais fracionado é o 2\textsuperscript{k}. Nesse
tipo, todos os fatores inicialmente selecionados são usados, mas apenas com dois
níveis cada (normalmente o mínimo e o máximo), resultando em um total de
2\textsuperscript{k} experimentos. Os detalhes do método para selecionar os
fatores mais influentes a partir dos resultados de um projeto de experimentos
2\textsuperscript{k} estão na subseção seguinte.

% ------------------------------------------------------------------------- %%
\subsection{Projeto de experimentos fatoriais fracionais 2\textsuperscript{k}}
\label{sec:projeto_de_experimentos_fatoriais_fracionais_2k}

Um projeto de experimentos fatoriais fracionais 2\textsuperscript{k} é composto
por 2\textsuperscript{k} experimentos que por sua vez resultam em
2\textsuperscript{k} medições de desempenho. Dadas essas medições, o desempenho
pode ser expresso por um modelo de regressão não-linear da forma:

$y = q_0 + q_Ax_A + q_Bx_B + q_Cx_C + ... + q_{AB}x_Ax_B + q_{AC}x_Ax_C +
q_{BC}x_Bx_C... + q_{ABC}x_Ax_Bx_C + ...$,

onde $y$ é o desempenho medido, $q_0$, $q_A$, $q_B$, etc são os coeficentes do
modelo, $x_A$, $x_B$, $x_C$, etc representam respectivamente os níveis dos
fatores A, B, C, etc. Os termos compostos pela multiplicação de dois ou mais
fatores representam as interações entre os fatores em questão.

Feito o modelo, define-se para cada fator uma relação entre seus níveis e os
valores -1 ou 1. Por exemplo, pode-se definir que a localidade 0,5 valerá -1 e a
0,9 valerá 1. Fazendo a substituição dos níveis por esses valores, tem-se um
sistema de 2\textsuperscript{k} equações e 2\textsuperscript{k} variáveis (os
coeficientes).

Com os coeficientes, calcula-se a variação total de y -- soma total dos
quadrados -- a partir da equação:

$STQ = SQA + SQB + SQC + ... + SQAB + SQAC + SQBC + ... + SQABC + ...$,

onde cada $SQX$ é dado por:

$SQX = 2^kq_X$

Cada $SQX$ é a porção da variação total explicada por X, que é um fator ou uma
interação entre eles. A partir disso, é possível finalmente calcular a fração da
variação explicada por cada X por:

$FSQX = SQX / STQ$

Comparando todos os $FSQX$s é possível descobrir quais são os fatores e
interações entre eles que mais afetam os resultados dos experimentos.

%% ------------------------------------------------------------------------- %%
\section{Aspectos técnicos} \label{sec:aspectos_tecnicos}

Uma das principais limitações no projeto de experimentos vem dos recursos
tecnológicos disponíveis para executá-los. Portanto, é preciso preparar o
sistema testado, o ambiente em que ele está instalado e a forma como a aplicação
de execução de testes funciona.

O sistema de armazenamento usado como objeto de testes é descrito na subseção
\ref{sec:sistema_de_armazenamento}. O ambiente dos experimentos é definido pela
plataforma escolhida para executá-los, descrita na subseção \ref{sec:ambiente}.
A forma como a WAN é emulada é descrita na subseção \ref{sec:rede}. A carga
sobre o sistema é definida pela aplicação de execução dos testes, descrita na
subseção \ref{sec:aplicacao_de_execucao_dos_testes}.

%% ------------------------------------------------------------------------- %%
\subsection{Sistema de armazenamento} \label{sec:sistema_de_armazenamento}

Uma abordagem para a comparação dos modelos de consistência seria o uso de um
sistema de armazenamento já existente que implementasse os dois modelos de
consistência, mas tal sistema não foi encontrado. A partir disso, uma outraa
abordagem seria o uso de sistemas diferentes, cada um implementando um modelo de
consistência. Apesar de existirem experimentos que usam essa abordagem
\cite{Cooper2008,Stonebraker2007,Pavlo2009}, dois problemas foram identificados.
O primeiro é que o desempenho de cada sistema pode ser afetado por fatores
particulares do sistema que não o modelo de consistência, como a tecnologia
utilizada, detalhes de configuração, entre outros. O segundo é que apesar de
existirem sistemas de armazenamento de software livre / código aberto que
implementam consistência em momento indeterminado, não foram encontrados
sistemas que implementassem consistência na linha do tempo.

Assim, decidiu-se usar um único sistema para os experimentos. Uma opção para tal
era implementar um sistema de armazenamento distribuído específico para os
experimentos. O problema dessa abordagem é que esse tipo de sistema é bastante
complexo, já que precisa prover funcionalidades como controle de entrada e saída
dos nós, algoritmos de particionamento, etc. Desenvolver todas essas
funcionalidades inviabilizaria este trabalho devido ao alto custo em tempo para
implementação.

Para evitar a implementação completa de um sistema de armazenamento, algumas
opções de software livre / código aberto foram analisadas. A seleção das opções
foi feita considerando modelos de consistência, estabilidade da solução e
simplicidade de desenvolvimento. Como não foram encontrados sistemas de
armazenamento de software livre / código aberto que implementem consistência na
linha do tempo, as soluções avaliadas foram aquelas que implementam consistência
em momento indeterminado. Os sistemas encontrados foram Dynomite
\cite{Dynomite}, Cassandra \cite{Lakshman2010}, Voldemort \cite{Voldemort} e
Riak \cite{Riak}. Todos eles usam basicamente a mesma arquitetura do Dynamo,
provendo gerenciamento de entrada e saída de nós no aglomerado, relógios vetor
para identificação e resolução de conflitos entre diferentes réplicas dos
objetos \cite{Lamport1978} e espalhamento consistente para o particionamento dos
objetos \cite{Karger1997a}.

O Dynomite foi descartado pois o projeto foi abandonado pela comunidade em um
estado ainda instável. O Cassandra por outro lado possui estabilidade e uma
comunidade bastante ativa, mas é mais complexo que os outros sistemas dado que
também implementa características de SGBDs orientados a colunas
\cite{Chang2006}. Dos dois sistemas restantes, o Riak foi escolhido por ser
implementado em Erlang, linguagem focada no desenvolvimento de sistemas
distribuídos, apresentando assim maior facilidade para o desenvolvimento do
modelo de consistência na linha do tempo. Um indício dessa facilidade é que o
riak\_kv, o módulo do Riak usado na implementação do novo modelo de
consistência, apresenta aproximadamente 20 mil linhas de código contra
aproximadamente 85 mil do Voldemort. Além disso, existe uma aplicação para
execução de testes usando Riak bastante completa (ver subseção
\ref{sec:aplicacao_de_execucao_dos_testes}). O Voldemort também possui aplicação
semelhante, mas ela oferece menos opções de configuração.

\subsubsection{Implementação da consistência na linha do tempo e outros} A
implementação da consistência na linha do tempo é incompleta. Para os
experimentos, a distinção entre leituras e escritas era importante. Mas a
distinção entre os tipo de escrita (inserção, atualização ou remoção) não era
muito importante dado que todos os tipos se comportam da mesma forma do ponto de
vista de tráfego local x remoto. Assim, apenas atualizações foram implementadas
de forma completa e eficiente, distinguindo a localização de cada nó com relação
aos centros de dados. As inserções são ineficientes, ocorrendo sempre pela mesma
réplica, mesmo que em outro centro de dados. Isso foi feito para não precisar
implementar um mecanismo para evitar conflitos de inserção. Remoções não foram
implementadas. Importante para a análise do desempenho com relação à localidade,
foi implementada a heurística do PNUTS em que a réplica mestre migra para o
centro de dados de onde vieram as últimas escritas. 

Além da implementação de consistência na linha do tempo, o riak\_kv foi alterado
para tratar corretamente os parâmetros extras necessários para a consistência na
linha do tempo recebidos através da interface HTTP. Outras alterações menores
dizem respeito a implementação de estatísticas sobre migrações.

Além do riak\_kv, outro módulo alterado foi o riak\_core. Quando o Riak recebe
uma requisição, ele descobre qual o nó responsável por tratá-la através do
algoritmo de espalhamento consistente, que se baseia no valor da chave do objeto
para tal. O Riak foi projetado para ser implantado em um único centro de
dados\footnote{O Riak Entreprise implementa replicação entre centros de dados,
mas é pago.}, portanto o algoritmo não leva em consideração os centros de dados
no momento de decidir para qual das réplicas a requisição deve seguir. Dessa
forma, algumas modificações foram necessárias no riak\_core, módulo responsável
pelo roteamento das requisições, para que ele priorizasse nós do mesmo centro de
dados em que a requisição chegou. A implementação é muito simples e pouco
versátil, funcionando apenas para o cenário do estudo (dois centros de dados) e
baseada nos nomes dos nós para saber em qual centro de dados cada um deles se
encontra.

%% ------------------------------------------------------------------------- %%
\subsection{Ambiente} \label{sec:ambiente}

Os experimentos foram executados no
Grid5000\footnote{\url{http://www.grid5000.fr/}}, uma plataforma para criação,
execução e monitoramento de experimentos de sistemas paralelos e distribuídos. A
plataforma possui mais de 5000 cores distribuídos em 9 sítios na França e um no
Brasil.

Outras plataformas como o OpenCirrus\footnote{\url{http://opencirrus.org/}} e
PlanetLab\footnote{\url{http://www.planet-lab.org/}} também foram consideradas,
mas foram descartadas por uma questão de conveniência, já que o autor deste
trabalho utilizou o Grid5000 em dois estágios de mestrado de respectivamente
quatro meses e um mês pelo INRIA na França. A experiência no ambiente adquirida
nesse período pode ser reutilizada neste trabalho, tornando o projeto e a
execução dos experimentos mais produtivos. O Amazon Web Services (AWS)
\footnote{\url{http://aws.amazon.com/}} também foi considerado, mas foi
descartado por não ser possível ter controle sobre as características de rede
entre os centros de dados, o que dificultaria a a interpretação dos resultados e
a reprodutibilidade dos experimentos.

A operação no Grid5000 se dá através do acesso ssh ao frontend de cada sítio.
Nele o usuário encontra seu diretório home, onde ele pode armazenar seus scripts
e dados dos experimentos, e tem acesso a ferramentas específicas da
infraestrutura. Como o Grid5000 é compartilhado por diversos pesquisadores, ele
oferece um conjunto de ferramentas (OAR\footnote{\url{http://oar.imag.fr/}}) e
regras para que um pesquisador reserve nós exclusivamente para ele por um
determinado período de tempo. Além dos nós, é possível reservar IPs para compor
sub-redes, recurso utilizado nos experimentos (ver \ref{sec:rede}). Outra
ferramenta bastante utilizada é o
kadeploy\footnote{\url{http://kadeploy.imag.fr/}}, responsável pela implantação
de imagens nos nós reservados pelo usuário.

%% ------------------------------------------------------------------------- %%
\subsubsection{Imagem} A imagem usada nos experimentos é um Debian GNU/Linux 6.0
(Squeeze) com kernel 2.6.32-5-amd64 baseado em uma imagem pré-configurada
disponibilizada pelo Grid5000. Além do conteúdo, essa imagem possui o Riak e o
Basho Bench modificados e algumas ferramentas de monitoração e análise de
desempenho como
sysstat\footnote{\url{http://sebastien.godard.pagesperso-orange.fr/}},
bwm-ng\footnote{\url{http://www.gropp.org/?id=projects&sub=bwm-ng}} e
iperf\footnote{\url{http://iperf.sourceforge.net/}}. Uma única imagem foi usada,
a distinção entre nós executando instâncias do Riak ou do Basho Bench foi feita
através dos scripts que gerenciam os experimentos.

%% ------------------------------------------------------------------------- %%
\subsubsection{Scripts de execução e análise dos experimentos} Os experimentos
foram conduzidos através de um conjunto de scripts (cmb) que se localiza no
frontend do Grid5000 e era usado para reserva de nós, instalação da imagem,
gerenciamento do sistema de armazenamento, configuração e execução da aplicação
de execução de testes e coleta dos resultados. Os scripts foram escritos em
bash. A parte de análise dos dados não usou o Grid5000 como ambiente, mas sim a
máquina do pesquisador, e foi feita através de um segundo conjunto de scripts
(cmb-local).  Esses scripts foram escritos em bash, Ruby e R.

%% ------------------------------------------------------------------------- %%
\subsection{Rede} \label{sec:rede}

Os sítios do Grid5000 são conectados por redes de alta velocidade. Suas redes
apresentam latências da ordem de cetenas de nanosegundos entre nós de um mesmo
aglomerado e da ordem de 20 ms entre sítios, e portanto não caracterizam uma
WAN. De qualquer forma, mesmo que caracterizassem, é necessário ter controle
sobre esses valores para poder testar o sistema em diferentes condições de rede
e possibilitar a reprodutibilidade dos experimentos.

Por isso, os experimentos usam a ferramenta traffic control (tc). que
possibilita a manipulação das filas de saída de pacotes de uma interface de
rede, por exemplo, priorizando um determinado tipo de tráfego. Mais
especificamente para emulação da WANs, é possível usar o
netem\footnote{\url{http://www.linuxfoundation.org/collaborate/workgroups/networking/}},
que provê funcionalidade para inserção de latência de rede, variação da
latência, perda de pacotes, pacotes duplicados, corrompidos e/ou fora de ordem.
Existem outras ferramentas como o
dummynet\footnote{\url{http://info.iet.unipi.it/~luigi/dummynet/}} e o
NISTNet\footnote{\url{http://snad.ncsl.nist.gov/itg/nistnet/}}, mas elas foram
desconsideradas dado que o netem já vem integrado ao tc e satisfazia os
requisitos funcionais dos experimentos.

Existem recomendações sobre otimizações de sistemas Linux para quando se
comunicam usando WANs -- o foco da configuração padrão são LANs.  Durante os
experimentos, sempre que os parâmetros da WAN foram alterados, um script para
ajuste da pilha TCP foi usado. A principal otimização desse script era ajustar
os tamanhos dos buffers de transmissão e recepção ao BDP (para mais detalhes,
ver seção \ref{sec:fatores_de_rede}).

\subsubsection{Centros de dados} \label{centros_de_dados} Para simular os
centros de dados, os nós que compunham o sistema eram divididos em dois
conjuntos CD1 e CD2, cada um representando um centro de dados. Além dos nós,
duas sub-redes SR1 e SR2 eram reservadas. Cada nó de CD1 recebia, além de seu IP
da rede do Grid5000, um IP de SR1, o mesmo valendo para CD2 e SR2.

Sistemas Linux usam o arquivo /etc/hosts como fonte primária para resolução de
nomes, apenas quando não encontram um nome definido ali (o que é a situação
padrão) consultam um DNS. Todos os nós no Grid5000 possuem um nome registrado no
DNS que aponta para o seu IP da rede do Grid5000. Nos experimentos, dois
arquivos hosts1 e hosts2 eram criados e substituíam o /etc/hosts dos nós de CD1
e CD2 respectivamente. O conteúdo de hosts1 eram os nomes dos nós de CD1 sendo
resolvidos para os IPs de SR1, o mesmo valendo entre hosts2 e SR2. Com isso, os
nós de CD1 resolviam os nomes dos nós de CD2 para os IPs de SR2 e vice-versa.
Como o /etc/hosts tem prioridade sobre o DNS na resolução de nomes, todas as
requisições que saíam de um centro de dados para o outro usavam o IP daquela
sub-rede, enquanto as requisições para o mesmo centro de dados usavam o IP da
rede do Grid5000.

A partir dessa configuração foi possível adicionar um filtro baseado em
sub-redes ao tc de modo que as características de WAN eram aplicadas às
requisições que saíam para o outro centro de dados, enquanto as requisições para
a mesma sub-rede saíam inalteradas.

%TODO: dummynet: Marta Carbone and Luigi Rizzo, Dummynet Revisited, ACM SIGCOMM
%Computer Communication Review, 40(2) pg.12-20, March 2010

%% ------------------------------------------------------------------------- %%
\subsection{Aplicação de execução dos testes}
\label{sec:aplicacao_de_execucao_dos_testes}

A aplicação de execução de testes usada foi o Basho Bench \cite{Basho},
específica para o Riak. Ela provê configurações para quantidade de clientes,
distribuições de acesso, proporção entre leituras e escritas, entre outras. A
aplicação foi modificada, pois mais de uma instância dela foi executada
simultaneamente nos experimentos. Além de evitar gargalos na aplicação de
execução de testes, isso era importante para implementação de localidade nos
experimentos. Além disso, foi necessária a implementação de um script para a
consolidação dos dados dos obtidos pelas diversas instâncias do Basho Bench.

Outra aplicação de execução de testes considerada foi o YCSB \cite{Cooper2010}.
Apesar de possuir mais flexibilidade que o Basho Bench nas suas configurações,
ela não está preparada para acessar o Riak, acesso esse que precisaria ser
implementado. Além disso, ela também não oferece todas as funcionalidades
necessárias para os experimentos, que precisariam ser implementadas.

%% ------------------------------------------------------------------------- %%
\section{Parâmetros fixados} \label{sec:parametros_fixados}

Um motivo para fixar um parâmetro é a impossibilidade de variá-lo. Por exemplo,
um estudo pode estar limitado apenas às configurações de hardware disponíveis
para o analista/pesquisador. Um outro motivo é saber de antemão que, apesar de
afetar o desempenho do sistema, o parâmetro é pouco relevante para o estudo em
questão -- caso contrário, ele seria considerado um fator.

Os parâmetros inicialmente levantados na seção \ref{sec:lista_de_parametros} que
não foram considerados fatores foram fixados nos seguintes valores:

\paragraph{Quantidade de centros de dados:}2. Com esse valor os experimentos
ficaram mais simples de executar e analisar devido à simetria do sistema.

\paragraph{Quantidade de nós por centro de dados:}Razão entre quantidade de nós
do sistema e quantidade de centros de dados. Com esse valor os experimentos
ficaram mais simples de executar e analisar devido à simetria do sistema.

\paragraph{Algoritmo de particionamento das chaves:}Algoritmo de espalhamento
consistente do Riak. A única configuração feita foi a quantidade de partições
utilizadas, 512. Esse valor satisfaz as duas condições descritas na documentação
do Riak, ser uma potência de 2 e resultar em ao menos 10 partições por nó (caso
os experimentos finais usassem mais do que 64 nós esse valor teria sido
aumentado).

\paragraph{Algoritmo de detecção de falhas:}Os experimentos sempre consideram
funcionamento correto dos nós, experimentos que apresentaram falha de algum nó
foram descartados e executados novamente.

\paragraph{Fator de replicação ($N$):}3. Valor que resulta em um balanço
razoável entre desempenho, disponibilidade e durabilidade em aplicações reais
\cite{DeCandia2007}.

\paragraph{Limiar de migração (para consistência na linha do tempo):}3.  Valor
padrão usado pelo PNUTS \cite{Cooper2008}.

\paragraph{Interface de acesso:}HTTP. O Riak também suporta Protocol
Buffers\footnote{\url{http://code.google.com/p/protobuf/}}, mais eficiente que a
interface HTTP. Apesar disso a opção foi por HTTP pois eficiência não era tão
relevante para os experimentos dado que a carga sobre o sistema era
relativamente baixa, mas implementar os parâmetros da consistência na linha do
tempo na interface HTTP era mais simples.

\paragraph{Nível de log:}WARN. Alguns experimentos exploratórios mostraram perda
de desempenho quando o  nível de log estava em INFO. De qualquer forma, como a
carga sobre o sistema era relativamente baixa, esse parâmetro era pouco
relevante.

\paragraph{Topologia da rede:}Topologia da rede do aglomerado utilizado no
estudo. A topologia dos aglomerados considerados consistem apenas de nós ligados
diretamente a um switch.

\paragraph{Largura de banda nos elementos intermediários (switches, roteadores,
etc):}Largura de banda no aglomerado utilizado no estudo. Esse valor é dado pelo
switch em que os nós estão ligados (ver seção
\ref{sec:mecanismo_de_armazenamento_e_aglomerado}). Mas antes da definição do
aglomerado utilizado, estudos exploratórios em alguns aglomerados mostraram que
não existiam gargalos no switch mesmo nos experimentos que mais demandavam
banda.

\paragraph{Latência da LAN:}Latência do aglomerado utilizado no estudo. Todos os
aglomerados considerados apresentam latências semelhantes. Uma medição com 60
amostras espaçadas em 5s no aglomerado sol mostrou 167$\mu$s.
% ping -i 5 -c 60 sol-20

\paragraph{Variação de latência da LAN:}Variação de latência do aglomerado
utilizado no estudo. Todos os aglomerados considerados apresentam variações de
latência semelhantes. A mesma medição feita para a latência mostrou desvio
padrão de 90$\mu$s.

\paragraph{Taxa de chegada de requisições} %TODO

Nesse ponto seria usado disco como mecanismo de armazenamento. Mas durante os
experimentos para aglomerado essa decisão foi mudada (ver subseção
\ref{sec:aglomerado}).

%% ------------------------------------------------------------------------- %%
\section{Seleção final de fatores} \label{sec:selecao_final_de_fatores}

Uma abordagem possível para a seleção final de fatores seria agrupar todos os
fatores levantados na seção \ref{sec:selecao_de_fatores_a_serem_estudados} em um
único projeto de experimentos fatoriais 2\textsuperscript{k}. O problema é que
mesmo com apenas 2 níveis por fator, a quantidade final de experimentos seria
proibitiva, dado que a quantidade de fatores era X. Por isso, a opção adotada
foi dividir os fatores em grupos menores e realizar experimentos para cada
grupo. Os grupos foram: aglomerado, quantidade de nós do sistema, quantidade e
tamanho dos objetos armazenados, rede e carga de trabalho.
%TODO: contar fatores iniciais

%O principal problema de fazer essa separação é o fato de se perder a
%importância relativa entre os fatores de grupos diferentes. Por exemplo, uma
%localidade de 0,5 ou 0,9 poderia ser comparada com outros fatores de carga de
%trabalho, mas provavelmente não apareceria como influente caso os experimentos
%fossem executados sem considerar a rede. 

Existem situações em que desconsiderar um fator que aparece como influente não
necessariamente implica em ameaça à validade. Experimentos fatoriais mostram a
influência relativa de cada fator e cada interação entre fatores. Nesse tipo de
análise, o total de todas as influências relativas deve ser sempre 100\%. Por
isso, mesmo que todos os fatores afetem pouco o resultado, um ou mais vão
aparecer nos experimentos fatoriais com influência alta. Assim, também foram
calculados os coeficientes de variabilidade\footnote{O coeficiente de variação é
a divisão do desvio padrão pela média e é uma maneira de representar a
variabilidade dos dados desconsiderando sua ordem de grandeza} (CVs) para cada
resultado de forma a estimar qual a importância daquele conjunto de fatores e
interações como um todo.

Os experimentos descritos nesta seção usam percentis dos tempos de resposta das
requisições ao invés de médias. As requisições deste estudo são divididas entre
locais, da ordem de poucos milissegundos, e remotas, da ordem de centenas de
milissegundos. Dessa forma, as requisições remotas dominam a média já que são em
geral duas ordens de grandeza maiores que as locais. Por isso os estudos fazem
análises distintas para cada tipo de requisição, usando percentis: percentis
baixos representam requisições locais e percentis altos representam requisições
remotas. Também é feita a distinção entre escritas e leituras dada a diferença
de natureza dessas operações.

Dois fatores que possuem um tratamento especial ao longo do experimento são
configuração de replicação (para consistência em momento indeterminado) e versão
requisitada nas leituras (para consistência na linha do tempo). Isso porque seus
níveis influenciam na proporção de requisições locais e remotas, fundamental
para este estudo. Por isso, esses dois fatores são tratados como um único,
chamado modo (subseção \ref{sec:modo}).


%% ------------------------------------------------------------------------- %%
\subsection{Modo} \label{sec:modo}

Todas as configurações usam $N = 3$, comumente adotado em aplicações web (ver
seção \ref{sec:parametros_fixados}). Os modos são:

\begin{itemize} \item ind1: Consistência em momento indeterminado com $W$ = 1 e
$R$ = 1 \item ind2: Consistência em momento indeterminado com $W$ = 2 e $R$ = 1
\item lt\_qqer: Consistência na linha do tempo com leituras de qualquer versão
\item lt\_rec: Consistência na linha do tempo com leituras da versão mais
recente \end{itemize}

Os experimentos simulam dois centros de dados. O algoritmo de particionamento
garante que existe ao menos uma réplica em cada centro de dados (ver subseção
\ref{sec:sistema_de_armazenamento}). Assim, existem sempre duas situações
possíveis com relação à localização das réplicas do ponto de vista do
coordenador: uma local e duas remota ou duas locais e uma remota. Dado isso,
ind1 resulta em todas as leituras e escritas locais.  ind2 resulta em todas as
leituras locais e metade das escritas locais e a outra metade remotas. lt\_qqer
resulta em todas as leituras locais e a quantidade de escritas dependente da
localidade dos acessos. Finalmente, lt\_rec resulta tanto em leituras quanto
escritas dependentes da localidade.

Os modos foram escolhidos de forma a representar situações encontradas em
sistemas de produção e ao mesmo tempo limitar a quantidade de níveis de forma a
tornar os experimentos viáveis devido a limitação de recursos. Assim,
consistência na linha do tempo com leituras de versões específicas não foi
considerada já que ela é um meio termo entre leituras de versão mais recente e
leituras de qualquer versão. Consistência em momento indeterminado com $W = 1$ e
$R = 2$ não foi considerada pois sua semântica é similar a $W = 2$ e $R = 1$,
mas teria seu desempenho prejudicado considerando que leituras predominam nas
distribuições de operações usadas nos experimentos (ver subseção
\ref{sec:distribuicao_de_operacoes}).

Esses modos implicam em trocas além de desempenho e consistência. A principal é
durabilidade, que para ind2 é mais alta do que para os outros casos, em que a
confirmação de escrita de uma única réplica é suficiente.

%% ------------------------------------------------------------------------- %%
\subsection{Mecanismo de armazenamento e aglomerado}
\label{sec:mecanismo_de_armazenamento_e_aglomerado}

Esse é o único fator que não usou experimentos fatoriais para ser desconsiderado
-- na época em que foi realizado o pesquisador ainda não conhecia o projeto
desse tipo de experimento. Apesar disso, os resultados obtidos são suficientes
para apoiar a decisão de desconsiderar esse fator.

Os aglomerados do Grid5000 considerados foram paradent, parapide, sol e suno. A
descrição do hardware e a quantidade de nós de cada um deles se encontra na
Tabela \ref{tab:aglomerados_do_grid5000}.

\begin{table}[!h] \begin{center} \begin{tabular}{|c|c|c|c|c|} \hline Aglomerado
& CPU & Memória & Disco & Quantidade de nós \\ \hline parapide & & & & \\ \hline
paradent & & & & \\ \hline \end{tabular} \caption{Aglomerados do Grid5000}
\label{tab:aglomerados_do_grid5000} \end{center} \end{table}

Os experimentos feitos para o mecanismo de armazenamento mostraram diferenças
consideráveis no desempenho do Riak em aglomerados diferentes. Considerando que
os experimentos são limitados por E/S (e não por CPU) e que não havia gargalo de
rede, decidiu-se verificar o desempenho dos discos em cada aglomerado. Pela
especificação do hardware dos aglomerados é possível notar que os discos são de
tipos diferentes. Assim, como esperado, essa diferença no desempenho dos discos
apareceu nos resultados. Para medição do desempenho, os experimentos usaram o
hdparm para acesso sequencial e o
seeker\footnote{url{http://www.linuxinsight.com/how\_fast\_is\_your\_disk.html}}
para acesso aleatório. Os resultados podem ser vistos na Tabela
\ref{tab:comparacao_de_discos_entre_aglomerados}.

\begin{table}[!h] \begin{center} \begin{tabular}{|c|c|c|c|c|c|} \hline
Aglomerado & Tipo & Tamanho & Acesso sequencial (MB/s) & Acesso aleatório
(seeks/s) & Acesso aleatório (tempo de resposta em ms) \\ \hline sol & & & 59,8
& 78 & 12,7 \\ \hline suno & & & 242,7 & 131 & 7,6 \\ \hline griffon & & & 73,9
& 56 & 17,6 \\ \hline parapluie & & & 103,9 & 77 & 13,0 \\ \hline \end{tabular}
\caption{Comparação de desempenho dos discos entre aglomerados}
\label{tab:comparacao_de_desempenho_dos_discos_entre_aglomerados} \end{center}
\end{table}

Além  do tipo de disco, um outro fator a considerar era o cache de disco. Em
sistemas Linux, todo a memória livre é automaticamente usada como cache de
disco. Dado isso, existiam três opções para a execução dos experimentos com
relação ao mecanismo de armazenamento, considerando que um tamanho do banco de
dados podia ser escolhido de forma a manter todos os dados em memória:

\begin{enumerate} \item Dados em disco e cache limpo no início dos experimentos:
O cenário seria mais real, mas mais difícil de analisar pois os efeitos do disco
e da memória sobre o desempenho do sistema se misturariam. Além disso, o efeito
do preenchimento do cache seria um complicador extra, dado que durante um teste
uma dada chave acessada mais de uma vez seria servida do disco a primeira vez e
da memória nas seguintes.

\item Dados em cache no início dos experimentos: O disco seria predominantemente
usado apenas para escritas e as leituras seriam servidas a partir do cache.

\item Dados em memória: O Riak pode ser configurado para funcionar como um banco
de dados em memória, eliminando definitivamente o efeito do disco.
\end{enumerate}

A terceira opção foi a escolhida. Realizar os experimentos com banco de dados em
memória deve gerar resultados mais precisos e fáceis de ser interpretados por
descartar a influência de desempenho do disco. A princípio os resultados podem
parecer menos realistas e aplicáveis, mas na prática eles são tão limitados
quanto o uso de disco, já que nesse caso os resultados são afetados pelo tipo de
disco e pela relação entre o tamanho do banco de dados e a memória livre. Um
exemplo pode ser visto na comparação de suno com parapluie, em que o primeiro
possui discos com taxas de acesso acima do 1Gb/s da rede -- o gargalo em caso
seria a rede, em outro o disco. Além disso, efeitos do cache de disco tornariam
os resultados ainda mais particulares e difíceis de ser generalizados.  Dessa
forma, ao se usar banco de dados em memória elimina-se os efeitos das interações
entre rede, disco e cache de disco e a análise pode ser focada apenas na rede.

%% ------------------------------------------------------------------------- %%
\subsection{Quantidade de nós do sistema}
\label{sec:quantidade_de_nos_do_sistema}

Além da quantidade de nós do sistema, estes experimentos fatoriais incluíram
dois fatores não considerados na lista de fatores inicial: quantidade de
instâncias da aplicação de execução de testes e quantidade de threads em cada
instância da aplicação de execução de testes. Esses dois fatores não haviam sido
considerados inicialmente pois o passo de levantamento dos parâmetros acontece
antes da seleção da técnica de avaliação. Assim, eles só foram considerados após
medição ser definida como técnica de avaliação para este estudo, o que fez
surgir a necessidade de dimensionar não só sistema mas também a aplicação de
execução dos testes.

Os níveis inicialmente selecionados para esse estudo foram:

\begin{itemize} \item Quantidade de nós do sistema: 8 e 16 \item Quantidade de
instâncias da aplicação de execução de testes: 2 e 4 \item Quantidade de threads
em cada instância da aplicação de execução de testes: 32 e 64 \end{itemize}

A quantidade de partições ser uma potência de 2 (ver seção
\ref{sec:parametros_fixados}. Para manter a simetria do sistema, os níveis
considerados para quantidade de nós no sistema também foram potências de 2,
garantindo assim a mesma quantidade de partições por nó. Por sua vez, a
quantidade de instâncias da aplicação de execução dos testes e a quantidade de
threads por instância também foram potências de 2, de forma a balancear a carga
média tanto por nó quanto por partição.

Este estudo usou modo lt\_rec, localidade de 50\% e latência de rede de 100ms.
Esses valores foram escolhidos pois através deles obtém-se uma quantidade
balanceada de leituras e escritas locais e remotas. O resultado do estudo pode
ser visto na Tabela \ref{tab:estudo_para_quantidade_de_nos_do_sistema}.

\begin{table}[!h] \begin{center} \begin{tabular}{|c|c|c|c|c|c|c|c|c|} \hline
Operação & Percentil & N & A & T & NA & NT & AT & NAT\\ \hline leitura & 10 & 30
& 18 & 22 & 10 & 8 & 7 & 4 \\ \hline leitura & 90 & 65 & 13 & 15 & 3 & 4 & 0 & 0
\\ \hline escrita & 10 & 96 & 2 & 1 & 0 & 0 & 0 & 0 \\ \hline escrita & 90 & 65
& 15 & 13 & 3 & 3 & 0 & 0 \\ \hline \end{tabular} \caption{Estudo para
quantidade de nós do sistema. N representa a quantidade de nós do sistema, A
representa a quantidade de instâncias da aplicação de execução de testes e T
representa a quantidade de threads usadas em cada instânca da aplicação de
execução de testes.} \label{tab:estudo_para_quantidade_de_nos_do_sistema}
\end{center} \end{table}

Na maioria dos casos, o tamanho do sistema tem a maior influência nos resultados
e a quantidade de instâncias da aplicação de execução de testes e a quantidade
de threads não são desprezíveis, ainda mais ao se considerar as interações entre
elas. Como comentado no início desta seção, mesmo sendo influentes, alguns
fatores foram desconsiderados para manter a quantidade de fatores finais baixa.
Esse foi o caso dos três fatores desse estudo. Nesse caso, a opção foi por
manter o maior tamanho de sistema possível, evitando gargalos de rede ao máximo
e não sobrecarregando o sistema. Por isso, a opção foi pelos valores que
resultam na configuração ``mais leve'', fato confirmado através da observação
dos gráficos das FDAs. Dessa forma, os valores fixados foram:

\begin{itemize} \item Quantidade de nós do sistema: 16 (maior valor) \item
Quantidade de instâncias da aplicação de execução de testes: 4 (maior valor)
\item Quantidade de threads em cada instância da aplicação de execução de
testes: 32 (menor valor) \end{itemize}

Uma outra opção a esses valores seria o uso de 32 nós do sistema e 8 instâncias
da aplicação de execução de testes, resultando em um total de 40 nós. Isso não
foi feito por questões operacionais. Ao definir que o sistema usaria memória
como mecanismo de armazenamento, a escolha do aglomerado passou a ser menos
relevante, dado que todos os aglomerados oferecem nós com capacidade de
processamento (CPU) razoável, ao menos 4GB de memória e placas de rede de 1Gb/s.
O aglomerado sol foi escolhido predominantemente por questões operacionais --
ele é um dos maiores aglomerados disponíveis no Grid5000 (47 nós) e tem baixa
concorrência com outros pesquisadores pela reserva de nós. Mas mesmo assim, é
muito comum alguns poucos nós já estarem reservados por outros pesquisadores,
além de alguns nós apresentarem falhas no momento da implantação da imagem. Esse
último problema levou o pesquisador a sempre reservar alguns nós além dos
necessários para garantir a quantidade mínima de nós para executar os
experimentos. Dessa forma, experimentos que precisassem de 40 nós seriam mais
difíceis de ser executados.

%% ------------------------------------------------------------------------- %%
\subsection{Quantidade de objetos armazenados e tamanho dos objetos armazenados}
\label{sec:quantidade_de_objetos_armazenados_e_tamanho_dos_objetos_armazenados}

Os experimentos fatoriais relacionados ao tamanho do banco de dados também
consideraram o atraso de rede como fator. O atraso de rede foi usado como uma
simplificação da WAN, dessa forma foi possível comparar a importância relativa
entre esses fatores e a rede.

Os níveis inicialmente selecionados foram:

\begin{itemize} \item Quantidade de objetos armazenados: 64000 e 256000 \item
Tamanho dos objetos armazenados: 100 e 10000 \end{itemize}

Este estudo usou modo lt\_rec e localidade de 50\%.  Esses valores foram
escolhidos pois através deles obtém-se uma quantidade balanceada de leituras e
escritas locais e remotas. O resultado do estudo pode ser visto na Tabela
\ref{tab:estudo_para_quantidade_e_tamanho_dos_objetos_armazenados}.

\begin{table}[!h] \begin{center} \begin{tabular}{|c|c|c|c|c|c|c|c|c|} \hline
Operação & Percentil & Q & T & L & QT & QL & TL & QTL\\ \hline leitura & 10 & 0
& 100 & 0 & 0 & 0 & 0 & 0 \\ \hline leitura & 90 & 0 & 0 & 100 & 0 & 0 & 0 & 0
\\ \hline escrita & 10 & 0 & 100 & 0 & 0 & 0 & 0 & 0 \\ \hline escrita & 90 & 0
& 0 & 100 & 0 & 0 & 0 & 0 \\ \hline \end{tabular} \caption{Estudo para
quantidade e tamanho dos objetos armazenados. Q representa a quantidade de
objetos armazenados, T representa o tamanho dos objetos armazenados e L
representa a latência.}
\label{tab:estudo_para_quantidade_e_tamanho_dos_objetos_armazenados}.
\end{center} \end{table}

É possível perceber que a quantidade de objetos não afeta o desempenho do
sistema. Como o tempo de aquecimento depende da quantidade de objetos
armazenados, quanto menor essa quantidade mais rápido os experimentos são
executados. Por outro lado, optou-se por um número não tão baixo de forma a
evitar um excesso de conflitos.

O tamanho dos objetos não afeta o desempenho das requisições remotas. E apesar
desse fator aparecer com 100\% de influência nas requisições locais, o CV dessas
requisições foi de 19\% para leituras e 16\% para escritas.  Além disso, o foco
desta pesquisa está no comportamento do sistema na WAN, onde as requisições são
duas ordens de grandeza maiores. O valor para tamanho dos objetos armazenados
foi escolhido baseado em estudo dos sistemas de caching distribuído no Facebook
que relata que 90\% dos valores de praticamente todos os sistemas está abaixo
desse valor.

Assim, os valores fixados foram:

\begin{itemize} \item Quantidade de objetos armazenados: 128000 \item Tamanho
dos objetos armazenados: 500 \end{itemize}

%TODO: comentar conflitos, resultados são estranhos confl : 5 44 44 1 2 5 1   |
%CV =  0.6548619 TODO: citar Workload Analysis of a Large-Scale Key-Value Store

%% ------------------------------------------------------------------------- %%
\subsection{Fatores de rede} \label{sec:fatores_de_rede}

Um estudo preliminar foi feito para verificar o tamanho dos buffers de leitura e
escrita para verificar as recomendações que dizem que os buffers devem ser o
dobro do BDP. A principal motivação de checar esse fato é que alguns
experimentos com iperf mostraram ganhos de desempenho para buffers até quatro
vezes maiores que o BDP. Esse é um tipo de cenário que coloca bastante pressão
nos buffers.

Os níveis inicialmente selecionados foram:

\begin{itemize} \item Proporção entre tamanho dos buffers: 2 e 4 \end{itemize}

Este estudo usou modo lt\_rec e localidade de 50\%. Esses valores foram
escolhidos pois através deles obtém-se uma quantidade balanceada de leituras e
escritas locais e remotas. Para a rede, o estudo usou latências de 100ms e
300ms, variação de latência de 50\% e taxas de pacotes fora do ordem de 0\% e
5\%. A alta variabilidade e os pacotes fora de ordem criam um cenário que
pressiona os buffers de transmissão e recepção. O resultado do estudo pode ser
visto na Tabela
\ref{tab:estudo_para_tamanho_dos_buffers_de_transmissao_e_recepcao}.

\begin{table}[!h] \begin{center} \begin{tabular}{|c|c|c|c|c|c|c|c|c|} \hline
Operação & Percentil & L & O & B & LO & LB & OB & LOB\\ \hline leitura & 10 & 92
& 0 & 3 & 0 & 0 & 2 & 3\\ \hline leitura & 90 & 98 & 0 & 1 & 0 & 0 & 0 & 0\\
\hline escrita & 10 & 87 & 11 & 0 & 1 & 1 & 0 & 0\\ \hline escrita & 90 & 99 & 0
& 0 & 0 & 0 & 0 & 0\\ \hline \end{tabular} \caption{Estudo para tamanho dos
buffers de transmissão e recepção. L representa a latência, R representa a taxa
de pacotes fora de ordem e B representa o tamanho dos buffers.}
\label{tab:estudo_para_tamanho_dos_buffers_de_transmissao_e_recepcao}.
\end{center} \end{table}

Como o tamanho dos buffers não afetou o desempenho, a opção foi por
configurá-los como o dobro do BDP, seguindo as recomendações.

Feito isso, os experimentos para rede foram executados. A taxa de pacotes
corrompidos não foi considerada neste estudo pois experimentos preliminares
fizeram com que nós do Riak falhassem por problemas de comunicação. Como nenhuma
referência indicando que a taxa de pacotes corrompidos é um fator fundamental em
WANs, a opção foi ignorar esse fator.

Os níveis inicialmente selecionados foram:

\begin{itemize} \item Latência da WAN (ms): 100 e 300 

\item Variação da latência da WAN (\%): 1 (pouca variação) e 50 (muita variação)

\item Taxa de perda de pacotes da WAN (\%): 0,05 (pouca perda) e 1 (muita perda) 

\item Taxa de duplicação de pacotes da WAN (\%): 0,05 e 5

\item Proporção de pacotes fora de ordem na WAN (\%): 0,05 e 5

\item Algoritmo de congestionamento: cubic e htcp \end{itemize}

%TODO: falar sobre cubic e htcp

O resultado do estudo pode ser visto na Tabela
\ref{tab:estudo_para_fatores_de_rede} (devido ao grande números de colunas da
tabela apenas colunas com ao menos um valor diferente de 0 são apresentadas).

\begin{table}[!h] \begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|} \hline Operação & Percentil \\
\hline leitura & 10 \\ \hline leitura & 90 \\ \hline escrita & 10 \\ \hline
escrita & 90 \\ \hline \end{tabular} \caption{Estudo para fatores de rede. L
representa a latência, V representa a variação da latência, P representa as taxa
de perdas, D representa a taxa de pacotes duplicados, O representa a taxa de
pacotes fora de ordem e C representa o algoritmo de congestionamento.}
\label{tab:estudo_para_fatores_de_rede}.  \end{center} \end{table}

%TODO: decidir se faz uma tabela pra cada ordem de efeitos (3a e talvez 4a ordem
%precisem de 2 tabelas) ou se só usa colunas != 0 (2 tabelas)

É possivel perceber que a latência, a variação da latência, a taxa de perdas e
as interações entre elas são os fatores que mais afetam o desempenho do sistema.
Assim, os níveis escolhidos para esses três fatores nos experimentos foram:

\begin{itemize} \item Latência da WAN (ms): 0, 100, 200 e 300

\item Taxa de perda de pacotes da WAN (\%): 0, 0,01 e 0,1 

\end{itemize}

%TODO: explicar perdas

Os níveis da latêncis são baseados nas latências entre os centros de dados dos
Amazon Web Services \cite{Sovran2011}.  Os centros de dados considerados são
Califórnia (EUA -- Costa Oeste), Virginia (EUA -- Costa Leste), Irlanda e
Singapura. A menor latência observada foi 82 ms entre os centros de dados dos
EUA e a maior foi 277 ms entre Irlanda e Singapura.

Níveis nulos de latência, variação da latência e taxa de perdas equivalem a ter
todo o sistema operando em uma rede local. Os resultados obtidos para esses
casos devem ser usados como auxílio na interpretação dos resultados, mas não
devem ser considerados na análise final dado que sistemas geo-replicados, por
definição, não operam nessas condições.

Os valores fixados dos fatores desconsiderados foram:

\begin{itemize}

\item Variação da latência da WAN (\%): 50 (muita variação)

\item Taxa de perda de pacotes da WAN (\%): 0 

\item Taxa de duplicação de pacotes da WAN (\%): 0

\item Proporção de pacotes fora de ordem na WAN (\%): 0

\item Algoritmo de congestionamento: cubic \end{itemize}

Apesar de afetar o desempenho, a variação foi fixada dado que grandes variações
de latência em WANs são comuns. Além disso, dos 3 fatores, esse é o que menos
afeta, mesmo com os experimentos usando variações bem diferentes (1\% e 50\%). O
algoritmo de congestionamento foi fixado como ``cubic'', pois esse é o padrão no
Linux utilizado nos experimentos.

Apesar de a taxa de pacotes fora de ordem ser fixada, a ocorrência de alguns
pacotes fora de ordem é possível dada a variação da latência. O emulador de WAN
foi configurado para aplicar uma correlação na variação da latência usando
distribuição normal. Com isso, a probabilidade de grandes diferenças de latência
entre pacotes consecutivos é baixa, diminuindo assim a probabilidade de pacotes
fora de ordem.

%% ------------------------------------------------------------------------- %%
\subsection{Fatores de carga de trabalho}
\label{sec:fatores_de_carga_de_trabalho}

Os experimentos para fatores de carga de trabalho também consideraram o atraso
de rede como fator. O atraso de rede foi usado como uma simplificação da WAN,
dessa forma foi possível comparar a importância relativa entre esses fatores e a
rede.

A consistência na linha do tempo pode tornar um sistema sob cargas com um maior
número de escritas inviável pois as escritas se tornam indisponíveis em caso de
falha. Assim, este estudo considera situações em que ela é competitiva quando
comparada com a consistência em momento indeterminado.

Ao fazer uma atualização em um objeto na consistência em momento indeterminado,
é necessário o envio do relógio-vetor. Por isso, espera-se que antes de qualquer
atualização haja uma leitura. Esse fato restringe a quantidade de escritas a um
máximo de 50\% da carga de trabalho.

A partir disso, os níveis inicialmente selecionados foram:

\begin{itemize} \item Distribuição de operações: 2:1 e 10:1

\item Popularidade dos objetos acessados:uniforme (todos os objetos são
acessados em média a mesma quantidade de vezes) e concentrada (os acessos
obedecem a uma distribuição Pareto)

\item Localidade: 0,5 (origem dos acessos para cada objeto distribuídos
igualmente entre centros de dados) e 0,9 (90\% dos acessos para cada objeto
originado em um centro de dados e os 10\% restantes originados no outro centro
de dados. \end{itemize}

A distribuição normal não foi usada para popularidade por simplicidade. Pelo
teorema do limite central, a medida em que o tamanho de uma amostra tende a
infinito, a distribuição normal e a uniforme se aproximam. Dado que a aplicação
de execução de testes já implementa a distribuição uniforme, não há a
necessidade de implementar a distribuição normal.

Como os modos possuem comportamentos diferentes para requisições locais e
remotas, os experimentos foram executados para cada modo. O resultado para
requisições locais apresentaram CVs em torno de 0,02 para todos os modos. Isso
indica que requisições locais não sofrem influência de nenhum dos fatores. Já
requisições remotas apresentaram CV de aproximadamente 0,5 e 100\% de influência
do atraso para ind2, tl\_qqer e tl\_rec (ind1 não tem requisições remotas).

A análise da relação leitura/escrita e localidade são feitas pela média do tempo
de resposta do total de requisições e não pelos percentis. Isso porque o
primeiro fator diz respeito à composição entre leituras e escritas e o segundo à
composição entre requisições locais e remotas. Por exemplo, com localidade 0,5
percebe-se que o percentil 70 representa requisições remotas, enquanto com
localidade 0,9 o mesmo percentil representa requisições locais. Se a análise
fosse feita por percentis, essa informação se perderia e localidade nunca teria
influência (como pode ser observado pelos baixos CVs). Dado issom, o resultado
do estudo pode ser visto na Tabela
\ref{tab:estudo_para_fatores_de_carga_de_trabalho}

\begin{table}[!h] \begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|} \hline Modo & R & X & P & L &
RX & RP & RL & XP & XL & PL & RXP & RXL & RPL & XPL & RXPL\\ \hline ind1 & 19 &
12 & 2 & 31 & 0 & 3 & 2 & 4 & 6 & 6 & 4 & 0 & 0 & 8 & 1\\ \hline ind2 & 50 & 0 &
0 & 39 & 0 & 0 & 11 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ \hline lt\_qqer & 25 & 30
& 0 & 19 & 9 & 0 & 6 & 0 & 8 & 0 & 0 & 3 & 0 & 0 & 0\\ \hline lt\_rec & 0 & 53 &
0 & 34 & 0 & 0 & 0 & 0 & 13 & 0 & 0 & 0 & 0 & 0 & 0\\ \hline \end{tabular}
\caption{Estudo para fatores de carga de trabalho para ind1. R representa a
relação leitura/escrita, X representa a localidade, P representa a popularidade
e L representa a latência de rede.}
\label{tab:estudo_para_fatores_de_carga_de_trabalho}.  \end{center} \end{table}

Como esperado, localidade e latência impactam os modos em geral. Uma observação
é o fato de incusive ind1 ser afetada por latência. Isso provavelmente vem do
fato de mecanismos de replicação e correção de leitura serem afetados. Assim, os
níveis são:

\begin{itemize}

\item Localidade: 0,5 (origem dos acessos para cada objeto distribuídos
igualmente entre centros de dados) e 0,9 (90\% dos acessos para cada objeto
originado em um centro de dados e os 10\% restantes originados no outro centro
de dados. \end{itemize}

Apesar de alguns modos aparentemente sofrerem impacto considerável da relação
leitura/escrita, há indícios de que esse impacto na verdade é consequência da
relação entre requisições locais e remotas. O modo ind1 tem tanto leituras
quanto escritas locais e a relação leitura/escrita e suas interações com outros
fatores impacta pouco esse modo. No modo lt\_rec tanto leituras quanto escritas
são locais ou remotas dependendo da localidade e a relação leitura/escrita não
impacta esse modo. O modo ind2 tem todas as leituras locais e metade das
escritas remotas. Assim, se a relação leitura/escrita muda a relação entre
requisições locais e remotas muda proporcionalmente. Como esperado, esse modo é
impactado pela relação leitura/escrita.  O mesmo vale para lt\_qqer que tem
todas as leituras locais e escritas dependendo da localidade. Esse modo também
sofre impacto da relação leitura/escrita.

Caso o mecanismo de armazenamento fosse disco ao invés de memória, a relação
leitura/escrita provavelmente sofreria impacto de fato. Isso porque escritas
implicariam no tempo de disco enquanto leituras poderiam ser mais rápidas no
geral pelo fato de uma parte delas serem servidas a partir do cache de disco.
Mas como não é esse o caso, a diferença relevante é a relação entre requisições
locais e remotas.

Percebe-se em todos os casos impacto praticamente nulo de popularidade. Talvez
em uma situação em que o sistema recebesse uma carga maior, como no caso de um
teste de stress, esse fator passasse a ser relevante. Como não é o caso, ele foi
desconsiderado e fixado no valor que simplifica o entendimento dos resultados.

Os valores fixados dos fatores desconsiderados foram:

\begin{itemize} \item Distribuição de operações: 2:1

\item Popularidade dos objetos acessados: uniforme (todos os objetos são
acessados em média a mesma quantidade de vezes) \end{itemize}

%% ------------------------------------------------------------------------- %%
\section{Ameaças à validade} \label{sec:ameacas_a_validade}

O controle da latência para caracterizar uma WAN é uma simplificação. Existem
outros fatores em uma WAN que afetam o desempenho de um sistema executando nela,
como limitações na largura da banda disponível, congestionamento, perda de
pacotes e explosões de tráfego. Os resultados obtidos podem ser diferentes em
uma WAN real, sujeita a esses fatores.

O Riak usa uma arquitetura muito semelhante à descrita no artigo sobre o Dynamo.
Com isso, os modelos de consistência usados nos experimentos podem apresentar
outros resultados em sistemas que usem outras arquiteturas, embora a
implementação de cada modelo de consistência é bastante isolada dos outros
componentes da arquitetura.

Por limitação de tempo e recursos algumas variáveis que podem alterar os
resultados desse trabalho foram desconsideradas ou fixadas. Esse é o caso de
todas as variáveis de controle e constantes, que poderiam ser trabalhadas como
variáveis independentes. Com isso, os resultados dos experimentos podem ser
diferentes caso sejam usados, por exemplo, um fator de replicação ou uma
quantidade de centros de dados diferentes. Em particular, testes de
escalabilidade serão realizados para entender a influência do tamanho do sistema
nos resultados.

Os experimentos consideram que todos os nós sempre operam sem falhas. Os
resultados de experimentos com o sistema operando em algum modo de falha (desde
a falha de um nó até de um centro de dados inteiro) devem ser diferentes dos
obtidos nesse estudo.
