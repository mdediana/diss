%% ------------------------------------------------------------------------- %%
\chapter{Parâmetros e Fatores} \label{cap:parametros_e_fatores}

A etapa seguinte à definição do estudo e dos aspectos técnicos lidou com os
parâmetros e fatores usados nos experimentos finais. Primeiramente, a lista de
parâmetros foi levantada. Dessa lista, alguns parâmetros já foram imediatamente
fixados por impossibilidade de variá-los, por limitação de recursos ou por não
serem foco do estudo. A seleção inicial de fatores foi formada pelos parâmetros
restantes. Como essa seleção era grande, experimentos foram usados para
identificar os fatores mais influentes para o estudo. Os fatores menos
influentes foram tratados como parâmetros e tiveram seus valores fixados. Os
fatores mais influentes foram usados nos experimentos finais, que usaram um
projeto de experimentos fatoriais completo. 

Os tipos de experimentos usados tanto na seleção dos fatores quanto no estudo
final são explicados na seção \ref{sec:tipos_de_experimentos}. A lista de
parâmetros inicialmente levantada é apresentada na seção
\ref{sec:lista_de_parametros}. Os parâmetros fixados e seus valores estão na
seção \ref{sec:parametros_fixados}. Por fim, a seleção dos fatores e os
experimentos que levaram a ela estão na seção \ref{sec:selecao_dos_fatores}.

%% ------------------------------------------------------------------------- %%
\section{Tipos de Experimentos} \label{sec:tipos_de_experimentos}

%TODO: talvez citar o outro livro de performance
São alguns os tipos de experimentos que podem ser usados em um estudo
experimental. A escolha entre eles se dá principalmente pelo balanço entre
recursos utilizados (tempo, dinheiro, energia, etc) e quantidade de informação
adquirida -- quanto mais recursos são gastos, maior é a quantidade de informação
adquirida.

Experimentos fatoriais consistem da combinação de dois ou mais fatores em cada
experimento que compõe o estudo. Existem dois tipos principais de projetos de
experimentos fatoriais: completo e fracionado \cite{Jain1991}.

Um projeto de experimentos fatoriais completo é constituído por experimentos com
todas as combinações possíveis de todos os níveis de todos os fatores. Assim, a
quantidade total de experimentos é dada por:

$n = \prod_{i=1}^k{n_i}$,

onde k é o número de fatores e $n_i$ é a quantidade de níveis do
i$^{\textrm{\'esimo}}$ fator.

Esse tipo de projeto de experimentos tem a vantagem de identificar com precisão
a influência de todos os fatores e suas interações nas variáveis de resposta.
Mas quanto maior a quantidade de fatores e de níveis em um estudo experimental,
maior a quantidade de recursos necessários para sua execução. Normalmente os
fatores não afetam igualmente as variáveis de resposta, pelo contrário, é comum
alguns poucos fatores explicarem a maior parte dos efeitos na resposta.

Para esses casos, utiliza-se o projeto de experimentos fatoriais fracionado para
fazer uma triagem dos fatores, identificando quais deles são os mais influentes.
Nesse tipo de experimento, utiliza-se apenas uma parte de todos os experimentos
definidos no projeto de experimentos fatoriais completo. Um tipo particular de
projeto de experimentos fatoriais fracionado é o 2\textsuperscript{k}. Nesse
tipo, todos os fatores inicialmente selecionados são usados, mas apenas com dois
níveis cada (normalmente o mínimo e o máximo), resultando em um total de
2\textsuperscript{k} experimentos.

Este trabalho usou alguns projetos de experimentos fatoriais fracionados para
seleção de fatores e níveis e um projeto de experimentos fatoriais completo para
o estudo final. O procedimento da seleção de fatores a partir de um projeto de
experimentos fatoriais fracionados 2\textsuperscript{k} é descrito a seguir.

\subsubsection{Projeto de experimentos fatoriais fracionados
2\textsuperscript{k}}

Um projeto de experimentos fatoriais fracionados 2\textsuperscript{k} é composto
por 2\textsuperscript{k} experimentos que por sua vez resultam em
2\textsuperscript{k} medições de desempenho. Dadas essas medições, o desempenho
é expresso por um modelo de regressão não-linear da forma:

$y = q_0 + q_Ax_A + q_Bx_B + q_Cx_C + ... + q_{AB}x_Ax_B + q_{AC}x_Ax_C +
q_{BC}x_Bx_C... + q_{ABC}x_Ax_Bx_C + ...$,

onde $y$ é o desempenho medido, $q_0$, $q_A$, $q_B$, etc são os coeficientes do
modelo e $x_A$, $x_B$, $x_C$, etc representam respectivamente os níveis dos
fatores A, B, C, etc. Os termos compostos pela multiplicação de dois ou mais
fatores representam as interações entre os fatores em questão.

Feito o modelo, define-se para cada fator uma relação entre seus níveis e os
valores -1 ou 1. Por exemplo, pode-se definir que a latência de 100 ms valerá -1
e a latência de 300 ms valerá 1. Fazendo a substituição dos níveis por esses
valores, tem-se um sistema de 2\textsuperscript{k} equações e
2\textsuperscript{k} variáveis (os coeficientes).

Com os coeficientes, calcula-se a variação total de y (ou soma total dos
quadrados) a partir da equação:

$STQ = SQA + SQB + SQC + ... + SQAB + SQAC + SQBC + ... + SQABC + ...$,

onde cada $SQX$ é dado por:

$SQX = 2^kq_X$

Cada $SQX$ é a porção da variação total explicada pelo fator ou pela interação
entre fatores X. A partir disso, é possível finalmente calcular a fração da
variação explicada por cada X por:

$FSQX = SQX / STQ$

Ordenando os $FSQX$s é possível descobrir quais são os fatores e interações
entre eles que mais afetam os resultados dos experimentos.

%% ------------------------------------------------------------------------- %%
\section{Lista de Parâmetros} \label{sec:lista_de_parametros}

Os parâmetros foram divididos em três categorias: parâmetros de sistema, de rede
e de carga de trabalho. As justificativas para a escolha de um parâmetro nem
sempre consideraram todas as situações possíveis em que ele afeta o desempenho
do sistema, em alguns casos uma única razão foi considerada suficiente para
tratá-lo como parâmetro.

Os parâmetros de sistema levantados foram:

\paragraph{Modelo de consistência}Objeto do estudo.
  
% Chequei app.config e vm/args
\paragraph{Configuração de hardware (CPU, memória, disco e placa de rede)}O
tempo de resposta de uma requisição é dado pela soma dos seus tempos de envio,
de processamento e de recebimento. CPU, memória e disco afetam o tempo de
processamento, a placa de rede afeta os tempos de envio e recebimento.

\paragraph{Mecanismo de armazenamento -- memória ou disco}O desempenho da
memória é ordens de grandeza maior que o desempenho de um disco\footnote{SSDs
são uma exceção, mas eles não estavam disponíveis no ambiente dos
experimentos.}. Em um sistema de armazenamento, o desempenho de leituras em
disco pode ser próximo do desempenho de leituras em memória dependendo do
tamanho do cache de disco e do conjunto de dados armazenados. Para escritas, o
desempenho em disco é sempre menor.

\paragraph{Quantidade de nós do sistema}A menos que um sistema distribuído
apresente escalabilidade linear, quanto mais nós ele tiver, menor será o
desempenho por nó.
% citar contenção e coerência - gcap

\paragraph{Quantidade de centros de dados}A menos que as redes que ligam os
centros de dados tomados dois a dois tenham as mesmas características, o tempo
de resposta de uma dada requisição é dependente de sua origem e destino.

\paragraph{Capacidade dos centro de dados}A menos que todos os centros de dados
possuam as mesmas capacidades agregadas de processamento, armazenamento e
largura de banda, a vazão de cada centro de dados é diferente, o que se reflete
no desempenho das requisições.

\paragraph{Quantidade de instâncias do benchmark}Uma quantidade muito pequena de
instâncias pode se tornar o gargalo do experimento, uma quantidade muito grande
pode resultar em sobrecarga do sistema. Em ambos os casos o desempenho medido do
sistema não corresponde a suas condições normais de operação.

\paragraph{Quantidade de threads por instância do benchmark}Mesma justificativa
que para quantidade de instâncias do benchmark.

\paragraph{Quantidade de objetos armazenados}A quantidade de objetos armazenados
influencia o volume de dados no disco e no cache de disco (caso disco seja o
mecanismo de armazenamento utilizado). Além disso, dada uma taxa de chegada de
requisições constante, a quantidade de objetos armazenados também afeta a
probabilidade de conflitos, já que quanto menos objetos estiverem armazenados no
sistema, maior a chance de um dado objeto ser requerido.

\paragraph{Tamanho dos objetos armazenados}O tamanho dos objetos armazenados
influencia o volume de dados no cache de disco, caso seja esse o mecanismo de
armazenamento utilizado. No caso de armazenamento em memória, o tamanho dos
objetos influencia a fragmentação da memória, o que também afeta o desempenho.
Além disso, o tamanho dos objetos afeta o comportamento da comunicação TCP, dado
que objetos muito grandes precisam ser divididos em mais de um pacote e objetos
muito pequenos resultam em uma carga paga proporcionalmente menor. Isso tende a
se refletir como diminuição da vazão e/ou aumento do tempo de resposta das
requisições.

\paragraph{Algoritmo de particionamento}O algoritmo de particionamento define a
distribuição dos objetos pelos nós. No caso de uma distribuição desbalanceada,
nós com mais objetos tendem a receber uma maior quantidade de requisições e ter
seu desempenho prejudicado com relação a outros.

\paragraph{Fator de replicação ($N$)}Quanto maior o fator de replicação, maior o
tráfego de rede, o que tende a causar uma diminuição do desempenho do sistema.

\paragraph{Configuração de replicação -- $R$ e $W$ (para consistência em momento
indeterminado)}Em um ambiente com mais de um centro de dados, a configuração de
replicação afeta a proporção entre requisições locais e remotas. Por exemplo, se
todo centro de dados possui uma e apenas uma réplica de cada objeto, todas as
leituras são locais para R = 1 e remotas para R = 2. Dessa forma, a configuração
de replicação afeta o tempo de resposta das requisições.

\paragraph{Limiar de migração (para consistência na linha do tempo)}O limiar de
migração é o valor no qual uma réplica mestra migra de um centro de dados para
outro. Dependendo da carga de trabalho, valores diferentes do limiar resultam em
proporções entre requisições locais e remotas diferentes, afetando assim o tempo
de resposta médio das requisições.

\paragraph{Protocolo de acesso}Um protocolo mais eficiente, que envia menos
metadados, por exemplo, resulta em desempenho das requisições mais alto.

\paragraph{Nível de log}O nível de log afeta a quantidade de escritas em disco,
o que por sua vez afeta o desempenho do sistema.

Os parâmetros de rede levantados foram:

\paragraph{Configuração de hardware dos elementos de rede intermediários
(switches, roteadores, etc)}A configuração dos elementos de rede intermediários
está relacionada à largura de banda disponível, tamanho dos buffers de entrada e
saída, capacidade de processamento de requisições, entre outros. Dessa forma,
sistemas se comunicando através desses elementos têm seu desempenho afetado por
eles. 

\paragraph{Topologia da rede}Várias características da topologia de rede afetam
o desempenho do sistema, por exemplo, a quantidade de segmentos de rede pelos
quais uma requisição precisa passar para chegar ao destino afeta o seu tempo de
resposta.

\paragraph{Latência da LAN}O tempo de resposta de uma requisição é dado pela
soma dos seus tempos de envio, de processamento e de recebimento. A latência
afeta os tempos de envio e recebimento.

\paragraph{Variação da latência da LAN}A latência em uma rede não é constante,
dado que dentre suas causas está a dinâmica da rede. Por exemplo, rajadas de
tráfego podem aumentar a fila de pacotes a ser processados em um roteador, o que
se manifesta como aumento de latência em todos os fluxos passando por ele. Após
um período de tempo, o roteador volta a sua operação normal e a latência
diminui. Esse exemplo ilustra outra característica de variações de latência, que
é o fato de existir correlação entre os valores de latência observados ao longo
do tempo.
%TODO: citar paper mdcc sobre variação de latência e
%http://amplab.cs.berkeley.edu/2011/10/20/latencies-gone-wild/

\paragraph{Latência da WAN}Mesma justificativa que para latência da LAN. Um
agravante é que latências em WANs são ordens de grandeza maiores que em LANs já
que as distâncias percorridas pelos pacotes são muito maiores.

\paragraph{Variação da latência da WAN}Mesma justificativa que para variação de
latência na LAN. Um agravante é que requisições em uma WAN atravessam mais
segmentos de rede, portanto são mais suscetíveis à variação da latência.  Quando
a variação é muito grande e a latência atinge valores muito grandes,
transmissores podem interpretar a demora na recepção de ACKs como perda de
pacotes, diminuindo ainda mais o desempenho.

\paragraph{Taxa de perda de pacotes na WAN}Perda de pacotes acontece, por
exemplo, quando um elemento intermediário falha ou está sobrecarregado e
descarta pacotes. Quando isso acontece, controles de congestão como início
lento, por exemplo, entram em ação no transmissor para diminuir a vazão através
da diminuição do tamanho da janela de transmissão. Além disso, o mecanismo
padrão de retransmissão do TCP aumenta exponencialmente o tempo entre
tentativas, portanto quanto mais pacotes perdidos, maior é o tempo necessário
para os pacotes serem re-transmitidos.

\paragraph{Taxa de duplicação de pacotes na WAN}Pacotes duplicados afetam a
comunicação TCP principalmente por gerarem tráfico e processamento
desnecessários, o que pode causar diminuição de vazão e/ou aumento do tempo de
resposta das requisições.
% RFC 793 - Transmission Control Protocol, Section 1.5

\paragraph{Taxa de corrupção de pacotes na WAN}O tratamento dado pelo TCP para
pacotes corrompidos é o descarte no receptor. Do ponto de vista do transmissor,
isso se manifesta como perda de pacotes, com as mesmas consequências.
% Improving TCP Performance: Identifying Corruption Based Packet Loss

\paragraph{Taxa de pacotes fora de ordem na WAN}Para todo pacote recebido, mesmo
que fora de ordem, o receptor envia um ACK informando qual o pacote esperado.
Por exemplo, se o receptor receber os pacotes 1, 4 e 5, ele envia três ACKs
informando que está esperando o pacote 2. O transmissor apenas ignora os
primeiros ACKs duplicados, mas após um determinado número (normalmente três) o
mecanismo de retransmissão rápida considera que o pacote informado nos ACKs foi
perdido e o retransmite imediatamente, sem esperar o timeout. Como existe perda,
um controle de congestão entra em ação. O controle em questão é a recuperação
rápida, que causa diminuição da vazão da rede (menor que a causada pelo início
lento). Por último, pacotes fora de ordem ocupam espaço no buffer do receptor, o
que pode afetar seu desempenho.
% https://tools.ietf.org/html/rfc2581#section-3.2 A Study of Internet Packet
% Reordering
% http://www.tcpipguide.com/free/t_TCPCongestionHandlingandCongestionAvoidanceAlgorit-3.htm

\paragraph{Algoritmo de controle de congestionamento}O algoritmo de controle de
congestionamento é responsável pelo dimensionamento da janela de transmissão.
Quanto maior a janela de transmissão, maior a quantidade dados em trânsito e
maior a vazão do sistema.

\paragraph{Produto Banda-Latência (\emph{Bandwidth Delay Product} -- BDP)}A
quantidade de dados em trânsito em uma conexão TCP é definida pelo Produto
Banda-Latência. Assim, dada uma largura de banda, quanto maior a latência da
rede, maior é a quantidade de pacotes em trânsito. Um gargalo comum nesse caso é
o tamanho dos buffers de transmissão e recepção nas pontas, o que pode diminuir
a vazão e/ou aumentar o tempo de resposta das requisições.

Taxas de perda, de duplicação, de corrupção e de pacotes fora de ordem não foram
consideradas para LAN pois ocorrem com menor frequência e geram pouco impacto
nesse tipo de rede. Em WANs, esses fenômenos estão relacionados a uma maior
quantidade de nós intermediários (incluindo roteadores e proxies) e redes
heterogêneas que os pacotes atravessam.

Os parâmetros de carga de trabalho levantados foram:

\paragraph{Relação leitura/escrita}Escritas normalmente são mais lentas que
leituras, portanto a relação leitura/escrita afeta o tempo de resposta médio das
requisições. Além disso, a consistência na linha do tempo pode apresentar
desempenho mais baixo em um cenário de escrita intensiva, pois a réplica mestre
pode se tornar um gargalo. Outro ponto a considerar é que a probabilidade de
haver conflitos entre réplicas aumenta com o aumento da taxa de escritas em um
sistema que usa consistência em momento indeterminado, que pode sofrer um
impacto no seu desempenho devido à execução de seus algoritmos de resolução de
conflitos.

\paragraph{Popularidade dos objetos}Em muitas aplicações a popularidade dos
objetos não é uniforme, alguns são mais acessados do que outros. Um exemplo é
uma loja virtual em que o interesse dos clientes pelos produtos tende a obedecer
uma lei de potência \cite{Anderson2006}. A existência de objetos muito populares
pode prejudicar o desempenho de um modelo de consistência como a consistência na
linha do tempo, em que a réplica mestre pode se tornar um gargalo nas escritas.

\paragraph{Localidade}Cooper et al. notam um alto índice de localidade nos
acessos aos objetos dos sistemas no Yahoo! \cite{Cooper2008}. Em uma análise
feita no período de uma semana, foi observado que em média 85\% das escritas a
determinado objeto vinham do mesmo centro de dados. Isso acontece por exemplo em
uma rede social, em que os usuários costumam tanto acessar a aplicação e quanto
ter a maior parte de seus contatos na mesma localização geográfica -- usuários
brasileiros tendem a acessar o sistema do Brasil e a maioria de seus contatos é
brasileira. Nesse caso, é possível evitar requisições entre centros de dados se
os objetos são particionados no sistema considerando a localização geográfica
dos acessos mais recentes. A implementação de consistência na linha do tempo
usada neste estudo implementa migração de réplica mestre por esse motivo.

\paragraph{Taxa de chegada de requisições}Mesma justificativa que para
quantidade de instâncias do benchmark.

\paragraph{Versão requisitada nas leituras (para consistência na linha do
tempo)}Leituras de ``qualquer versão'' apresentam tempo de resposta menor que
leituras de ``versão mais recente'' pois têm maior probabilidade de ser
atendidas localmente. No caso onde existe garantia de haver ao menos uma réplica
por centro de dados, as leituras de ``qualquer versão'' só não são atendidas
localmente em caso de falha.

Alguns parâmetros dessa lista foram fixados, as justificativas e seus valores
estão descritos na seção \ref{sec:parametros_fixados}. Os restantes foram
considerados fatores e o tratamento dado a eles está na seção
\ref{sec:selecao_dos_fatores}.

%% ------------------------------------------------------------------------- %%
\section{Parâmetros Fixados} \label{sec:parametros_fixados}

Um motivo para fixar um parâmetro é a impossibilidade de variá-lo. Por exemplo,
um estudo pode estar limitado apenas às configurações de hardware disponíveis
para o pesquisador. Um outro motivo é saber de antemão que, apesar de afetar o
desempenho do sistema, o parâmetro é pouco relevante para o estudo em questão --
caso contrário, ele seria considerado um fator.

Favorecer simetria e homogeneidade nos experimentos foi um princípio que guiou
algumas das decisões abaixo, pois isso simplificou a implementação e a análise
dos experimentos. A desvantagem disso é a possibilidade de perda de realismo,
dado que sistemas distribuídos de larga escala não costumam ser totalmente
simétricos nem homogêneos.

Como o foco do estudo era a operação do sistema sobre WAN, fatores relacionados
a rede e carga de trabalho eram prioridade. Por isso, sempre que possível,
parâmetros de sistema foram fixados, mesmo quando se sabia que eles afetavam o
desempenho.

A configuração de hardware e o mecanismo de armazenamento são os únicos
parâmetros cuja decisão envolveu experimentos, descritos na subseção
\ref{sec:aglomerado_e_mecanismo_de_armazenamento}.  Os outros parâmetros estão
descritos na subseção \ref{sec:parametros_restantes}.

%% ------------------------------------------------------------------------- %%
\subsection{Aglomerado e mecanismo de armazenamento}
\label{sec:aglomerado_e_mecanismo_de_armazenamento}

As configurações de hardware estavam limitadas às oferecidas pelo Grid5000. Cada
aglomerado do Grid5000 possui todos os nós com mesma configuração de hardware, e
aglomerados diferentes são compostos por hardware com configurações diferentes.
Com isso, decidiu-se restringir os experimentos a um único aglomerado, de forma
a garantir homogeneidade de hardware. Além disso, do ponto de vista operacional,
o uso de um único aglomerado simplificou a execução dos experimentos. Dado isso,
alguns experimentos foram feitos para decidir qual aglomerado seria usado.

Os aglomerados do Grid5000 considerados foram parapluie, sol e suno. A descrição
do hardware e a quantidade de nós de cada um deles se encontra na Tabela
\ref{tab:aglomerados_do_grid5000}.

\begin{table}[!h] \begin{center}

\begin{tabular}{|c|c|c|c|c|} \hline

Aglomerado & CPU & Memória & Disco & Nós \\ \hline

parapluie & AMD Opteron 6164 HE 1.7 Ghz & 48 GB & SATA / 250 GB & 40\\ \hline

sol & AMD Opteron 2218 2.6 GHz & 4 GB & SATA / 250 GB & 50\\ \hline

suno & Intel Xeon E5520 2.26 GHz & 32 GB & SAS/RAID-0 / 2x300 GB & 45\\ \hline

\end{tabular}

\caption{Aglomerados do Grid5000.} \label{tab:aglomerados_do_grid5000}

\end{center} \end{table}

Os experimentos mostraram diferenças consideráveis no desempenho do Riak entre
esses aglomerados. Considerando que os experimentos eram limitados por E/S (e
não por CPU) e que não havia gargalo de rede, decidiu-se checar o desempenho dos
discos em cada aglomerado. A especificação do hardware mostrava tipos de discos
diferentes entre aglomerados.  Dada essa diferença, experimentos foram
realizados para quantificá-la e tomar uma decisão mais informada.

Testes de desempenho de disco foram realizados em cada aglomerado. Para medição
do desempenho, os experimentos usaram o hdparm para acesso sequencial e o
seeker\footnote{\url{http://www.linuxinsight.com/how\_fast\_is\_your\_disk.html}}
para acesso aleatório. Os resultados confirmaram as grandes diferenças de
desempenho, como pode ser visto na Tabela
\ref{tab:comparacao_de_desempenho_de_acessos_dos_discos_entre_aglomerados}.

\begin{table}[!h] \begin{center}

\begin{tabular}{|c|c|c|c|c|c|} \hline

Aglomerado & Sequencial (MB/s) & Aleatório (seeks/s) & Aleatório (em ms) \\
\hline

parapluie & 103,9 & 77 & 13,0 \\ \hline

sol & 59,8 & 78 & 12,7 \\ \hline

suno & 242,7 & 131 & 7,6 \\ \hline

\end{tabular}

\caption{Comparação de desempenho de acessos dos discos entre aglomerados.}
\label{tab:comparacao_de_desempenho_de_acessos_dos_discos_entre_aglomerados}

\end{center} \end{table}

Além do tipo de disco, um outro ponto considerado foi o cache de disco. Em
sistemas Linux, todo a memória livre é automaticamente usada como cache de
disco. Dado isso, existiam três opções para a execução dos experimentos com
relação ao mecanismo de armazenamento, considerando que um tamanho do banco de
dados podia ser escolhido de forma a manter todos os dados em memória:

\begin{enumerate} \item Dados em disco e cache limpo no início dos experimentos:
O cenário seria mais real, mas mais difícil de analisar pois os efeitos do disco
e da memória sobre o desempenho do sistema se misturariam. Além disso, o efeito
do preenchimento do cache seria dependente da duração do experimento, quanto
mais longo o experimento maiores as chances de as leituras encontrarem os
objetos no cache.

\item Dados em cache no início dos experimentos: O disco seria predominantemente
usado apenas para escritas e as leituras seriam servidas a partir do cache. Com
isso, o desempenho das escritas seria dependente do disco, enquanto o das
leituras não.

\item Dados em memória: O Riak podia ser configurado para funcionar como um
banco de dados em memória, eliminando definitivamente o efeito do disco.
\end{enumerate}

A terceira opção foi a escolhida. Realizar os experimentos com banco de dados em
memória geraria resultados mais precisos e de interpretação mais simples por
descartar a influência de desempenho do disco. Em princípio, os resultados podem
parecer menos realistas e aplicáveis, mas na prática eles são tão limitados
quanto com o uso de disco, já que nesse caso os resultados seriam afetados pelo
tipo de disco e pela relação entre o tamanho do banco de dados e a memória
livre. Um exemplo é a comparação de suno com parapluie, em que o primeiro
aglomerado possui discos com taxas de acesso maiores que a largura de banda da
rede (1 Gb/s) -- o gargalo em um caso seria a rede, em outro caso seria o disco.
Além disso, efeitos do cache de disco tornariam os resultados ainda mais
particulares e difíceis de ser generalizados.  Dessa forma, ao adotar memória
como mecanismo de armazenamento, eliminou-se os efeitos das interações entre
rede, disco e cache de disco e a análise foi focada apenas na rede. Trabalhos
futuros podem estudar o efeito de disco e cache de disco no desempenho (seção
\ref{sec:trabalhos_futuros}).

Ao definir que o sistema usaria memória como mecanismo de armazenamento, a
configuração de hardware do aglomerado passou a ser menos relevante, dado que
todos os aglomerados oferecem nós com capacidade de processamento (CPU)
razoável, ao menos 4 GB de memória e placas de rede de 1 Gb/s. O aglomerado sol
foi escolhido predominantemente por questões operacionais -- ele tem um tamanho
suficiente (47 nós) e a concorrência pela reserva de seus nós é baixa.

Dessa forma, os valores fixados foram:

\begin{itemize}

\item Aglomerado: sol

\item Mecanismo de armazenamento: memória

\end{itemize}

A topologia do aglomerado escolhido é constituída por cada um dos nós ligado
diretamente a um switch Foundry FastIron Super X.

%% ------------------------------------------------------------------------- %%
\subsection{Parâmetros restantes} \label{sec:parametros_restantes}

Os parâmetros inicialmente levantados que não foram considerados fatores foram
fixados nos seguintes valores:

\paragraph{Quantidade de centros de dados:}2. Esse valor simplificou a análise
pois resultou em apenas um segmento de WAN nos experimentos. Além disso, ele
tornou a modificação do algoritmo de particionamento do Riak mais simples (ver
seção \ref{sec:sistema_de_armazenamento}).

\paragraph{Capacidade do centro de dados:}Os centros de dados têm a mesma
capacidade, pois ambos possuem a mesma quantidade de nós e os nós têm a mesma
configuração de hardware, resultando em um sistema simétrico e homogêneo.

\paragraph{Algoritmo de particionamento das chaves:}O algoritmo padrão do Riak
foi usado (espalhamento consistente), configurado com 512 partições. Esse valor
satisfaz as duas condições descritas na documentação do Riak: ser uma potência
de 2 e resultar em ao menos 10 partições por nó (caso os experimentos finais
usassem mais do que 64 nós esse valor teria sido aumentado).

\paragraph{Fator de replicação ($N$):}3. Valor que resulta em um balanço
razoável entre desempenho, disponibilidade e durabilidade em aplicações reais
\cite{DeCandia2007}.

\paragraph{Limiar de migração (para consistência na linha do tempo):}3.  Valor
padrão usado pelo PNUTS \cite{Cooper2008}.

\paragraph{Interface de acesso:}HTTP. O Riak também suporta Protocol
Buffers\footnote{\url{http://code.google.com/p/protobuf/}}, mais eficiente que a
interface HTTP. Apesar disso, a opção foi pelo uso de HTTP pois eficiência da
interface não era tão relevante para os experimentos dado que a carga sobre o
sistema era controlada, mas implementar os parâmetros da consistência na linha
do tempo na interface HTTP era mais simples.

\paragraph{Nível de log:}WARN. Alguns experimentos exploratórios mostraram perda
de desempenho quando o  nível de log estava em INFO. De qualquer forma, como a
carga sobre o sistema era controlada, esse parâmetro era pouco relevante.

\paragraph{Topologia da rede:}Topologia da rede do aglomerado usado no estudo. A
topologia do aglomerado consistia apenas de nós ligados diretamente a um switch.

\paragraph{Largura de banda nos elementos intermediários (switches, roteadores,
etc):}Largura de banda no aglomerado utilizado no estudo. Esse valor é dado pelo
switch em que os nós estão ligados (ver subseção
\ref{sec:aglomerado_e_mecanismo_de_armazenamento}). Testes mostraram que não
existiam gargalos no switch mesmo nos experimentos com maior consumo de banda.

\paragraph{Latência da LAN:}Latência do aglomerado utilizado no estudo.  Uma
medição com 60 amostras espaçadas em 5 s no aglomerado mostrou 167 $\mu$s.
% ping -i 5 -c 60 sol-20

\paragraph{Variação de latência da LAN:}Variação de latência do aglomerado
utilizado no estudo. A mesma medição feita para a latência mostrou desvio padrão
de 90 $\mu$s.

\paragraph{Taxa de chegada de requisições}15 operações/s para cada thread de
cada instância do benchmark. Esse valor foi usado pois esse parâmetro se
relaciona diretamente com a quantidade de threads por instância do benchmark.
Assim, considerando que threads por instância foi inicialmente considerado um
fator, a taxa de chegada foi fixada.

%% ------------------------------------------------------------------------- %%
\section{Seleção dos Fatores} \label{sec:selecao_dos_fatores}

Os parâmetros que não foram fixados consequentemente eram candidatos a fatores
nos experimentos finais. Como a lista de fatores ainda continha muitos deles,
precisava ser reduzida, o que foi feito através de experimentos fatoriais
fracionados. Eles foram divididos em dois grupo, o primeiro constituído por
fatores de sistema, que teriam baixa prioridade para entrar nos experimentos
finais, e o segundo constituído pelos fatores restantes, de alta prioridade.

Os fatores do grupo de baixa prioridade eram:

\begin{itemize}

\item Quantidade de nós do sistema

\item Quantidade de instâncias do benchmark

\item Quantidade de threads por instância do benchmark

\item Quantidade dos objetos armazenados

\item Tamanho dos objetos armazenados.

\end{itemize}

Os fatores do grupo de alta prioridade eram:

\begin{itemize}

\item Modelo de consistência

\item Latência da WAN

\item Variação da latência da WAN

\item Taxa de perda de pacotes na WAN

\item Taxa de duplicação de pacotes na WAN

\item Taxa de corrupção de pacotes na WAN

\item Taxa de pacotes fora de ordem na WAN

\item Algoritmo de congestionamento

\item Produto Banda-Latência (\emph{Bandwidth Delay Product} -- BDP)

\item Relação leitura/escrita

\item Popularidade dos objetos

\item Localidade

\end{itemize}

Uma abordagem possível para a seleção final de fatores seria agrupar todos os
fatores levantados em um único projeto de experimentos fatoriais
2\textsuperscript{k}. O problema é que mesmo com apenas 2 níveis por fator, a
quantidade final de experimentos seria proibitiva, dado que a quantidade de
fatores era 17.

A opção adotada para lidar com o excesso de fatores foi dividi-los em grupos
menores e realizar experimentos para cada grupo. O principal problema de fazer
essa separação é o fato de a comparação da importância entre fatores de grupos
diferentes ser perdida. Por exemplo, se houvesse interação entre localidade e
quantidade de nós do sistema e eles não fizessem parte do mesmo estudo, essa
informação seria perdida. Além disso, mesmo que um grupo fosse constituído
apenas por fatores pouco influentes, um ou mais deles apareceriam com valores de
influência altos, o que praticamente invalidaria o processo de seleção.
Analisando os casos suscetíveis a esse problema, percebeu-se que o maior risco
era ignorar comparações e/ou interações com fatores de rede. Dado isso, a
abordagem adotada foi usar a latência, fator que já era sabido ser influente (e
comprovado experimentalmente depois), como um representante da rede. A partir
dessa abordagem foi possível concluir, por exemplo, que apesar de o tamanho dos
objetos armazenados aparecer como fator influente no estudo fatorial para ele,
desconsiderá-lo no estudo final não era uma grande ameaça à validade pois a
latência de rede era um fator bem mais relevante.

Existem outras situações em que desconsiderar um fator que aparece como
influente não implica necessariamente em ameaça à validade. Experimentos
fatoriais mostram a influência relativa de cada fator e cada interação entre
fatores. Nesse tipo de análise, o total de todas as influências relativas deve
ser sempre 100\%. Por isso, mesmo que todos os fatores afetem pouco a resposta,
um ou mais vão aparecer nos experimentos fatoriais com influência alta. Assim,
também foram calculados os coeficientes de variabilidade\footnote{O coeficiente
de variação é a divisão do desvio padrão pela média e é uma maneira de
representar a variabilidade dos dados desconsiderando sua ordem de grandeza}
(CVs) para cada resultado de forma a estimar qual a importância daquele conjunto
de fatores e interações como um todo. Se o CV é baixo ao final de um estudo
fatorial, isso implica que nenhum daqueles fatores é influente, dado que todas
as combinações entre eles foram testadas e o desempenho variou pouco de um
experimento para o outro.

O tempo de resposta de requisições locais é da ordem de poucos milissegundos,
enquanto das requisições remotas é da ordem de centenas de milissegundos. Dessa
forma, as requisições remotas dominam a média já que são em geral duas ordens de
grandeza maiores que as locais. Por isso, a análise da maioria dos estudos é
feita por percentis em vez de médias -- percentis baixos representam requisições
locais e percentis altos representam requisições remotas. Também é feita a
distinção entre escritas e leituras dada a diferença de natureza dessas
operações.

Três fatores receberam um tratamento diferente ao longo do experimento: modelo
de consistência, configuração de replicação (para consistência em momento
indeterminado) e versão requisitada nas leituras (para consistência na linha do
tempo). Isso foi feito pois seus níveis influenciam na proporção de requisições
locais e remotas, fundamental para este estudo. Por isso, esses fatores foram
tratados como um único, chamado modo (subseção seguinte). Projetos de
experimentos fatoriais fracionados 2\textsuperscript{k} foram realizados para
cada um dos fatores restantes e estão descritos nas subseções subsequentes.

%% ------------------------------------------------------------------------- %%
\subsection{Modo} \label{sec:modo}

Os modos adotados foram:

\begin{itemize}

\item ind1: Consistência em momento indeterminado com $W$ = 1 e $R$ = 1

\item ind2: Consistência em momento indeterminado com $W$ = 2 e $R$ = 1

\item lt\_qqer: Consistência na linha do tempo com leituras de qualquer versão

\item lt\_rec: Consistência na linha do tempo com leituras da versão mais
recente

\end{itemize}

Todas as configurações usam $N = 3$ (ver seção \ref{sec:parametros_fixados}). O
algoritmo de particionamento garante que existe ao menos uma réplica em cada
centro de dados (ver subseção \ref{sec:sistema_de_armazenamento}). Assim,
existem sempre duas situações possíveis com relação à localização das réplicas
do ponto de vista do coordenador: uma local e duas remota ou duas locais e uma
remota. Dado isso, ind1 resulta em todas as leituras e escritas locais. ind2
resulta em todas as leituras locais e metade das escritas locais e a outra
metade remotas. lt\_qqer resulta em todas as leituras locais e a quantidade de
escritas dependente da localidade dos acessos. Finalmente, lt\_rec resulta tanto
em leituras quanto escritas dependentes da localidade.

Os modos foram escolhidos de forma a representar situações encontradas em
sistemas de produção e ao mesmo tempo limitar a quantidade de níveis. Assim,
consistência na linha do tempo com leituras de versões específicas não foi
considerada já que ela é um meio termo entre leituras de versão mais recente e
leituras de qualquer versão. Consistência em momento indeterminado com $W = 1$ e
$R = 2$ não foi considerada pois sua semântica é similar a $W = 2$ e $R = 1$,
mas teria seu desempenho prejudicado considerando que leituras predominam nas
relações leitura/escrita usadas nos experimentos (ver subseção
\ref{sec:fatores_de_carga_de_trabalho}).

Esses modos implicam em trocas além de desempenho e consistência. A principal é
durabilidade, que para ind2 é mais alta do que para os outros casos, em que a
confirmação de escrita de uma única réplica é suficiente.

%% ------------------------------------------------------------------------- %%
\subsection{Aquecimento} \label{sec:aquecimento}

Como localidade e popularidade eram fatores, apenas a inserção de objetos na
etapa de carga (seção \ref{sec:scripts_de_execucao_e_analise_dos_experimentos})
não era suficiente para que o sistema operasse em regime durante os experimentos
para a consistência na linha do tempo. Isso porque ao final da inserção, cada
objeto no banco de dados tinha recebido apenas um acesso de cada centro de
dados, nenhuma réplica mestre teria migrado por efeito da localidade até esse
momento. Por isso, o aquecimento era necessário durante a etapa de carga para a
consistência na linha do tempo.

O aquecimento era dado por uma quantidade de passos, cada passo fazendo uma
quantidade de acessos igual a quantidade de objetos armazenados no banco de
dados. Para saber quantos passos seriam necessários para cada combinação de
localidade e popularidade, um estudo foi realizado. O estudo executou diversos
passos e ao final de cada um mediu a quantidade de migrações ocorridas. O estudo
foi feito com 20000 objetos, mas quantidades maiores de objetos precisariam da
mesma quantidade de passos, a diferença é que eles seriam compostos por mais
requisições e, portanto, demorariam mais. Os resultados desse estudo estão na
Figura \ref{fig:aquecimento_do_sistema}.

\begin{figure}[!htb] \centering

\includegraphics[width=0.8\textwidth]{warmup.png}

\caption{Aquecimento do sistema.} \label{fig:aquecimento_do_sistema}
\end{figure}

A quantidade de migrações aumenta nos primeiros passos. Para localidade 0,5, a
quantidade de migrações estabiliza após o 3\textsuperscript{o} passo e a
popularidade não influencia. Já para localidade 0,9, a estabilização demora
cerca de 15 passos e as curvas são diferentes para popularidade apenas nos
primeiros passos. Com isso, a etapa de aquecimento nos estudos foi configurada
para usar uma quantidade de passos de acordo com a localidade. Os valores para
quantidade de passos configurados foram:

\begin{itemize}

\item Localidade 0,5: 3

\item Localidade 0,9: 17

\end{itemize}

%% ------------------------------------------------------------------------- %%
\subsection{Fatores de tamanho do sistema e benchmark}
\label{sec:fatores_de_tamanho_do_sistema_e_benchmark}

Este estudo foi feito para dimensionar o tamanho do sistema e do benchmark.
Esses valores não só teriam impacto nos experimentos, mas também afetavam
questões operacionais, dado que quanto mais nós fossem usados, maiores as
dificuldades de conseguir reserv-a-los no Grid5000.

Os níveis inicialmente selecionados para o estudo foram:

\begin{itemize}

\item Quantidade de nós do sistema: 8 e 16

\item Quantidade de instâncias do benchmark: 2 e 4

\item Quantidade de threads em cada instância do benchmark: 32 e 64

\end{itemize}

A quantidade de partições usadas pelo Riak deve ser uma potência de 2 (ver seção
\ref{sec:parametros_fixados}). Uma forma simples de manter a simetria do sistema
foi adotar potências de 2 para os níveis da quantidade de nós no sistema,
garantindo assim a mesma quantidade de partições por nó. Na mesma linha, fazer o
mesmo para quantidade de instâncias da do benchmark e quantidade de threads por
instância foi uma forma de balancear a carga média tanto por nó quanto por
partição.

Este estudo usou modo lt\_rec, localidade de 50\% e latência de rede de 100 ms.
Esses valores foram escolhidos pois através deles obtém-se uma quantidade
balanceada de leituras e escritas locais e remotas. O resultado do estudo está
na Tabela \ref{tab:estudo_para_quantidade_de_nos_do_sistema}.

\begin{table}[!h] \begin{center} \begin{tabular}{|c|c|c|c|c|c|c|c|c|} \hline

Operação & Percentil & N & A & T & NA & NT & AT & NAT\\ \hline

leitura & 10 & 30 & 18 & 22 & 10 & 8 & 7 & 4 \\ \hline

leitura & 90 & 65 & 13 & 15 & 3 & 4 & 0 & 0 \\ \hline

escrita & 10 & 96 & 2 & 1 & 0 & 0 & 0 & 0 \\ \hline

escrita & 90 & 65 & 15 & 13 & 3 & 3 & 0 & 0 \\ \hline

\end{tabular} \caption[Estudo para quantidade de nós do sistema.]{Estudo para
quantidade de nós do sistema. N representa a quantidade de nós do sistema, A
representa a quantidade de instâncias do benchmark e T representa a quantidade
de threads usadas em cada instânca do benchmark.}
\label{tab:estudo_para_quantidade_de_nos_do_sistema} \end{center} \end{table}

Na maioria dos casos, o tamanho do sistema tem a maior influência nos resultados
e a quantidade de instâncias do benchmark e a quantidade de threads não são
desprezíveis, ainda mais ao se considerar as interações entre elas. Apesar
disso, esses fatores foram desconsiderados nos estudo final devido ao excesso de
fatores. Dessa forma, os valores fixados foram:

\begin{itemize}

\item Quantidade de nós do sistema: 16 (maior valor)

\item Quantidade de instâncias do benchmark: 4 (maior valor)

\item Quantidade de threads em cada instância do benchmark: 32 (menor valor)

\end{itemize}

Esses valores foram selecionados pois resultaram em uma configuração ``leve'',
evitando gargalos de rede e não sobrecarregando o sistema. Ao mesmo tempo, a
quantidade total de nós necessária para os experimentos se enquadrava nas
limitações de recursos do aglomerado.

Uma opção semelhante seriam 32 nós do sistema e 8 instâncias do benchmark,
resultando em um total de 40 nós. Isso não foi feito por questões operacionais.
Apesar de o aglomerado ter mais do que 40 nós, é muito comum alguns poucos nós
já estarem reservados por outros pesquisadores, além de alguns nós apresentarem
falhas no momento da implantação da imagem. Esse último problema levou o autor a
sempre reservar alguns nós além dos necessários para garantir a quantidade
mínima de nós para executar os experimentos. Além disso, alguns limites de uso
do Grid5000 são relativos ao tamanho do aglomerado usado. Por exemplo, uma das
regras diz que, entre 9:00 e 19:00, a quantidade de nós reservados multiplicada
pelo período da reserva deve ser menor ou igual a quantidade total de nós do
aglomerado multiplicada por 2 horas. Dessa forma, experimentos que precisassem
de 40 nós seriam mais difíceis de ser executados.

%% ------------------------------------------------------------------------- %%
\subsection{Fatores de banco de dados} \label{sec:fatores_de_banco_de_dados}

Este estudo foi feito para dimensionar o tamanho do banco de dados, que afeta o
uso de memória e de banda. Os experimentos também consideraram a latência como
fator para verificar a importância relativa entre esses fatores e a rede.

Os níveis inicialmente selecionados foram:

\begin{itemize}

\item Quantidade de objetos armazenados: 64000 e 256000

\item Tamanho dos objetos armazenados (bytes): 100 e 10000

\end{itemize}

Este estudo usou modo lt\_rec e localidade de 50\%.  Esses valores foram
escolhidos pois através deles obtém-se uma quantidade balanceada de leituras e
escritas locais e remotas. O resultado do estudo está na Tabela
\ref{tab:estudo_para_quantidade_e_tamanho_dos_objetos_armazenados}.

\begin{table}[!h] \begin{center} \begin{tabular}{|c|c|c|c|c|c|c|c|c|} \hline

Operação & Percentil & Q & T & L & QT & QL & TL & QTL\\ \hline

leitura & 10 & 0 & 100 & 0 & 0 & 0 & 0 & 0 \\ \hline

leitura & 90 & 0 & 0 & 100 & 0 & 0 & 0 & 0 \\ \hline

escrita & 10 & 0 & 100 & 0 & 0 & 0 & 0 & 0 \\ \hline

escrita & 90 & 0 & 0 & 100 & 0 & 0 & 0 & 0 \\ \hline

\end{tabular} \caption[Estudo para quantidade e tamanho dos objetos
armazenados.]{Estudo para quantidade e tamanho dos objetos armazenados. Q
representa a quantidade de objetos armazenados, T representa o tamanho dos
objetos armazenados e L representa a latência.}
\label{tab:estudo_para_quantidade_e_tamanho_dos_objetos_armazenados}.
\end{center} \end{table}

A quantidade de objetos não afeta o desempenho do sistema. O tamanho dos objetos
não afeta o desempenho das requisições remotas. E apesar desse fator aparecer
com 100\% de influência nas requisições locais, o CV dessas requisições indica
que sua influência na prática não é tão grande -- 19\% para leituras e 16\% para
escritas. Além disso, o foco deste trabalho estava no comportamento do sistema
na WAN, onde as requisições são duas ordens de grandeza maiores. Assim, os
valores fixados foram:

\begin{itemize}

\item Quantidade de objetos armazenados: 128000

\item Tamanho dos objetos armazenados (bytes): 500

\end{itemize}

Como o tempo de aquecimento depende da quantidade de objetos armazenados, quanto
menor essa quantidade, mais rápida é a execução dos experimentos. Por outro
lado, optou-se por um número não tão baixo de forma a evitar um excesso de
conflitos. Já no caso do tamanho dos objetos armazenados, o valor foi escolhido
baseado em estudo dos sistemas de caching distribuído no Facebook, que relata
que 90\% dos objetos nesses sistemas é menor do que 500 bytes.

%TODO: comentar conflitos, resultados são estranhos confl : 5 44 44 1 2 5 1   |
%CV =  0.6548619 TODO: citar Workload Analysis of a Large-Scale Key-Value Store

%% ------------------------------------------------------------------------- %%
\subsection{Fatores de rede} \label{sec:fatores_de_rede}

Dado o objetivo deste trabalho, este era um dos estudos mais importantes, dado
que a partir dele seria possível selecionar os fatores de rede mais influentes.
Mas antes do estudo propriamente dito, um estudo preliminar foi feito para
verificar o tamanho dos buffers de leitura e escrita para verificar as
recomendações que dizem que os buffers devem ser o dobro do BDP. A principal
motivação de checar esse fato é que alguns experimentos com iperf mostraram
ganhos de desempenho para buffers até quatro vezes maiores que o BDP. O estudo
usou latência e pacotes fora de ordem para criar cenários que pressionassem os
buffers de forma diferente.

Os níveis inicialmente selecionados foram:

\begin{itemize}

\item Proporção entre tamanho dos buffers e BDP: 2 e 4

\item Latência da WAN (ms): 100 e 300

\item Proporção de pacotes fora de ordem na WAN (\%): 0 e 5

\end{itemize}

Este estudo usou modo lt\_rec e localidade de 50\%. Esses valores foram
escolhidos pois através deles obtém-se uma quantidade balanceada de leituras e
escritas locais e remotas. Para a rede, a variação de latência foi de 50\%.  A
alta variabilidade ajuda a criar um cenário que pressiona os buffers de
transmissão e recepção. O resultado do estudo está na Tabela
\ref{tab:estudo_para_tamanho_dos_buffers_de_transmissao_e_recepcao}.

\begin{table}[!h] \begin{center} \begin{tabular}{|c|c|c|c|c|c|c|c|c|} \hline

Operação & Percentil & L & O & B & LO & LB & OB & LOB\\ \hline

leitura & 10 & 92 & 0 & 3 & 0 & 0 & 2 & 3\\ \hline

leitura & 90 & 98 & 0 & 1 & 0 & 0 & 0 & 0\\ \hline

escrita & 10 & 87 & 11 & 0 & 1 & 1 & 0 & 0\\ \hline

escrita & 90 & 99 & 0 & 0 & 0 & 0 & 0 & 0\\ \hline

\end{tabular} \caption[Estudo para tamanho dos buffers de transmissão e
recepção.]{Estudo para tamanho dos buffers de transmissão e recepção. L
representa a latência, R representa a taxa de pacotes fora de ordem e B
representa o tamanho dos buffers.}
\label{tab:estudo_para_tamanho_dos_buffers_de_transmissao_e_recepcao}.

\end{center} \end{table}

Como o tamanho dos buffers não afetou o desempenho, a opção foi por
configurá-los seguindo as recomendações, assim o valor fixado foi:

\begin{itemize}

\item Proporção entre tamanho dos buffers e BDP: 2

\end{itemize}

Feito isso, o procedimento de otimização da WAN estava finalizado e os
experimentos para rede foram executados. A taxa de pacotes corrompidos não foi
considerada neste estudo pois experimentos preliminares fizeram com que nós do
Riak falhassem por problemas de comunicação. Como não foi encontrada nenhuma
referência indicando que a taxa de pacotes corrompidos é um fator fundamental em
WANs, a opção foi ignorar esse fator.

Este estudo usou a mesma configuração de modo e localidade que o estudo para
tamanho de buffers, pelo mesmo motivo. Os níveis inicialmente selecionados para
fatores de rede foram:

\begin{itemize}

\item Latência da WAN (ms): 100 e 300 

\item Variação da latência da WAN (\%): 1 e 50

\item Taxa de perda de pacotes na WAN (\%): 0,01 e 0,1
 
\item Taxa de duplicação de pacotes na WAN (\%): 0,05 e 5

\item Proporção de pacotes fora de ordem na WAN (\%): 0,05 e 5

\item Algoritmo de congestionamento: TCP CUBIC e H-TCP

\end{itemize}
%TODO: ref sobre perdas Considera-se que perdas acima de x\% tornam a
%comunicação impraticável.  A Study of Internet Packet Reordering

Ambos os algoritmos de congestionamento testados são específicos para redes com
largura de banda e latências grandes. Ambos já estavam disponíveis no Linux
usado nos experimentos, sendo que TCP CUBIC é a configuração padrão. O H-TCP foi
citado em duas referências sobre otimização para WANs da pilha TCP.

O resultado do estudo está na Tabela \ref{tab:estudo_para_fatores_de_rede}.  Com
exceção dos fatores e da interação entre latência e variação de latência, todas
as outras colunas apresentavam valores nulos e foram suprimidas.

\begin{table}[!h] \begin{center} \begin{tabular}{|c|c|c|c|c|c|c|c|c|} \hline

Operação & Percentil & L & V & P & D & O & C & LV\\ \hline

leitura & 90 & 77 & 18 & 0 & 0 & 0 & 0 & 5\\ \hline

escrita & 90 & 70 & 24 & 0 & 0 & 0 & 0 & 6\\ \hline

\end{tabular}

\caption[Estudo para fatores de rede.]{Estudo para fatores de rede. L representa
a latência, V representa a variação da latência, P representa as taxa de perdas,
D representa a taxa de pacotes duplicados, O representa a taxa de pacotes fora
de ordem e C representa o algoritmo de congestionamento.}
\label{tab:estudo_para_fatores_de_rede}

\end{center} \end{table}

% Factors: delay delay_var loss dupl reorder congest 

% get - p10 : 54 1 1 7 1 2 14 0 6 1 0 0 4 1 0 0 0 0 0 0 0 0 5 1 0 0 0 0 0 0 0 0
% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0   | CV =
% 0.007921385 

% get - p90 : 77 18 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0   | CV =
% 0.5825256 

% upd - p10 : 67 3 0 6 0 2 7 0 4 1 0 0 3 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0
% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0   | CV =
% 0.006834625 

% upd - p90 : 70 24 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0   | CV =
% 0.6184648 

Como esperado, fatores relacionados a WAN afetam pouco as requisições locais,
que apresentaram CVs de 1\% tanto para leituras quanto para escritas. O mesmo
não acontece para requisições remotas, cujos CVs são 58\% e 62\% para leituras e
escritas, respectivamente.

O mesmo estudo havia sido realizado anteriormente com níveis de perda de pacotes
0,01\% e 1\%. Nesse estudo, a perda de pacotes era mais influente até do que a
variação da latência. Mas como redes normalmente não apresentam taxas de perda
de pacotes tão altas quanto 1\%, o estudo foi refeito com nível máximo de 0,1\%
e a perda de pacotes não afetou o resultado nesse caso.

A latência, a variação de latência e a interação de primeira ordem entre elas
respondem por 100\% dos resultados. Assim, os níveis escolhidos para esses
fatores nos experimentos foram:

\begin{itemize} \item Latência da WAN (ms): 0, 100, 200 e 300

\item Variação da latência da WAN (\%): 0 e 50

\end{itemize}

Níveis nulos de latência e variação da latência equivalem a ter todo o sistema
operando em uma rede local. Os resultados obtidos para esses casos foram usados
como auxílio na interpretação dos resultados, mas não foram considerados na
análise final dado que sistemas geo-replicados, por definição, não operam nessas
condições.

Os níveis da latências são baseados em estudo que relata as latências entre os
centros de dados dos Amazon Web Services \cite{Sovran2011}. Os centros de dados
considerados são Califórnia (EUA -- Costa Oeste), Virginia (EUA -- Costa Leste),
Irlanda e Singapura. A menor latência observada foi 82 ms entre os centros de
dados dos EUA e a maior foi 277 ms entre Irlanda e Singapura. O valor de 50\% de
variação da latência é aproximado, ele foi baseado em um gráfico do mesmo
estudo, mas não está claramente descrito.

Os valores fixados dos fatores desconsiderados foram:

\begin{itemize}

\item Taxa de perda de pacotes na WAN (\%): 0 

\item Taxa de duplicação de pacotes na WAN (\%): 0

\item Proporção de pacotes fora de ordem na WAN (\%): 0

\item Algoritmo de congestionamento: cubic

\end{itemize}

Taxas de perda de pacotes, taxa de duplicação de pacotes e proporção de pacotes
fora de ordem foram ignorados no estudo final. O algoritmo de congestionamento
foi fixado como ``cubic'', pois esse é o padrão no sistema Linux utilizado nos
experimentos.

Apesar de a taxa de pacotes fora de ordem ser fixada, a ocorrência de alguns
pacotes fora de ordem é possível dada a variação da latência. Por exemplo, com
uma latência de 100 ms e uma variação de 50\%, é possível que o emulador aplique
atrasos de 120ms para um pacote e 80 ms para um outro no mesmo milissegundo, o
que faz com que o segundo pacote seja transmitido antes do primeiro. Mas a
ocorrência de grandes diferenças de latência entre pacotes consecutivos é rara,
dado que o emulador foi configurado para aplicar uma correlação na variação da
latência usando distribuição normal.

%% ------------------------------------------------------------------------- %%
\subsection{Fatores de carga de trabalho}
\label{sec:fatores_de_carga_de_trabalho}

Juntamente com o estudo para fatores de rede, este estudo era um dos estudos
mais importantes, dado o objetivo deste trabalho. Os experimentos também
consideraram a latência como fator para verificar a importância relativa entre
esses fatores e a rede.

A consistência na linha do tempo pode tornar um sistema sob cargas com um maior
número de escritas inviável pois as escritas se tornam indisponíveis em caso de
falha. Assim, este estudo considera situações em que ela é competitiva quando
comparada com a consistência em momento indeterminado, por isso as relações
leitura/escrita usadas resultavam em mais leituras que escritas. Além disso, ao
atualizar um objeto na consistência em momento indeterminado, é necessário o
envio do relógio-vetor. Por isso, antes de qualquer atualização existe uma
leitura\footnote{É possível fazer atualizações sem relógio-vetor, mas isso cria
versões paralelas do mesmo objeto.}. Isso restringe a quantidade de escritas a
um máximo de 50\% da carga de trabalho.

A partir disso, os níveis inicialmente selecionados para carga de trabalho
foram:

\begin{itemize}

\item Relação leitura/escrita: 2:1 e 10:1

\item Popularidade dos objetos: uniforme (a quantidade de requisições para cada
objeto em um dado período é a mesma em média) e concentrada (os acessos obedecem
a uma distribuição Pareto)

\item Localidade: 0,5 (origem dos acessos para cada objeto distribuídos
igualmente entre centros de dados) e 0,9 (90\% dos acessos para cada objeto
originado em um centro de dados e os 10\% restantes originados no outro centro
de dados.

\end{itemize}

A distribuição normal não foi usada para popularidade por simplicidade. Pelo
teorema do limite central, a medida em que o tamanho de uma amostra tende a
infinito, a distribuição normal e a uniforme se aproximam. Dado que o benchmark
já implementava a distribuição uniforme mas não a normal, não havia a
necessidade de implementar a segunda.

Como os modos possuem comportamentos diferentes para requisições locais e
remotas, os experimentos foram executados para cada modo. O resultado para
requisições locais apresentaram CVs em torno de 0,02 para todos os modos. Isso
indica que requisições locais não sofrem influência de nenhum dos fatores. Já
requisições remotas apresentaram CVs de aproximadamente 0,5 e influência da
latência de 100\% para ind2, tl\_qqer e tl\_rec (ind1 não tem requisições
remotas).

A análise da relação leitura/escrita e localidade não usou percentis, mas sim a
média do tempo de resposta de todas as requisições (leituras e escritas). Isso
porque o primeiro fator diz respeito à composição entre leituras e escritas e o
segundo à composição entre requisições locais e remotas, portanto esses fatores
não fazem sentido nos percentis separados por tipo de requisição. Por exemplo,
com localidade 0,5 percebe-se que o percentil 70 representa requisições remotas,
enquanto com localidade 0,9 o mesmo percentil representa requisições locais. Se
a análise fosse feita por percentis, essa informação se perderia e localidade
nunca teria influência. O resultado do estudo está na Tabela
\ref{tab:estudo_para_fatores_de_carga_de_trabalho}

\begin{table}[!h] \begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|} \hline

Modo & R & X & P & L & RX & RP & RL & XP & XL & PL & RXP & RXL & RPL & XPL &
RXPL\\ \hline

ind1 & 19 & 12 & 2 & 31 & 0 & 3 & 2 & 4 & 6 & 6 & 4 & 0 & 0 & 8 & 1\\ \hline

ind2 & 50 & 0 & 0 & 39 & 0 & 0 & 11 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ \hline

lt\_qqer & 25 & 30 & 0 & 19 & 9 & 0 & 6 & 0 & 8 & 0 & 0 & 3 & 0 & 0 & 0\\ \hline

lt\_rec & 0 & 53 & 0 & 34 & 0 & 0 & 0 & 0 & 13 & 0 & 0 & 0 & 0 & 0 & 0\\ \hline

\end{tabular} \caption[Estudo para fatores de carga de trabalho.]{Estudo para
fatores de carga de trabalho. R representa a relação leitura/escrita, X
representa a localidade, P representa a popularidade e L representa a latência
de rede.} \label{tab:estudo_para_fatores_de_carga_de_trabalho}.  \end{center}
\end{table}

Como esperado, localidade e latência impactam os modos em geral. Uma observação
é o fato de inclusive ind1 ser afetada por latência. Isso provavelmente
éresultado dos mecanismos de replicação e correção de leituras serem afetados.

O impacto de popularidade dos objetos é praticamente nulo. Talvez em uma
situação em que o sistema recebesse uma carga maior, como no caso de um teste de
stress, esse fator passasse a ser relevante. Como não é o caso, ele foi
desconsiderado e fixado no valor que simplifica o entendimento dos resultados.
Em trabalhos futuros, experimentos podem ser realizados com o sistema sob carga
mais alta para verificar se a influência de popularidade aumenta.

Apesar de alguns modos aparentemente sofrerem impacto considerável da relação
leitura/escrita, esse impacto na verdade é consequência da relação entre
requisições locais e remotas. Para ind1, tanto leituras quanto escritas são
locais e a relação leitura/escrita e suas interações com outros fatores impacta
pouco esse modo. Para lt\_rec, leituras e escritas são locais ou remotas
dependendo da localidade e a relação leitura/escrita não impacta esse modo. Para
ind2, todas as leituras são locais e metade das escritas é remota, portanto
quando a relação leitura/escrita muda, a relação entre requisições locais e
remotas muda proporcionalmente -- como esperado, esse modo é impactado pela
relação leitura/escrita. A mesma observação vale para lt\_qqer, que tem todas as
leituras locais e escritas dependendo da localidade, e também sofre impacto da
relação leitura/escrita.

Caso o mecanismo de armazenamento fosse disco ao invés de memória, a relação
leitura/escrita provavelmente sofreria impacto de fato. Isso porque escritas
seriam afetadas pelo tempo de escrita no disco, enquanto leituras poderiam ser
mais rápidas pois parte delas seriam servidas a partir do cache de disco.  Mas
como não é esse o caso, a diferença relevante é a relação entre requisições
locais e remotas.

Dessa forma, só foram escolhidos níveis para localidade:

\begin{itemize}

\item Localidade: 0,5 e 0,9

\end{itemize}

Os níveis de localidade foram escolhidos de forma a ter situações sem influência
de localidade (0,5) e com localidade alta (0,9). O valor de localidade alta é
baseado no relatado em estudo feito pelo Yahoo! em seus sistemas de produção
\cite{Cooper2008}.

Os valores fixados dos fatores desconsiderados foram:

\begin{itemize}

\item Relação leitura/escrita: 2:1

\item Popularidade dos objetos: uniforme

\end{itemize}

O valor da relação leitura/escrita é uma balanço razoável entre leituras e
escritas. O valor de popularidade é o mais simples para a interpretação dos
resultados.
