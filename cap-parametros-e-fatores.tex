%% ------------------------------------------------------------------------- %%
\chapter{Parâmetros e Fatores} \label{cap:parametros_e_fatores}

A definição da lista de parâmetros e a seleção de fatores e níveis são passos
fundamentais de um estudo experimental. Os requisitos e limitações a serem
considerados nesses passos são dados pelas definições do estudo e pelos aspectos
técnicos (ver capítulo \ref{cap:metodo_e_aspectos_tecnicos}), que em conjunto
definem o que deve ser feito e quais são os procedimentos e recursos disponíveis
para tal.

Primeiramente, a lista de parâmetros foi levantada. Dessa lista, alguns
parâmetros já foram imediatamente fixados por impossibilidade de variá-los, por
limitação de recursos ou por não serem foco do estudo. A seleção inicial de
fatores foi formada pelos parâmetros restantes. Como essa seleção era grande,
projetos de experimentos fatoriais fracionados foram usados para identificar os
fatores mais influentes para o estudo. Os fatores menos influentes foram
tratados como parâmetros e tiveram seus valores fixados. Os fatores mais
influentes foram usados nos experimentos finais, que usaram um projeto de
experimentos fatoriais completo.

%TODO: seções

%% ------------------------------------------------------------------------- %%
\section{Lista de parâmetros} \label{sec:lista_de_parametros}

Os parâmetros foram divididos em três categorias: parâmetros de sistema, de rede
e de carga de trabalho. As justificativas para a escolha de um parâmetro nem
sempre consideraram todas as situações possíveis em que ele afeta o desempenho
do sistema, em alguns casos uma única razão foi considerada suficiente para
tratá-lo como parâmetro.

Os parâmetros de sistema levantados foram:

\paragraph{Modelo de consistência}Objeto do estudo.
  
% Chequei app.config e vm/args
\paragraph{Configuração de hardware (CPU, memória, disco e placa de rede)}O
tempo de resposta de uma requisição é dado pela soma dos seus tempos de envio,
de processamento e de recebimento. CPU, memória e disco afetam o tempo de
processamento, a placa de rede afeta os tempos de envio e recebimento.

\paragraph{Mecanismo de armazenamento -- memória ou disco}O desempenho da
memória é ordens de grandeza maior que o desempenho de um disco\footnote{SSDs
são uma exceção, mas eles não estavam disponíveis no ambiente dos
experimentos.}. Em um sistema de armazenamento, o desempenho de leituras em
disco pode ser próximo do desempenho de leituras em memória dependendo do
tamanho relativo do cache de disco e do conjunto de dados armazenado. Para
escritas, o desempenho em disco é sempre menor.

\paragraph{Quantidade de nós do sistema}A menos que um sistema distribuído
apresente escalabilidade linear, quanto mais nós ele tiver, menor o seu
desempenho por nó.
% citar contenção e coerência - gcap

\paragraph{Quantidade de centros de dados}A menos que as redes que ligam os
centros de dados tomados dois a dois tenham as mesmas características, o tempo
de resposta de uma dada requisição é dependente de sua origem e destino.

\paragraph{Capacidade dos centro de dados}A menos que todos os centros de dados
possuam as mesmas capacidades agregadas de processamento, armazenamento e
comunicação, a vazão de cada centro de dados é diferente, o que se reflete no
desempenho das requisições.

\paragraph{Quantidade de instâncias do benchmark}Uma quantidade muito pequena de
instâncias pode se tornar o gargalo do experimento, uma quantidade muito grande
pode resultar em sobrecarga do sistema. Em ambos os casos o desempenho medido do
sistema não corresponde a suas condições normais de operação.

\paragraph{Quantidade de threads por instância da aplicação de execução de
testes}Mesma justificativa que para quantidade de instâncias da aplicação de
execução de testes.

\paragraph{Quantidade de objetos armazenados}A quantidade de objetos armazenados
influencia o volume de dados no disco e no cache de disco (caso seja esse o
mecanismo de armazenamento utilizado). Além disso, ela também afeta a quantidade
de conflitos, já que quanto menos objetos existirem no sistema de armazenamento,
maior a chance de um dado objeto ser requerido.

\paragraph{Tamanho dos objetos armazenados}O tamanho dos objetos armazenados
influencia o volume de dados no cache de disco, caso seja esse o mecanismo de
armazenamento utilizado. No caso de armazenamento em memória, o tamanho dos
objetos influencia a fragmentação da memória, o que também afeta o desempenho.
Além disso, o tamanho dos objetos afeta o consumo de banda, dado que objetos
muito grandes precisam ser divididos em mais de um pacote TCP e objetos muito
pequenos resultam em uma carga paga relativamente menor. Consumo maior de banda
tende a se refletir como diminuição da vazão e/ou aumento do tempo de resposta
das requisições.

\paragraph{Algoritmo de particionamento das chaves}O algoritmo de
particionamento define a distribuição dos objetos pelos nós. No caso de
distribuição heterogênea, nós com mais objetos tendem a receber uma maior
quantidade de requisições e ter seu desempenho prejudicado com relação a outros.

\paragraph{Fator de replicação ($N$)}Quanto maior o fator de replicação, maior o
tráfego de rede, o que tende a causar uma diminuição do desempenho do sistema.

\paragraph{Configuração de replicação -- $R$ e $W$ (para consistência em momento
indeterminado)}Em um ambiente com mais de um centro de dados, a configuração de
replicação afeta a proporção entre requisições locais e remotas. Por exemplo, se
todo centro de dados possui uma e apenas uma réplica de cada objeto, todas as
leituras são locais para R = 1 e remotas para R = 2. Dessa forma, a configuração
de replicação afeta o tempo de resposta das requisições.

\paragraph{Limiar de migração (para consistência na linha do tempo)}O limiar de
migração é uma otimização que visa aumentar a quantidade de requisições locais.
Dependendo da carga de trabalho, valores diferentes do limiar resultam em
proporções entre requisições locais e remotas diferentes, afetando assim o tempo
de resposta das requisições.

\paragraph{Protocolo de acesso}Um protocolo mais eficiente, que envia menos
metadados, por exemplo, resulta em desempenho das requisições mais alto.

\paragraph{Nível de log}O nível de log afeta a quantidade de escritas em disco,
o que por sua vez afeta o desempenho do sistema.

Os parâmetros de rede levantados foram:

\paragraph{Configuração de hardware dos elementos de rede intermediários
(switches, roteadores, etc)}A capacidade dos elementos de rede intermediários é
dada pela largura de banda disponível, tamanho dos buffers de entrada e saída,
capacidade de processamento de requisições, entre outros. Dessa forma, sistemas
se comunicando através desses elementos têm seu desempenho afetado por eles. 

\paragraph{Topologia da rede}Várias características da topologia de rede afetam
o desempenho do sistema. Por exemplo, a quantidade de segmentos de rede pelos
quais uma requisição precisa passar para chegar ao destino afeta o seu tempo de
resposta.

\paragraph{Latência da LAN}O tempo de resposta de uma requisição é dado pela
soma dos seus tempos de envio, de processamento e de recebimento. A latência
afeta os tempos de envio e recebimento.

\paragraph{Variação da latência da LAN}A latência em uma rede não é constante,
dado que dentre suas causas está a dinâmica da rede. Por exemplo, rajadas de
tráfego podem encher os buffers de um roteador no caminho entre dois nós,
fazendo com que pacotes sejam descartados, o que se manifesta para o transmissor
como um aumento de latência. Além disso, as variações normalmente não são
aleatórias. A partir do mesmo exemplo, enquanto o roteador está sobrecarregado a
latência vista pelo transmissor é mais alta, quando ele volta a operar
normalmente a latência vista pelo transmissor passa a ser mais baixa. Por isso,
além da variação existe uma correlação entre os valores de latência observados
ao longo do tempo. Dado isso, grandes variações de latência tendem a afetar
negativamente o tempo de resposta das requisições.
%TODO: citar paper mdcc sobre variação de latência e
%http://amplab.cs.berkeley.edu/2011/10/20/latencies-gone-wild/

\paragraph{Latência da WAN}Mesma justificativa que para latência da LAN. Um
agravante é que latências em WANs são ordens de grandeza maiores que em LANs,
dado que quanto maior a distância a ser percorrida pelos pacotes, maior a
latência devido ao limite do meio físico para a velocidade de transmissão.

\paragraph{Variação da latência da WAN}Mesma justificativa que para variação de
latência na LAN. Um agravante para WAN é que requisições em uma WAN atravessam
uma quantidade maior de segmentos de rede, portando são mais suscetíveis à
variação da latência.

\paragraph{Taxa de perda de pacotes na WAN}A perda de pacotes é uma das
principais causas de atrasos e gargalos em um sistema usando TCP, dado que ao
registrar a perda de um pacote a janela de transmissão da conexão é reiniciada,
o que se manifesta como diminuição da largura de banda. Além disso, o mecanismo
padrão de retransmissão do TCP aumenta exponencialmente o tempo entre
tentativas, portanto quanto maior o número de pacotes perdidos, mais tempo é
necessário para os pacotes serem reenviados. Assim, perdas causam diminuição da
vazão e/ou aumento do tempo de resposta de requisições.
%TODO: ref sobre perdas Considera-se que perdas acima de x\% tornam a
%comunicação impraticável.

\paragraph{Taxa de duplicação de pacotes na WAN}Pacotes duplicados afetam a
comunicação TCP principalmente por gerarem tráfico desnecessariamente. Isso
causa diminuição da largura de banda, que pode causar diminuição de vazão e/ou
aumento do tempo de resposta das requisições.
%TODO: checar problemas de duplicação O tratamento dado pelo TCP é o descarte
%dos pacotes duplicados no receptor.

\paragraph{Taxa de corrupção de pacotes na WAN}Pacotes corrompidos afetam a
comunicação TCP por gerarem retransmissões. Isso causa diminuição da largura de
banda, que pode causar diminuição de vazão e/ou aumento do tempo de resposta das
requisições.
%TODO: checar problemas de corrupção

\paragraph{Proporção de pacotes fora de ordem na WAN}Pacotes fora de ordem
afetam a comunicação TCP principalmente por ocuparem buffers em elementos de
rede intermediários e finais no aguardo dos pacotes anteriores a eles. Isso pode
causar perda de desempenho nesses elementos, o que se reflete nos outros
elementos que se comunicam com ou através deles.
%TODO: checar problemas de pacotes fora de ordem

\paragraph{Algoritmo de congestionamento}O algoritmo de congestionamento é
responsável pelo dimensionamento da janela de transmissão. Quanto maior a janela
de transmissão, maior a quantidade dados em trânsito e maior a vazão do sistema.
%TODO: checar como algoritmo de congestionamento realmente opera

\paragraph{Produto Banda-Latência (\emph{Bandwidth Delay Product} -- BDP)}A
quantidade de dados em trânsito em uma conexão TCP é dada pelo Produto
Banda-Latência. Dessa forma, dada uma largura de banda, quanto maior a latência
da rede, maior é a quantidade de pacotes em trânsito. Um gargalo comum nesse
caso é o tamanho dos buffers de transmissão e recepção nas pontas, o que pode
diminuir a vazão e/ou aumentar o tempo de resposta das requisições.

Taxas de perda, de duplicação e de corrupção de pacotes e proporção de pacotes
fora de ordem não são considerados para LAN pois ocorrem com menor frequência e
geram pouco impacto nesse tipo de rede. Em WANs, esses fenômenos estão
relacionados a uma maior quantidade de nós intermediários (incluindo roteadores
e proxies) e redes heterogêneas que os pacotes atravessam.

Os parâmetros de carga de trabalho levantados foram:

\paragraph{Relação leitura/escrita}Escritas normalmente são mais lentas que
leituras, portanto a relação leitura/escrita afeta o tempo de resposta das
requisições em geral. Além disso, a consistência na linha do tempo pode
apresentar desempenho mais baixo em um cenário de escrita intensiva, pois a
réplica mestre pode se tornar um gargalo. Outro ponto a considerar é que a
probabilidade de haver conflitos entre réplicas aumenta com o aumento da taxa de
escritas em um sistema que usa consistência em momento indeterminado, que pode
sofrer um impacto no seu desempenho devido à execução de seus algoritmos de
resolução de conflitos.

\paragraph{Popularidade dos objetos}Em muitas aplicações a popularidade dos
objetos não é uniforme, alguns são mais acessados do que outros. Um exemplo é
uma loja virtual em que o interesse dos clientes pelos produtos tende a obedecer
uma lei de potência \cite{Anderson2006}. A existência de objetos muito populares
pode prejudicar o desempenho de um modelo de consistência como a consistência na
linha do tempo, em que a réplica mestre pode se tornar um gargalo nas escritas.

\paragraph{Localidade}Cooper et al. notam um alto índice de localidade nos
acessos aos objetos dos sistemas no Yahoo! \cite{Cooper2008}. Em uma análise
feita no período de uma semana, foi observado que em média 85\% das escritas a
determinado objeto vinham do mesmo centro de dados. Isso acontece por exemplo em
uma rede social, em que os usuários costumam acessar a aplicação a partir da
mesma localização geográfica e possuem a maior parte de seus contatos na mesma
localização geográfica -- por exemplo, usuários brasileiros tendem a acessar o
sistema do Brasil e a maioria de seus contatos é brasileira. Nesse caso, se os
objetos são particionados no sistema a partir da localização geográfica dos
acessos mais recentes é possível economizar um número considerável de
requisições entre centros de dados. A implementação de consistência na linha do
tempo usada neste estudo implementa migração de réplica mestre por esse motivo.

\paragraph{Taxa de chegada de requisições}Mesma justificativa que para
quantidade de instâncias do benchmark.

\paragraph{Versão requisitada nas leituras (para consistência na linha do
tempo)}Leituras de ``qualquer versão'' apresentam tempo de resposta menor que
leituras de ``versão mais recente'' pois têm maior probabilidade de ser
atendidas localmente. No caso onde existe garantia de haver ao menos uma réplica
por centro de dados, as leituras de ``qualquer versão'' só não são atendidas
localmente em caso de falha.

Dessa lista de parâmetros, alguns foram fixados, as justificativas e seus
valores estão descritos na seção abaixo. Os restantes foram considerados fatores
e o tratamento dado a eles está na seção \ref{sec:selecao_dos_fatores}.

%% ------------------------------------------------------------------------- %%
\section{Parâmetros fixados} \label{sec:parametros_fixados}

Um motivo para fixar um parâmetro é a impossibilidade de variá-lo. Por exemplo,
um estudo pode estar limitado apenas às configurações de hardware disponíveis
para o pesquisador. Um outro motivo é saber de antemão que, apesar de afetar o
desempenho do sistema, o parâmetro é pouco relevante para o estudo em questão --
caso contrário, ele seria considerado um fator.

Favorecer simetria e homogeneidade nos experimentos foi um princípio que guiou
algumas das decisões abaixo, pois assim a implementação e a análise dos
resultados dos experimentos torna-se mais simples. A desvantagem disso é a
possibilidade de perda de realismo, dado que sistemas distribuídos de larga
escala não costumam ser perfeitamente simétricos nem homogêneos.

Como o foco do estudo era a operação do sistema sobre WAN, fatores relacionados
a rede e carga de trabalho eram prioridade. Por isso, sempre que possível,
parâmetros de sistema foram fixados, mesmo quando se sabia que eles afetavam o
desempenho.

A configuração de hardware e o mecanismo de armazenamento são os únicos
parâmetros cuja decisão envolveu experimentos, descritos na subseção seguinte.
Os outros parâmetros estão descritos na subseção \ref{sec:parametros_restantes}.

%% ------------------------------------------------------------------------- %%
\subsection{Aglomerado e mecanismo de armazenamento}
\label{sec:aglomerado_e_mecanismo_de_armazenamento}

As configurações de hardware estavam limitadas às oferecidas pelo Grid5000. Cada
aglomerado do Grid5000 possui todos os nós com mesma configuração de hardware.
Com isso, decidiu-se restringir os experimentos a um único aglomerado, de forma
a ter homogeneidade de hardware no sistema. Dado isso, alguns experimentos foram
feitos para decidir qual aglomerado seria usado nos experimentos finais.

Os aglomerados do Grid5000 considerados foram paradent, parapide, sol e suno. A
descrição do hardware e a quantidade de nós de cada um deles se encontra na
Tabela \ref{tab:aglomerados_do_grid5000}.

\begin{table}[!h] \begin{center} \begin{tabular}{|c|c|c|c|c|} \hline Aglomerado
& CPU & Memória & Disco & Quantidade de nós \\ \hline parapide & & & & \\ \hline
paradent & & & & \\ \hline \end{tabular} \caption{Aglomerados do Grid5000}
\label{tab:aglomerados_do_grid5000} \end{center} \end{table}

Os experimentos feitos para o mecanismo de armazenamento mostraram diferenças
consideráveis no desempenho do Riak em aglomerados diferentes. Considerando que
os experimentos eram limitados por E/S (e não por CPU) e que não havia gargalo
de rede, decidiu-se checar o desempenho dos discos em cada aglomerado. A
especificação do hardware mostrava tipos de discos diferentes entre aglomerados.
Dada essa diferença, experimentos foram realizados para quantificá-la e tomar
uma decisão mais informada.

Testes simples de desempenho de disco foram realizados em cada aglomerado. Para
medição do desempenho, os experimentos usaram o hdparm para acesso sequencial e
o
seeker\footnote{url{http://www.linuxinsight.com/how\_fast\_is\_your\_disk.html}}
para acesso aleatório. Os resultados estão na Tabela
\ref{tab:comparacao_de_desempenho_dos_discos_entre_aglomerados}.

\begin{table}[!h] \begin{center} \begin{tabular}{|c|c|c|c|c|c|} \hline
Aglomerado & Tipo & Tamanho & Acesso sequencial (MB/s) & Acesso aleatório
(seeks/s) & Acesso aleatório (tempo de resposta em ms) \\ \hline sol & & & 59,8
& 78 & 12,7 \\ \hline suno & & & 242,7 & 131 & 7,6 \\ \hline griffon & & & 73,9
& 56 & 17,6 \\ \hline parapluie & & & 103,9 & 77 & 13,0 \\ \hline \end{tabular}
\caption{Comparação de desempenho dos discos entre aglomerados}
\label{tab:comparacao_de_desempenho_dos_discos_entre_aglomerados} \end{center}
\end{table}

Além  do tipo de disco, um outro ponto que precisava ser considerado foi o cache
de disco. Em sistemas Linux, todo a memória livre é automaticamente usada como
cache de disco. Dado isso, existiam três opções para a execução dos experimentos
com relação ao mecanismo de armazenamento, considerando que um tamanho do banco
de dados podia ser escolhido de forma a manter todos os dados em memória:

\begin{enumerate} \item Dados em disco e cache limpo no início dos experimentos:
O cenário seria mais real, mas mais difícil de analisar pois os efeitos do disco
e da memória sobre o desempenho do sistema se misturariam. Além disso, o efeito
do preenchimento do cache seria um complicador extra, dado que durante um
experimento um determinado objeto é acessado mais de uma vez seria servido do
disco a primeira vez e da memória nas seguintes.

\item Dados em cache no início dos experimentos: O disco seria predominantemente
usado apenas para escritas e as leituras seriam servidas a partir do cache.

\item Dados em memória: O Riak podia ser configurado para funcionar como um
banco de dados em memória, eliminando definitivamente o efeito do disco.
\end{enumerate}

A terceira opção foi a escolhida. Realizar os experimentos com banco de dados em
memória geraria resultados mais precisos e fáceis de ser interpretados por
descartar a influência de desempenho do disco. Em princípio, os resultados podem
parecer menos realistas e aplicáveis, mas na prática eles são tão limitados
quanto o uso de disco, já que nesse caso os resultados seriam afetados pelo tipo
de disco e pela relação entre o tamanho do banco de dados e a memória livre. Um
exemplo é a comparação de suno com parapluie, em que o primeiro aglomerado
possui discos com taxas de acesso acima do 1Gb/s da rede -- o gargalo em um caso
seria a rede, em outro o disco. Além disso, efeitos do cache de disco tornariam
os resultados ainda mais particulares e difíceis de ser generalizados. Dessa
forma, ao adotar memória como mecanismo de armazenamento, eliminou-se os efeitos
das interações entre rede, disco e cache de disco e a análise foi focada apenas
na rede. Trabalhos futuros podem estudar o efeito de disco e cache de disco no
desempenho.
%TODO: colocar os valores escolhidos em itens

%% ------------------------------------------------------------------------- %%
\subsection{Parâmetros restantes} \label{sec:parametros_restantes}

Os parâmetros inicialmente levantados que não foram considerados fatores foram
fixados nos seguintes valores:

\paragraph{Quantidade de centros de dados:}2. Esse valor simplificou a análise
pois existia apenas um segmento de WAN nos experimentos. Além disso, ele tornou
a modificação do algoritmo de particionamento do Riak mais simples (ver seção
\ref{sec:sistema_de_armazenamento}).

\paragraph{Capacidade do centro de dados:}Os centros de dados têm a mesma
capacidade, pois têm a mesma quantidade de nós por centro de dados de nós e os
nós têm mesma configuração de hardware. Dessa forma, os experimentos ficaram
mais simples de executar e analisar devido à simetria do sistema.

\paragraph{Algoritmo de particionamento das chaves:}O algoritmo padrão do Riak
foi usado (espalhamento consistente), configurado com 512 partições. Esse valor
satisfaz as duas condições descritas na documentação do Riak: ser uma potência
de 2 e resultar em ao menos 10 partições por nó (caso os experimentos finais
usassem mais do que 64 nós esse valor teria sido aumentado).

\paragraph{Fator de replicação ($N$):}3. Valor que resulta em um balanço
razoável entre desempenho, disponibilidade e durabilidade em aplicações reais
\cite{DeCandia2007}.

\paragraph{Limiar de migração (para consistência na linha do tempo):}3.  Valor
padrão usado pelo PNUTS \cite{Cooper2008}.

\paragraph{Interface de acesso:}HTTP. O Riak também suporta Protocol
Buffers\footnote{\url{http://code.google.com/p/protobuf/}}, mais eficiente que a
interface HTTP. Apesar disso a opção foi por HTTP pois eficiência não era tão
relevante para os experimentos dado que a carga sobre o sistema era
relativamente baixa, mas implementar os parâmetros da consistência na linha do
tempo na interface HTTP era mais simples.

\paragraph{Nível de log:}WARN. Alguns experimentos exploratórios mostraram perda
de desempenho quando o  nível de log estava em INFO. De qualquer forma, como a
carga sobre o sistema era relativamente baixa, esse parâmetro era pouco
relevante.

\paragraph{Topologia da rede:}Topologia da rede do aglomerado utilizado no
estudo. A topologia dos aglomerados considerados consistiam apenas de nós
ligados diretamente a um switch.

\paragraph{Largura de banda nos elementos intermediários (switches, roteadores,
etc):}Largura de banda no aglomerado utilizado no estudo. Esse valor é dado pelo
switch em que os nós estão ligados (ver subseção
\ref{sec:aglomerado_e_mecanismo_de_armazenamento}). Mas antes da definição do
aglomerado utilizado, estudos exploratórios em alguns aglomerados mostraram que
não existiam gargalos no switch mesmo nos experimentos que mais demandavam
banda.

\paragraph{Latência da LAN:}Latência do aglomerado utilizado no estudo. Todos os
aglomerados considerados apresentam latências semelhantes. Uma medição com 60
amostras espaçadas em 5 s no aglomerado sol mostrou 167 $\mu$s.
% ping -i 5 -c 60 sol-20

\paragraph{Variação de latência da LAN:}Variação de latência do aglomerado
utilizado no estudo. Todos os aglomerados considerados apresentam variações de
latência semelhantes. A mesma medição feita para a latência mostrou desvio
padrão de 90 $\mu$s.

\paragraph{Taxa de chegada de requisições}15 operações/s para cada thread de
cada instância do benchmark. Esse valor foi usado pois esse parâmetro se
relaciona diretamente com a quantidade de threads por instância do benchmark.
Assim, considerando que threads por instância foi inicialmente considerado um
fator, a taxa de chegada foi fixada.

Os parâmetros que não foram fixados consequentemente eram candidatos a fatores
nos experimentos finais. A quantidade de fatores inicialmente considerada nesse
ponto era grande, portanto experimentos foram realizados para diminuir essa
lista. A descrição dos experimentos, dos fatores e seus níveis se encontra na
seção \ref{sec:selecao_dos_fatores}.


%% ------------------------------------------------------------------------- %%
\section{Seleção dos fatores} \label{sec:selecao_dos_fatores}

Os parâmetros que não foram fixados imediatamente passaram a ser candidatos a
fatores. Como essa lista continha muitos deles, ela precisava ser reduzida,
portanto experimentos foram realizados.

Assim, os fatores foram divididos em dois grupos, de acordo com a forma com que
seriam tratados. O primeiro era o grupo dos fatores que tinham baixa prioridade
para entrar no estudo final:

\begin{itemize}

\item Quantidade de nós do sistema

\item Quantidade de instâncias do benchmark

\item Quantidade de threads por instância do benchmark

\item Quantidade dos objetos armazenados

\item Tamanho dos objetos armazenados.

\end{itemize}

O segundo era o grupo dos fatores com alta prioridade para entrar no estudo
final. Como a lista ainda era grande, eles precisavam passar por uma triagem:

\begin{itemize}

\item Modelo de consistência

\item Latência da WAN

\item Variação da latência da WAN

\item Taxa de perda de pacotes na WAN

\item Taxa de duplicação de pacotes na WAN

\item Taxa de corrupção de pacotes na WAN

\item Proporção de pacotes fora de ordem na WAN

\item Algoritmo de congestionamento

\item Produto Banda-Latência (\emph{Bandwidth Delay Product} -- BDP)

\item Relação leitura/escrita

\item Popularidade dos objetos

\item Localidade

\end{itemize}

Uma abordagem possível para a seleção final de fatores seria agrupar todos os
fatores levantados em um único projeto de experimentos fatoriais
2\textsuperscript{k}. O problema é que mesmo com apenas 2 níveis por fator, a
quantidade final de experimentos seria proibitiva, dado que a quantidade de
fatores era 17. Por isso, a opção adotada foi dividir os fatores em grupos
menores e realizar experimentos para cada grupo. O principal problema de fazer
essa separação é o fato de se perder a comparação da importância entre fatores
de grupos diferentes. Por exemplo, uma localidade de 0,5 ou 0,9 poderia ser
comparada com outros fatores de carga de trabalho, mas não apareceria como
influente caso os experimentos fossem executados sem considerar a rede. Nos
casos em que isso aconteceu, os fatores precisavam ser comparados com a rede. A
abordagem adotada foi usar a latência, fator que já era sabido ser influente
(fato comprovado experimentalmente), como um representante da rede. A partir
dessa abordagem foi possível concluir, por exemplo, que apesar de o tamanho dos
objetos armazenados aparecer como fator influente no estudo fatorial para ele,
desconsiderá-lo no estudo final não era uma grande ameaça à validade pois a
latência de rede era um fator bem mais relevante.

Existem outras situações em que desconsiderar um fator que aparece como
influente não implica necessariamente em ameaça à validade. Experimentos
fatoriais mostram a influência relativa de cada fator e cada interação entre
fatores. Nesse tipo de análise, o total de todas as influências relativas deve
ser sempre 100\%. Por isso, mesmo que todos os fatores afetem pouco o resultado,
um ou mais vão aparecer nos experimentos fatoriais com influência alta. Assim,
também foram calculados os coeficientes de variabilidade\footnote{O coeficiente
de variação é a divisão do desvio padrão pela média e é uma maneira de
representar a variabilidade dos dados desconsiderando sua ordem de grandeza}
(CVs) para cada resultado de forma a estimar qual a importância daquele conjunto
de fatores e interações como um todo. Se o CV é baixo ao final de um estudo
fatorial, isso implica que nenhum daqueles fatores é influente, dado que todas
as combinações entre eles foram testadas e o desempenho variou pouco de um
experimento para o outro.

Os experimentos descritos nesta seção usam percentis dos tempos de resposta das
requisições em vez de médias. As requisições deste estudo são divididas entre
locais, da ordem de poucos milissegundos, e remotas, da ordem de centenas de
milissegundos. Dessa forma, as requisições remotas dominam a média já que são em
geral duas ordens de grandeza maiores que as locais. Por isso os estudos fazem
análises distintas para cada tipo de requisição, usando percentis: percentis
baixos representam requisições locais e percentis altos representam requisições
remotas. Também é feita a distinção entre escritas e leituras dada a diferença
de natureza dessas operações.

Três fatores receberam um tratamento diferente ao longo do experimento: modelo
de consistência, configuração de replicação (para consistência em momento
indeterminado) e versão requisitada nas leituras (para consistência na linha do
tempo). Isso porque seus níveis influenciam na proporção de requisições locais e
remotas, fundamental para este estudo. Por isso, esses fatores foram tratados
como um único, chamado modo (subseção seguinte). Projetos de experimentos
fatoriais fracionados 2\textsuperscript{k} foram realizados para cada um dos
fatores restantes e estão descritos nas subseções subsequentes.

%% ------------------------------------------------------------------------- %%
\subsection{Modo} \label{sec:modo}

Os modos adotados são:

\begin{itemize} \item ind1: Consistência em momento indeterminado com $W$ = 1 e
$R$ = 1 \item ind2: Consistência em momento indeterminado com $W$ = 2 e $R$ = 1
\item lt\_qqer: Consistência na linha do tempo com leituras de qualquer versão
\item lt\_rec: Consistência na linha do tempo com leituras da versão mais
recente \end{itemize}

Todas as configurações usam $N = 3$ (ver seção \ref{sec:parametros_fixados}). O
algoritmo de particionamento garante que existe ao menos uma réplica em cada
centro de dados (ver subseção \ref{sec:sistema_de_armazenamento}). Assim,
existem sempre duas situações possíveis com relação à localização das réplicas
do ponto de vista do coordenador: uma local e duas remota ou duas locais e uma
remota. Dado isso, ind1 resulta em todas as leituras e escritas locais. ind2
resulta em todas as leituras locais e metade das escritas locais e a outra
metade remotas. lt\_qqer resulta em todas as leituras locais e a quantidade de
escritas dependente da localidade dos acessos. Finalmente, lt\_rec resulta tanto
em leituras quanto escritas dependentes da localidade.

Os modos foram escolhidos de forma a representar situações encontradas em
sistemas de produção e ao mesmo tempo limitar a quantidade de níveis. Assim,
consistência na linha do tempo com leituras de versões específicas não foi
considerada já que ela é um meio termo entre leituras de versão mais recente e
leituras de qualquer versão. Consistência em momento indeterminado com $W = 1$ e
$R = 2$ não foi considerada pois sua semântica é similar a $W = 2$ e $R = 1$,
mas teria seu desempenho prejudicado considerando que leituras predominam nas
distribuições de operações usadas nos experimentos (ver subseção
\ref{sec:fatores_de_carga_de_trabalho}).

Esses modos implicam em trocas além de desempenho e consistência. A principal é
durabilidade, que para ind2 é mais alta do que para os outros casos, em que a
confirmação de escrita de uma única réplica é suficiente.

%% ------------------------------------------------------------------------- %%
\subsection{Quantidade de nós do sistema, quantidade de instâncias da aplicação
de execução de testes e quantidade de threads por instância da aplicação de
execução de testes}
\label{sec:quantidade_de_nos_do_sistema_quantidade_de_instancias_da_aplicacao_de_execucao_de_testes_e_quantidade_de_threads_por_instancia_da_aplicacao_de_execucao_de_testes}

Os níveis inicialmente selecionados para esse estudo foram:

\begin{itemize}

\item Quantidade de nós do sistema: 8 e 16

\item Quantidade de instâncias do benchmark: 2 e 4

\item Quantidade de threads em cada instância da aplicação de execução de
testes: 32 e 64

\end{itemize}

A quantidade de partições deve ser uma potência de 2 (ver seção
\ref{sec:parametros_fixados}). Para manter a simetria do sistema, os níveis
considerados para quantidade de nós no sistema também foram potências de 2,
garantindo assim a mesma quantidade de partições por nó. Por sua vez, a
quantidade de instâncias da do benchmark e a quantidade de threads por instância
também foram potências de 2, de forma a balancear a carga média tanto por nó
quanto por partição.

Este estudo usou modo lt\_rec, localidade de 50\% e latência de rede de 100 ms.
Esses valores foram escolhidos pois através deles obtém-se uma quantidade
balanceada de leituras e escritas locais e remotas. O resultado do estudo está
na Tabela \ref{tab:estudo_para_quantidade_de_nos_do_sistema}.

\begin{table}[!h] \begin{center} \begin{tabular}{|c|c|c|c|c|c|c|c|c|} \hline
Operação & Percentil & N & A & T & NA & NT & AT & NAT\\ \hline leitura & 10 & 30
& 18 & 22 & 10 & 8 & 7 & 4 \\ \hline leitura & 90 & 65 & 13 & 15 & 3 & 4 & 0 & 0
\\ \hline escrita & 10 & 96 & 2 & 1 & 0 & 0 & 0 & 0 \\ \hline escrita & 90 & 65
& 15 & 13 & 3 & 3 & 0 & 0 \\ \hline \end{tabular} \caption{Estudo para
quantidade de nós do sistema. N representa a quantidade de nós do sistema, A
representa a quantidade de instâncias do benchmark e T representa a quantidade
de threads usadas em cada instânca da aplicação de execução de testes.}
\label{tab:estudo_para_quantidade_de_nos_do_sistema} \end{center} \end{table}

Na maioria dos casos, o tamanho do sistema tem a maior influência nos resultados
e a quantidade de instâncias do benchmark e a quantidade de threads não são
desprezíveis, ainda mais ao se considerar as interações entre elas. Como
comentado no início desta seção, mesmo sendo influentes, alguns fatores foram
desconsiderados para manter a quantidade de fatores finais baixa.  Esse foi o
caso dos três fatores desse estudo. Nesse caso, a opção foi por manter o maior
tamanho de sistema possível, evitando gargalos de rede ao máximo e não
sobrecarregando o sistema. Por isso, a opção foi pelos valores que resultam na
configuração ``mais leve'', fato confirmado através da observação dos gráficos
das FDAs. Dessa forma, os valores fixados foram:

\begin{itemize} \item Quantidade de nós do sistema: 16 (maior valor) \item
Quantidade de instâncias do benchmark: 4 (maior valor) \item Quantidade de
threads em cada instância da aplicação de execução de testes: 32 (menor valor)
\end{itemize}

Uma outra opção a esses valores seria o uso de 32 nós do sistema e 8 instâncias
do benchmark, resultando em um total de 40 nós. Isso não foi feito por questões
operacionais. Ao definir que o sistema usaria memória como mecanismo de
armazenamento, a escolha do aglomerado passou a ser menos relevante, dado que
todos os aglomerados oferecem nós com capacidade de processamento (CPU)
razoável, ao menos 4GB de memória e placas de rede de 1Gb/s.  O aglomerado sol
foi escolhido predominantemente por questões operacionais -- ele é um dos
maiores aglomerados disponíveis no Grid5000 (47 nós) e tem baixa concorrência
com outros pesquisadores pela reserva de nós. Mas mesmo assim, é muito comum
alguns poucos nós já estarem reservados por outros pesquisadores, além de alguns
nós apresentarem falhas no momento da implantação da imagem. Esse último
problema levou o pesquisador a sempre reservar alguns nós além dos necessários
para garantir a quantidade mínima de nós para executar os experimentos. Dessa
forma, experimentos que precisassem de 40 nós seriam mais difíceis de ser
executados.

%% ------------------------------------------------------------------------- %%
\subsection{Quantidade de objetos armazenados e tamanho dos objetos armazenados}
\label{sec:quantidade_de_objetos_armazenados_e_tamanho_dos_objetos_armazenados}

Os experimentos fatoriais relacionados ao tamanho do banco de dados também
consideraram o atraso de rede como fator. O atraso de rede foi usado como uma
simplificação da WAN, dessa forma foi possível comparar a importância relativa
entre esses fatores e a rede.

Os níveis inicialmente selecionados foram:

\begin{itemize} \item Quantidade de objetos armazenados: 64000 e 256000 \item
Tamanho dos objetos armazenados: 100 e 10000 \end{itemize}

Este estudo usou modo lt\_rec e localidade de 50\%.  Esses valores foram
escolhidos pois através deles obtém-se uma quantidade balanceada de leituras e
escritas locais e remotas. O resultado do estudo está na Tabela
\ref{tab:estudo_para_quantidade_e_tamanho_dos_objetos_armazenados}.

\begin{table}[!h] \begin{center} \begin{tabular}{|c|c|c|c|c|c|c|c|c|} \hline
Operação & Percentil & Q & T & L & QT & QL & TL & QTL\\ \hline leitura & 10 & 0
& 100 & 0 & 0 & 0 & 0 & 0 \\ \hline leitura & 90 & 0 & 0 & 100 & 0 & 0 & 0 & 0
\\ \hline escrita & 10 & 0 & 100 & 0 & 0 & 0 & 0 & 0 \\ \hline escrita & 90 & 0
& 0 & 100 & 0 & 0 & 0 & 0 \\ \hline \end{tabular} \caption{Estudo para
quantidade e tamanho dos objetos armazenados. Q representa a quantidade de
objetos armazenados, T representa o tamanho dos objetos armazenados e L
representa a latência.}
\label{tab:estudo_para_quantidade_e_tamanho_dos_objetos_armazenados}.
\end{center} \end{table}

É possível perceber que a quantidade de objetos não afeta o desempenho do
sistema. Como o tempo de aquecimento depende da quantidade de objetos
armazenados, quanto menor essa quantidade mais rápido os experimentos são
executados. Por outro lado, optou-se por um número não tão baixo de forma a
evitar um excesso de conflitos.

O tamanho dos objetos não afeta o desempenho das requisições remotas. E apesar
desse fator aparecer com 100\% de influência nas requisições locais, o CV dessas
requisições foi de 19\% para leituras e 16\% para escritas.  Além disso, o foco
deste trabalho está no comportamento do sistema na WAN, onde as requisições são
duas ordens de grandeza maiores. O valor para tamanho dos objetos armazenados
foi escolhido baseado em estudo dos sistemas de caching distribuído no Facebook
que relata que 90\% dos valores de praticamente todos os sistemas está abaixo
desse valor.

Assim, os valores fixados foram:

\begin{itemize} \item Quantidade de objetos armazenados: 128000 \item Tamanho
dos objetos armazenados: 500 \end{itemize}

%TODO: comentar conflitos, resultados são estranhos confl : 5 44 44 1 2 5 1   |
%CV =  0.6548619 TODO: citar Workload Analysis of a Large-Scale Key-Value Store

%% ------------------------------------------------------------------------- %%
\subsection{Fatores de rede} \label{sec:fatores_de_rede}

Um estudo preliminar foi feito para verificar o tamanho dos buffers de leitura e
escrita para verificar as recomendações que dizem que os buffers devem ser o
dobro do BDP. A principal motivação de checar esse fato é que alguns
experimentos com iperf mostraram ganhos de desempenho para buffers até quatro
vezes maiores que o BDP. Esse é um tipo de cenário que coloca bastante pressão
nos buffers.

Os níveis inicialmente selecionados foram:

\begin{itemize} \item Proporção entre tamanho dos buffers: 2 e 4 \end{itemize}

Este estudo usou modo lt\_rec e localidade de 50\%. Esses valores foram
escolhidos pois através deles obtém-se uma quantidade balanceada de leituras e
escritas locais e remotas. Para a rede, o estudo usou latências de 100 ms e 300
ms, variação de latência de 50\% e taxas de pacotes fora do ordem de 0\% e 5\%.
A alta variabilidade e os pacotes fora de ordem criam um cenário que pressiona
os buffers de transmissão e recepção. O resultado do estudo está na Tabela
\ref{tab:estudo_para_tamanho_dos_buffers_de_transmissao_e_recepcao}.

\begin{table}[!h] \begin{center} \begin{tabular}{|c|c|c|c|c|c|c|c|c|} \hline
Operação & Percentil & L & O & B & LO & LB & OB & LOB\\ \hline leitura & 10 & 92
& 0 & 3 & 0 & 0 & 2 & 3\\ \hline leitura & 90 & 98 & 0 & 1 & 0 & 0 & 0 & 0\\
\hline escrita & 10 & 87 & 11 & 0 & 1 & 1 & 0 & 0\\ \hline escrita & 90 & 99 & 0
& 0 & 0 & 0 & 0 & 0\\ \hline \end{tabular} \caption{Estudo para tamanho dos
buffers de transmissão e recepção. L representa a latência, R representa a taxa
de pacotes fora de ordem e B representa o tamanho dos buffers.}
\label{tab:estudo_para_tamanho_dos_buffers_de_transmissao_e_recepcao}.
\end{center} \end{table}

Como o tamanho dos buffers não afetou o desempenho, a opção foi por
configurá-los como o dobro do BDP, seguindo as recomendações.

Feito isso, os experimentos para rede foram executados. A taxa de pacotes
corrompidos não foi considerada neste estudo pois experimentos preliminares
fizeram com que nós do Riak falhassem por problemas de comunicação. Como nenhuma
referência indicando que a taxa de pacotes corrompidos é um fator fundamental em
WANs, a opção foi ignorar esse fator.

Os níveis inicialmente selecionados foram:

\begin{itemize} \item Latência da WAN (ms): 100 e 300 

\item Variação da latência da WAN (\%): 1 (pouca variação) e 50 (muita variação)

\item Taxa de perda de pacotes na WAN (\%): 0,05 (pouca perda) e 1 (muita perda) 

\item Taxa de duplicação de pacotes na WAN (\%): 0,05 e 5

\item Proporção de pacotes fora de ordem na WAN (\%): 0,05 e 5

\item Algoritmo de congestionamento: cubic e htcp \end{itemize}

%TODO: falar sobre cubic e htcp

O resultado do estudo está na Tabela \ref{tab:estudo_para_fatores_de_rede}
(devido ao grande números de colunas da tabela apenas colunas com ao menos um
valor diferente de 0 são apresentadas).

\begin{table}[!h] \begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|} \hline Operação & Percentil \\
\hline leitura & 10 \\ \hline leitura & 90 \\ \hline escrita & 10 \\ \hline
escrita & 90 \\ \hline \end{tabular} \caption{Estudo para fatores de rede. L
representa a latência, V representa a variação da latência, P representa as taxa
de perdas, D representa a taxa de pacotes duplicados, O representa a taxa de
pacotes fora de ordem e C representa o algoritmo de congestionamento.}
\label{tab:estudo_para_fatores_de_rede}.  \end{center} \end{table}

%TODO: decidir se faz uma tabela pra cada ordem de efeitos (3a e talvez 4a ordem
%precisem de 2 tabelas) ou se só usa colunas != 0 (2 tabelas)

É possível perceber que a latência, a variação da latência, a taxa de perdas e
as interações entre elas são os fatores que mais afetam o desempenho do sistema.
Assim, os níveis escolhidos para esses três fatores nos experimentos foram:

\begin{itemize} \item Latência da WAN (ms): 0, 100, 200 e 300

\item Variação da latência da WAN (\%): 0 e 50

\item Taxa de perda de pacotes na WAN (\%): 0, 0,01 e 0,1 

\end{itemize}

%TODO: explicar perdas

Os níveis da latências são baseados nas latências entre os centros de dados dos
Amazon Web Services \cite{Sovran2011}. Os centros de dados considerados são
Califórnia (EUA -- Costa Oeste), Virginia (EUA -- Costa Leste), Irlanda e
Singapura. A menor latência observada foi 82 ms entre os centros de dados dos
EUA e a maior foi 277 ms entre Irlanda e Singapura.

Níveis nulos de latência, variação da latência e taxa de perdas equivalem a ter
todo o sistema operando em uma rede local. Os resultados obtidos para esses
casos devem ser usados como auxílio na interpretação dos resultados, mas não
devem ser considerados na análise final dado que sistemas geo-replicados, por
definição, não operam nessas condições.

Os valores fixados dos fatores desconsiderados foram:

\begin{itemize}

\item Taxa de perda de pacotes na WAN (\%): 0 

\item Taxa de duplicação de pacotes na WAN (\%): 0

\item Proporção de pacotes fora de ordem na WAN (\%): 0

\item Algoritmo de congestionamento: cubic \end{itemize}

Apesar de afetar o desempenho, a variação foi fixada dado que grandes variações
de latência em WANs são comuns. Além disso, dos 3 fatores, esse é o que menos
afeta, mesmo com os experimentos usando variações bem diferentes (1\% e 50\%). O
algoritmo de congestionamento foi fixado como ``cubic'', pois esse é o padrão no
Linux utilizado nos experimentos.

Apesar de a taxa de pacotes fora de ordem ser fixada, a ocorrência de alguns
pacotes fora de ordem é possível dada a variação da latência. O emulador de WAN
foi configurado para aplicar uma correlação na variação da latência usando
distribuição normal. Com isso, a probabilidade de grandes diferenças de latência
entre pacotes consecutivos é baixa, diminuindo assim a probabilidade de pacotes
fora de ordem.

%% ------------------------------------------------------------------------- %%
\subsection{Fatores de carga de trabalho}
\label{sec:fatores_de_carga_de_trabalho}

Os experimentos para fatores de carga de trabalho também consideraram o atraso
de rede como fator. O atraso de rede foi usado como uma simplificação da WAN,
dessa forma foi possível comparar a importância relativa entre esses fatores e a
rede.

A consistência na linha do tempo pode tornar um sistema sob cargas com um maior
número de escritas inviável pois as escritas se tornam indisponíveis em caso de
falha. Assim, este estudo considera situações em que ela é competitiva quando
comparada com a consistência em momento indeterminado.

Ao fazer uma atualização em um objeto na consistência em momento indeterminado,
é necessário o envio do relógio-vetor. Por isso, espera-se que antes de qualquer
atualização haja uma leitura. Esse fato restringe a quantidade de escritas a um
máximo de 50\% da carga de trabalho.

A partir disso, os níveis inicialmente selecionados foram:

\begin{itemize} \item Relação leitura/escrita: 2:1 e 10:1

\item Popularidade dos objetos: uniforme (a quantidade de requisições para cada
objeto em um dado período é a mesma em média) e concentrada (os acessos obedecem
a uma distribuição Pareto)

\item Localidade: 0,5 (origem dos acessos para cada objeto distribuídos
igualmente entre centros de dados) e 0,9 (90\% dos acessos para cada objeto
originado em um centro de dados e os 10\% restantes originados no outro centro
de dados. \end{itemize}

A distribuição normal não foi usada para popularidade por simplicidade. Pelo
teorema do limite central, a medida em que o tamanho de uma amostra tende a
infinito, a distribuição normal e a uniforme se aproximam. Dado que a aplicação
de execução de testes já implementa a distribuição uniforme, não há a
necessidade de implementar a distribuição normal.

Como os modos possuem comportamentos diferentes para requisições locais e
remotas, os experimentos foram executados para cada modo. O resultado para
requisições locais apresentaram CVs em torno de 0,02 para todos os modos. Isso
indica que requisições locais não sofrem influência de nenhum dos fatores. Já
requisições remotas apresentaram CV de aproximadamente 0,5 e 100\% de influência
do atraso para ind2, tl\_qqer e tl\_rec (ind1 não tem requisições remotas).

A análise da relação leitura/escrita e localidade são feitas pela média do tempo
de resposta do total de requisições e não pelos percentis. Isso porque o
primeiro fator diz respeito à composição entre leituras e escritas e o segundo à
composição entre requisições locais e remotas. Por exemplo, com localidade 0,5
percebe-se que o percentil 70 representa requisições remotas, enquanto com
localidade 0,9 o mesmo percentil representa requisições locais. Se a análise
fosse feita por percentis, essa informação se perderia e localidade nunca teria
influência (como pode ser observado pelos baixos CVs). Dado issom, o resultado
do estudo pode ser visto na Tabela
\ref{tab:estudo_para_fatores_de_carga_de_trabalho}

\begin{table}[!h] \begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|} \hline Modo & R & X & P & L &
RX & RP & RL & XP & XL & PL & RXP & RXL & RPL & XPL & RXPL\\ \hline ind1 & 19 &
12 & 2 & 31 & 0 & 3 & 2 & 4 & 6 & 6 & 4 & 0 & 0 & 8 & 1\\ \hline ind2 & 50 & 0 &
0 & 39 & 0 & 0 & 11 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ \hline lt\_qqer & 25 & 30
& 0 & 19 & 9 & 0 & 6 & 0 & 8 & 0 & 0 & 3 & 0 & 0 & 0\\ \hline lt\_rec & 0 & 53 &
0 & 34 & 0 & 0 & 0 & 0 & 13 & 0 & 0 & 0 & 0 & 0 & 0\\ \hline \end{tabular}
\caption{Estudo para fatores de carga de trabalho para ind1. R representa a
relação leitura/escrita, X representa a localidade, P representa a popularidade
e L representa a latência de rede.}
\label{tab:estudo_para_fatores_de_carga_de_trabalho}.  \end{center} \end{table}

Como esperado, localidade e latência impactam os modos em geral. Uma observação
é o fato de inclusive ind1 ser afetada por latência. Isso provavelmente vem do
fato de mecanismos de replicação e correção de leitura serem afetados. Assim, os
níveis são:

\begin{itemize}

\item Localidade: 0,5 (origem dos acessos para cada objeto distribuídos
igualmente entre centros de dados) e 0,9 (90\% dos acessos para cada objeto
originado em um centro de dados e os 10\% restantes originados no outro centro
de dados. \end{itemize}

Apesar de alguns modos aparentemente sofrerem impacto considerável da relação
leitura/escrita, há indícios de que esse impacto na verdade é consequência da
relação entre requisições locais e remotas. O modo ind1 tem tanto leituras
quanto escritas locais e a relação leitura/escrita e suas interações com outros
fatores impacta pouco esse modo. No modo lt\_rec tanto leituras quanto escritas
são locais ou remotas dependendo da localidade e a relação leitura/escrita não
impacta esse modo. O modo ind2 tem todas as leituras locais e metade das
escritas remotas. Assim, se a relação leitura/escrita muda a relação entre
requisições locais e remotas muda proporcionalmente. Como esperado, esse modo é
impactado pela relação leitura/escrita.  O mesmo vale para lt\_qqer que tem
todas as leituras locais e escritas dependendo da localidade. Esse modo também
sofre impacto da relação leitura/escrita.

Caso o mecanismo de armazenamento fosse disco ao invés de memória, a relação
leitura/escrita provavelmente sofreria impacto de fato. Isso porque escritas
seriam afetadas pelo tempo de escrita no disco, enquanto leituras poderiam ser
mais rápidas pois parte delas seriam servidas a partir do cache de disco.  Mas
como não é esse o caso, a diferença relevante é a relação entre requisições
locais e remotas.

Percebe-se em todos os casos impacto praticamente nulo de popularidade. Talvez
em uma situação em que o sistema recebesse uma carga maior, como no caso de um
teste de stress, esse fator passasse a ser relevante. Como não é o caso, ele foi
desconsiderado e fixado no valor que simplifica o entendimento dos resultados.

Os valores fixados dos fatores desconsiderados foram:

\begin{itemize} \item Relação leituras/escritas: 2:1

\item Popularidade dos objetos: uniforme

\end{itemize}
