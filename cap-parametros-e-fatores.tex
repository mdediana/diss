%% ------------------------------------------------------------------------- %%
\chapter{Parâmetros e Fatores} \label{cap:parametros_e_fatores}

A etapa seguinte à definição do estudo e dos aspectos técnicos tratou dos
parâmetros e fatores usados nos experimentos finais. Primeiramente, a lista de
parâmetros foi levantada. Dessa lista, alguns parâmetros já foram imediatamente
fixados por limitação de recursos ou por não serem foco do estudo. A seleção
inicial de fatores foi formada pelos parâmetros restantes. Como essa seleção era
grande, experimentos foram usados para identificar os fatores mais influentes
para o estudo. Os fatores menos influentes foram tratados como parâmetros e
tiveram seus valores fixados. Os fatores mais influentes foram usados nos
experimentos finais.

A fim de caracterizar a WAN, as principais características de uma rede são
evidenciadas pelos mecanismos presentes no protocolo TCP, explicado na
Seção~\ref{sec:mecanismos_do_tcp_e_parametros_de_rede}. A lista de parâmetros
inicialmente levantada é apresentada na Seção~\ref{sec:lista_de_parametros}. Os
parâmetros fixados e seus valores estão na Seção~\ref{sec:parametros_fixados}. A
seleção dos fatores e os experimentos que levaram a ela estão na
Seção~\ref{sec:selecao_dos_fatores}. Por fim, um sumário dos fatores
selecionados e as configurações do estudo final são apresentados na
Seção~\ref{sec:fatores_selecionados}.

%% ------------------------------------------------------------------------- %%
\section{Mecanismos do TCP e Parâmetros de Rede}
\label{sec:mecanismos_do_tcp_e_parametros_de_rede} Uma das principais diferenças
entre redes de longa distância (WANs) e redes locais (LANs), além da área pela
qual se estendem, diz respeito a confiabilidade do meio. LANs costumam usar
topologias simples com poucos dispositivos e segmentos entre os nós, enquanto o
contrário acontece em WANs. Além disso, LANs costumam ser mais homogêneas e
terem um único administrador. No caso de WANs, um pacote de dados normalmente
atravessa diversas redes compostas por dispositivos e administradores
diferentes. Do ponto de vista deste trabalho, um centro de dados corresponde a
uma LAN, enquanto a georeplicação ocorre na WAN.

TCP/IP é a pilha de protocolos comumente utilizada em sistemas georeplicados. O
protocolo IP provê os mecanismos de endereçamento e roteamento. O TCP provê
comunicação ponto-a-ponto confiável. Para tal, usa diversos mecanismos
relacionados e dependentes entre si para lidar com controle de fluxo e perdas,
corrupção, reordenação e duplicação de pacotes.

O controle de fluxo é feito por mecanismos usados nas pontas de uma conexão com
o objetivo de usar a rede de forma eficiente e evitar o envio de mais dados do
que o receptor pode tratar. Perdas acontecem quando um dispositivo na rede
descarta pacotes, o que pode ser causado por corrupção de pacotes ou
congestionamento da rede, como \emph{buffers} esgotados em um roteador, por
exemplo. Reordenação ocorre quando pacotes de uma mesma conexão TCP enviados nos
instantes T1 e T2 seguem caminhos diferentes na rede, e o pacote enviado em T2
chega ao receptor antes do enviado em T1. Duplicação normalmente está
relacionada a retransmissões do TCP, mas também acontece devido a balanceamento
de carga ou problemas de hardware ou software em dispositivos intermediários.

Os principais mecanismos adotados no TCP para prover comunicação confiável são
descritos a seguir \cite{Stevens1993,RFC5861}:

\paragraph{Reconhecimento positivo com retransmissão}O TCP garante a entrega de
dados pelo uso de números de sequência e reconhecimento dos pacotes e de
mensagens de reconhecimento enviadas pelo receptor. Cada pacote enviado pelo
transmissor carrega um número de sequência que representa a posição do primeiro
byte de dados desse pacote no fluxo de dados. Ao receber um pacote, o receptor
envia para o transmissor um pacote ACK com número de reconhecimento informando
qual é o próximo byte que espera receber. Por exemplo, se um transmissor envia
um pacote de 10 bytes de dados de carga e número de sequência 1, o receptor
responderá com um ACK com número de reconhecimento 11. Um temporizador de
transmissão é ativado para cada pacote enviado. Se o temporizador expirar antes
do recebimento do ACK, o pacote é reenviado.

\paragraph{Controle de fluxo}A janela de recebimento é a quantidade de bytes que
o receptor está disposto a receber, baseada no espaço livre de seu \emph{buffer}
de recepção. O receptor envia o valor da janela em todas as suas respostas para
o transmissor. Esse mecanismo evita que o transmissor envie mais dados do que o
receptor pode tratar.

\paragraph{Início lento}Ao contrário da janela de recebimento, a janela de
congestionamento é mantida pelo transmissor, e é uma estimativa do
congestionamento da rede. O transmissor calcula o tamanho da janela ($cwnd$ --
\emph{Congestion window}) a partir dos ACKs recebidos. O mecanismo de início
lento atua no início de uma conexão, quando o transmissor ainda não recebeu
ACKs. No primeiro pacote, $cwnd$ é igual a 1 ou 2 vezes o tamanho máximo de
segmento TCP ($MSS$ -- \emph{Maximum Segment Size}). Para cada ACK recebido,
$cwnd$ é incrementada em 1 $MSS$. Assim, a janela dobra de tamanho a cada tempo
de ida e volta até que atinja o tamanho da janela de recebimento ou uma perda
aconteça. Quando uma perda acontece, um segundo valor passa a ser levado em
consideração, o limiar do início lento ($ssthresh$ -- \emph{Slow start
threshold} onde $ssthresh = cwnd / 2$) e o processo começa de novo, com $cwnd$
igual a 1 ou 2 $MSS$, até atingir $ssthresh$.  A partir desse ponto, o TCP entra
em modo de prevenção de congestionamento.

\paragraph{Prevenção de congestionamento}As diferentes variações do TCP usam
diferentes algoritmos de prevenção de congestionamento. Um dos primeiros
algoritmos de prevenção de congestionamento implementados no TCP aumenta a
janela de congestionamento em $1 / cwnd$ a cada ACK recebido
\cite{Jacobson1988}. Assim, durante essa fase, o aumento da janela de
transmissão é linear, e não mais exponencial como no início lento. Variações de
TCP oferecem outras opções de algoritmos de prevenção de congestionamento,
inclusive algumas delas sendo focadas em redes com latência e largura de banda
grandes (ver Subseção~\ref{sec:fatores_de_rede}).

\paragraph{Retransmissão rápida}O receptor envia um ACK para todo pacote
recebido, mesmo que fora de ordem. Por exemplo, se os pacotes de 10 bytes com
números de sequência 1, 21 e 31 chegam ao receptor, ele responde com três ACKs
com número de reconhecimento 11. O transmissor trata os primeiros ACKs em
duplicata como reordenação de pacotes e apenas os ignora. Mas ao receber o
terceiro, ele considera que um pacote foi perdido (o de número 21 no exemplo).
EM vez de esperar o temporizador, o mecanismo de retransmissão rápida
retransmite o pacote imediatamente.

\paragraph{Recuperação rápida}O mecanismo de retransmissão rápida ter sido
acionado indica que uma perda aconteceu, portanto algum mecanismo de prevenção
de congestionamento deve atuar. Mas o recebimento de ACKs de pacotes posteriores
ao perdido indica que o congestionamento foi uma situação pontual, já que o
fluxo de dados entre transmissor e receptor não foi totalmente cortado. Por
isso, reduzir drasticamente a janela de transmissão pelo uso do início lento
implicaria em perda de vazão desnecessária. Assim, a recuperação rápida atua
juntamente com a retransmissão rápida. Quando o terceiro ACK em duplicata é
recebido, ssthresh assume o valor de $cwnd / 2$, o pacote é retransmitido e a
janela de congestionamento assume o valor $cwnd = ssthresh + 3 * MSS$. Se outros
ACKs chegam em duplicata, a janela é incrementada em 1 MSS para cada um. Quando
um ACK diferente chega, reconhecendo todos os pacotes recebidos fora de ordem (o
de número 41 no exemplo), a janela assume o valor $cwnd = ssthresh$ -- metade do
seu tamanho no momento em que o terceiro ACK em duplicata foi recebido.

\paragraph{Pacotes duplicados}Pacotes duplicados são simplesmente descartados no
receptor.

\paragraph{Pacotes corrompidos}O TCP tem um campo com uma soma de verificação
que é usada no receptor para checar se o pacote foi corrompido em trânsito. Em
caso positivo, ele é descartado. Do ponto de vista do transmissor, o pacote foi
perdido, então os mecanismos usuais de controle de fluxo são acionados.

%% ------------------------------------------------------------------------- %%
\section{Lista de Parâmetros} \label{sec:lista_de_parametros}

Os parâmetros foram divididos em três categorias: parâmetros de sistema, de rede
e de carga de trabalho. As justificativas para a escolha de um parâmetro nem
sempre consideraram todas as situações possíveis em que ele afeta o desempenho
do sistema, em alguns casos uma única razão foi considerada suficiente para
tratá-lo como parâmetro.

Alguns parâmetros das listas a seguir foram fixados, as justificativas e seus
valores estão descritos na Seção~\ref{sec:parametros_fixados}. Os restantes
foram considerados fatores e o tratamento dado a eles está na Seção
\ref{sec:selecao_dos_fatores}.

Uma última observação é que todos valores de latência relatados referem-se a
latência de ida e volta.

%% ------------------------------------------------------------------------- %%
\subsection{Parâmetros de sistema} \label{sec:parametros_de_sistema}

Os parâmetros de sistema levantados foram:

% Chequei app.config e vm/args
\paragraph{Configuração de hardware (CPU, memória, disco e placa de rede)}O
tempo de resposta de uma requisição é dado pela soma dos seus tempos de envio,
de processamento e de recebimento. CPU, memória e disco afetam o tempo de
processamento, a placa de rede afeta os tempos de envio e recebimento.

\paragraph{Mecanismo de armazenamento -- memória ou disco}O desempenho da
memória é ordens de grandeza maior que o desempenho de um disco\footnote{SSDs
são uma exceção, mas eles não estavam disponíveis no ambiente dos
experimentos.}. Em um sistema de armazenamento, o desempenho de leituras em
disco pode ser próximo do desempenho de leituras em memória dependendo do
tamanho do cache de disco e do conjunto de dados armazenados. Para escritas, o
desempenho em disco é sempre menor.

\paragraph{Quantidade de nós do sistema}A menos que um sistema distribuído
apresente escalabilidade linear, quanto mais nós ele tiver, menor será o
desempenho por nó.

\paragraph{Capacidade dos centros de dados}A menos que todos os centros de dados
possuam as mesmas capacidades agregadas de processamento, armazenamento e
largura de banda, a vazão de cada centro de dados é diferente, o que se reflete
no desempenho das requisições.

\paragraph{Quantidade de instâncias do \emph{benchmark}}Considerando que cada
instância do \emph{benchmark} gere a mesma taxa de requisições, uma quantidade
mínima é necessária para a evitar gargalos no \emph{benchmark}.

\paragraph{Quantidade de threads por instância do \emph{benchmark}}Mesma
justificativa que para quantidade de instâncias do \emph{benchmark}.

\paragraph{Quantidade de objetos armazenados}A quantidade de objetos armazenados
influencia o volume de dados no disco e no cache de disco (caso disco seja o
mecanismo de armazenamento utilizado). Além disso, dada uma taxa de chegada de
requisições constante, a quantidade de objetos armazenados também afeta a
probabilidade de conflitos, já que quanto menos objetos estiverem armazenados no
sistema, maior a chance de um dado objeto ser requerido.

\paragraph{Tamanho dos objetos armazenados}O tamanho dos objetos armazenados
influencia o volume de dados no cache de disco, caso seja esse o mecanismo de
armazenamento utilizado. No caso de armazenamento em memória, o tamanho dos
objetos influencia a fragmentação da memória, o que também afeta o desempenho.
Além disso, o tamanho dos objetos afeta o comportamento da comunicação TCP, dado
que objetos muito grandes precisam ser divididos em mais de um pacote e objetos
muito pequenos resultam em uma carga paga (\emph{payload}) proporcionalmente
menor. Isso tende a se refletir como diminuição da vazão e/ou aumento do tempo
de resposta das requisições.

\paragraph{Algoritmo de particionamento}O algoritmo de particionamento define a
distribuição dos objetos pelos nós. No caso de uma distribuição desbalanceada,
nós com mais objetos tendem a receber uma maior quantidade de requisições e ter
seu desempenho prejudicado com relação a outros.

\paragraph{Modelo de consistência}Objeto do estudo.
  
\paragraph{Fator de replicação ($N$)}Quanto maior o fator de replicação, maior o
tráfego de rede, o que tende a causar uma diminuição do desempenho do sistema.

\paragraph{Configuração de replicação -- $R$ e $W$ (para consistência em momento
indeterminado)}Em um ambiente com mais de um centro de dados, a configuração de
replicação afeta a proporção entre requisições locais e remotas. Por exemplo, se
todo centro de dados possui uma e apenas uma réplica de cada objeto, todas as
leituras são locais para R = 1 e remotas para R = 2. Dessa forma, a configuração
de replicação afeta o tempo de resposta das requisições.

\paragraph{Limiar de migração (para consistência na linha do tempo)}O limiar de
migração é o valor no qual uma réplica mestre migra de um centro de dados para
outro. Dependendo da carga de trabalho, valores diferentes do limiar resultam em
proporções entre requisições locais e remotas diferentes, afetando assim o tempo
de resposta médio das requisições.

\paragraph{Protocolo de acesso}Um protocolo mais eficiente, que envia menos
metadados, por exemplo, resulta em desempenho das requisições mais alto.

\paragraph{Nível de log}O nível de log afeta a quantidade de escritas em disco,
o que por sua vez afeta o desempenho do sistema.

%% ------------------------------------------------------------------------- %%
\subsection{Parâmetros de rede} \label{sec:parametros_de_rede}

Os parâmetros de rede levantados foram:

\paragraph{Configuração de hardware dos dispositivos de rede intermediários
(comutadores, roteadores, etc.)}A configuração dos dispositivos de rede
intermediários relaciona-se à largura de banda disponível, tamanho dos
\emph{buffers} de transmissão e recepção, capacidade de processamento de
requisições, entre outros.  Dessa forma, gargalos nesses dispositivos causam
congestionamento na rede, com perda de desempenho do sistema.

\paragraph{Topologia da rede}Várias características da topologia de rede afetam
o desempenho do sistema, por exemplo, a quantidade de segmentos de rede pelos
quais uma requisição passa para chegar ao destino afeta o seu tempo de resposta.

\paragraph{Largura de banda da LAN}A largura de banda limita a vazão máxima do
sistema em bits/s.

\paragraph{Latência da LAN}O tempo de resposta de uma requisição é dado pela
soma dos seus tempos de envio, de processamento e de recebimento. A latência
afeta os tempos de envio e recebimento.

\paragraph{Variação da latência da LAN}A latência em uma rede não é constante,
dado que dentre suas causas está a dinâmica da rede
\cite{Gurtov2002,Kraska2012}. Por exemplo, rajadas de tráfego aumentam a fila de
pacotes a ser processados em um roteador, o que se manifesta como aumento de
latência nas conexões passando por ele. Quando o roteador volta a sua operação
normal, a latência diminui. A latência não vaira aleatoriamente, ela tem
períodos de aumento e de diminuição gradual. No exemplo, a latência diminui em
função da diminuição da fila no roteador, ela não cai imediatamente para o seu
valor médio. Esse fato levou ao uso de correlação na variação da latência nos
experimentos.

\paragraph{Largura de banda da WAN}Mesma justificativa que para largura de banda
da LAN.

\paragraph{Latência da WAN}Mesma justificativa que para latência da LAN. Um
agravante é que latências em WANs são ordens de grandeza maiores que em LANs já
que as distâncias percorridas pelos pacotes são muito maiores.

\paragraph{Variação da latência da WAN}Mesma justificativa que para variação de
latência na LAN. Um agravante é que requisições em uma WAN atravessam mais
segmentos de rede e dispositivos intermediários, portanto são mais suscetíveis à
variação da latência. Quando a variação é muita e a latência torna-se maior que
o tempo de expiração do temporizador de transmissão, o transmissor interpreta a
demora na recepção de ACKs como perda de pacotes, o que diminui a vazão do
sistema (a seguir).

\paragraph{Taxa de perda de pacotes na WAN}Após uma perda\footnote{Perdas
acontecem por corrupção de pacotes ou congestionamento. A ocorrência de
corrupção de pacotes é um fenômeno mais frequente em redes sem fio ou via
satélite, [Stevens] cita que esse valor é muito menor que 1\% normalmente. Além
disso, o tratamento dado pelo TCP para perda de pacotes é o mesmo independente
do motivo da perda.  Assim, este trabalho considera perdas por congestionamento,
mesmo que o netem seja capaz de emular ambas as situações.}, o transmissor
aciona o mecanismo de início lento (no caso de expiração do temporizador de
transmissão) ou o mecanismo de prevenção de congestionamento (no caso do
recebimento de ACKS em duplicata). Com isso, a janela de transmissão é
diminuída, com consequente diminuição da vazão.

\paragraph{Taxa de duplicação de pacotes na WAN}Duplicação de pacotes gera
tráfego e processamento desnecessários, o que pode causar diminuição de vazão
e/ou aumento do tempo de resposta das requisições.

\paragraph{Taxa de reordenação de pacotes na WAN}Pacotes fora de ordem acionam o
mecanismo de recuperação rápida, com consequente diminuição da janela de
transmissão. Além disso, pacotes fora de ordem ocupam espaço no \emph{buffer} do
receptor, o que pode afetar seu desempenho \cite{Wang2004}.

\paragraph{Variação de TCP}Variações de TCP oferecem diferentes algoritmos de
prevenção de congestionamento, responsável pelo dimensionamento da janela de
congestionamento.  Quanto maior a janela de congestionamento, maior a quantidade
dados em trânsito e maior a vazão do sistema.

\paragraph{Quantidade e características dos enlaces de WAN}A menos que os
enlaces que interligam os centros de dados tenham as mesmas características, o
tempo de resposta de uma dada requisição depende de sua origem e destino.

Taxas de perda, de duplicação e reordenação de pacotes não foram consideradas
para LAN pois ocorrem com menor frequência e geram pouco impacto nesse tipo de
rede. Em WANs, esses fenômenos estão relacionados a uma maior quantidade de nós
intermediários (incluindo roteadores e \emph{proxies}) e redes heterogêneas que
os pacotes atravessam.

O Produto Banda-Latência (\emph{Bandwidth Delay Product} -- BDP) representa a
quantidade máxima de dados em trânsito em uma conexão TCP e é comumente usado
como medida de capacidade de enlaces de WANs em vez de latência e largura de
banda separadamente. Neste trabalho a opção foi tratar latência e largura de
banda separadamente pois a principal métrica do estudo é o tempo de resposta das
requisições (Seção~\ref{sec:metricas}), que é mais facilmente comparável
diretamente com a latência da rede. Além disso, foi considerado para estudo um
cenário de implantação em que uma nuvem semelhante ao EC2 da Amazon fosse usada,
então a largura de banda foi fixada nos estudos com base em valores relatados
(ver Seção~\ref{sec:parametros_fixados}).

Por último, a variação de TCP usada é definida naa configuração nos nós, e
portanto poderia ser considerada um parâmetro de sistema. Mas como uma única
variação foi usada em todos os nós e a análise do parâmetro fazia mais sentido
no contexto da rede, a opção foi por classificá-lo como parâmetro de rede.

%% ------------------------------------------------------------------------- %%
\subsection{Parâmetros de carga de trabalho}
\label{sec:parametros_de_carga_de_trabalho}

Os parâmetros de carga de trabalho levantados foram:

\paragraph{Relação leitura/escrita}Escritas normalmente são mais lentas que
leituras, portanto a relação leitura/escrita afeta o tempo de resposta médio das
requisições. Além disso, a consistência na linha do tempo pode apresentar
desempenho mais baixo em um cenário de escrita intensiva, pois a réplica mestre
pode se tornar um gargalo. Outro ponto a considerar é que a probabilidade de
haver conflitos entre réplicas aumenta com o aumento da taxa de escritas em um
sistema que usa consistência em momento indeterminado, que pode sofrer um
impacto no seu desempenho devido à execução de seus algoritmos de resolução de
conflitos.

\paragraph{Popularidade dos objetos}Em muitas aplicações a popularidade dos
objetos não é uniforme, alguns são mais acessados do que outros. Um exemplo é
uma loja virtual em que o interesse dos clientes pelos produtos tende a obedecer
uma lei de potência \cite{Anderson2006}. A existência de objetos muito populares
pode prejudicar o desempenho de um modelo de consistência como a consistência na
linha do tempo, em que a réplica mestre pode se tornar um gargalo nas escritas.

\paragraph{Localidade}Cooper et al. notam um alto índice de localidade nos
acessos aos objetos dos sistemas no Yahoo! \cite{Cooper2008}. Em uma análise
feita no período de uma semana, foi observado que em média 85\% das escritas a
determinado objeto vinham do mesmo centro de dados. Isso acontece por exemplo em
uma rede social, em que os usuários costumam tanto acessar a aplicação quanto
ter a maior parte de seus contatos na mesma localização geográfica -- usuários
brasileiros tendem a acessar o sistema do Brasil e a maioria de seus contatos é
brasileira. Nesse caso, é possível evitar requisições entre centros de dados se
os objetos são particionados no sistema considerando a localização geográfica
dos acessos mais recentes. A implementação de consistência na linha do tempo
usada neste estudo implementa migração de réplica mestre por esse motivo.

\paragraph{Taxa de chegada de requisições}Mesma justificativa que para
quantidade de instâncias do \emph{benchmark}.

\paragraph{Versão requisitada nas leituras (para consistência na linha do
tempo)}Leituras de ``qualquer versão'' apresentam tempo de resposta menor que
leituras de ``versão mais recente'' pois têm maior probabilidade de ser
atendidas localmente. No caso onde existe garantia de haver ao menos uma réplica
por centro de dados, as leituras de ``qualquer versão'' só não são atendidas
localmente em caso de falha.

%% ------------------------------------------------------------------------- %%
\section{Parâmetros Fixados} \label{sec:parametros_fixados}

Um motivo para fixar um parâmetro é a limitação de recursos. Por exemplo, um
estudo pode estar limitado apenas às configurações de hardware disponíveis para
o pesquisador. Um outro motivo é saber de antemão que, apesar de afetar o
desempenho do sistema, o parâmetro é pouco relevante para o estudo.

Favorecer simetria e homogeneidade nos experimentos foi um princípio que guiou
algumas das decisões, pois isso simplificou a implementação e a análise dos
experimentos. A desvantagem é a possível perda de realismo, dado que sistemas
distribuídos de larga escala não costumam ser totalmente simétricos nem
homogêneos.

Como o foco do estudo era a operação do sistema sobre uma WAN, fatores
relacionados a rede e carga de trabalho eram prioridade. Por isso, sempre que
possível, parâmetros de sistema foram fixados, mesmo quando se sabia que eles
afetavam o desempenho.

A configuração de hardware e o mecanismo de armazenamento são os únicos
parâmetros cuja decisão envolveu experimentos, descritos na Subseção
\ref{sec:aglomerado_e_mecanismo_de_armazenamento}. Os outros parâmetros estão
descritos na Subseção~\ref{sec:parametros_restantes}.

%% ------------------------------------------------------------------------- %%
\subsection{Aglomerado e mecanismo de armazenamento}
\label{sec:aglomerado_e_mecanismo_de_armazenamento}

As configurações de hardware estavam limitadas às oferecidas pelo Grid5000. Cada
aglomerado do Grid5000 possui todos os nós com mesma configuração de hardware, e
aglomerados diferentes são compostos por hardware com configurações diferentes.
Com isso, decidiu-se restringir os experimentos a um único aglomerado, de forma
a garantir homogeneidade de hardware. Além disso, do ponto de vista operacional,
o uso de um único aglomerado simplificou a execução dos experimentos. Dado isso,
alguns experimentos foram feitos para decidir qual aglomerado seria usado.

Os aglomerados do Grid5000 considerados foram parapluie, sol e suno. A descrição
do hardware e a quantidade de nós de cada um deles se encontra na Tabela
\ref{tab:aglomerados_do_grid5000}.

\begin{table}[!h] \begin{center}

\begin{tabular}{|c|c|c|c|c|} \hline

Aglomerado & CPU & Memória & Disco & Nós \\ \hline

parapluie & AMD Opteron 6164 HE 1.7 Ghz & 48 GB & SATA / 250 GB & 40\\ \hline

sol & AMD Opteron 2218 2.6 GHz & 4 GB & SATA / 250 GB & 50\\ \hline

suno & Intel Xeon E5520 2.26 GHz & 32 GB & SAS/RAID-0 / 2x300 GB & 45\\ \hline

\end{tabular}

\caption{Aglomerados do Grid5000.} \label{tab:aglomerados_do_grid5000}

\end{center} \end{table}

Os experimentos mostraram diferenças consideráveis no desempenho do Riak entre
esses aglomerados. Considerando que os experimentos eram limitados por E/S (e
não por CPU) e que não havia gargalo de rede, decidiu-se checar o desempenho dos
discos em cada aglomerado. A especificação do hardware mostrava tipos de discos
diferentes entre aglomerados.  Dada essa diferença, experimentos foram
realizados para quantificá-la e tomar uma decisão mais informada.

Testes de desempenho de disco foram realizados em cada aglomerado. Para medição
do desempenho, os experimentos usaram o hdparm para acesso sequencial e o
seeker\footnote{\url{http://www.linuxinsight.com/how\_fast\_is\_your\_disk.html}}
para acesso aleatório. Os resultados confirmaram as grandes diferenças de
desempenho, como pode ser visto na Tabela
\ref{tab:comparacao_de_desempenho_de_acessos_dos_discos_entre_aglomerados}.

\begin{table}[!h] \begin{center}

\begin{tabular}{|c|c|c|c|c|c|} \hline

Aglomerado & Sequencial (MB/s) & Aleatório (buscas/s) & Aleatório (em ms) \\
\hline

parapluie & 103,9 & 77 & 13,0 \\ \hline

sol & 59,8 & 78 & 12,7 \\ \hline

suno & 242,7 & 131 & 7,6 \\ \hline

\end{tabular}

\caption{Comparação de desempenho de acessos dos discos entre aglomerados.}
\label{tab:comparacao_de_desempenho_de_acessos_dos_discos_entre_aglomerados}

\end{center} \end{table}

Além do tipo de disco, um outro ponto considerado foi o cache de disco. Em
sistemas Linux, todo a memória livre é automaticamente usada como cache de
disco. Dado isso, existiam três opções para a execução dos experimentos com
relação ao mecanismo de armazenamento, considerando que um tamanho do banco de
dados podia ser escolhido de forma a manter todos os dados em memória:

\begin{enumerate} \item Dados em disco e cache limpo no início dos experimentos:
O cenário seria mais real, mas mais difícil de analisar pois os efeitos do disco
e da memória sobre o desempenho do sistema se misturariam. Além disso, o efeito
do preenchimento do cache seria dependente da duração do experimento, quanto
mais longo o experimento maiores as chances de as leituras encontrarem os
objetos no cache.

\item Dados em cache no início dos experimentos: O disco seria predominantemente
usado apenas para escritas e as leituras seriam servidas a partir do cache. Com
isso, o desempenho das escritas seria dependente do disco, enquanto o das
leituras não.

\item Dados em memória: O Riak podia ser configurado para funcionar como um
banco de dados em memória, eliminando definitivamente o efeito do disco.
\end{enumerate}

A terceira opção foi a escolhida. Realizar os experimentos com banco de dados em
memória geraria resultados mais precisos e de interpretação mais simples por
descartar a influência de desempenho do disco. Em princípio, os resultados podem
parecer menos realistas e aplicáveis, mas na prática eles são tão limitados
quanto com o uso de disco, já que nesse caso os resultados seriam afetados pelo
tipo de disco e pela relação entre o tamanho do banco de dados e a memória
livre. Um exemplo é a comparação de suno com parapluie, em que o primeiro
aglomerado possui discos com taxas de acesso maiores que a largura de banda da
rede (1 Gb/s) -- o gargalo em um caso seria a rede, em outro caso seria o disco.
Efeitos do cache de disco tornariam os resultados ainda mais particulares e
difíceis de ser generalizados.  Dessa forma, ao adotar memória como mecanismo de
armazenamento, eliminou-se os efeitos das interações entre rede, disco e cache
de disco e a análise foi focada apenas na rede. Trabalhos futuros podem estudar
o efeito de disco e cache de disco no desempenho (Seção
\ref{sec:trabalhos_futuros}).

Ao definir que o sistema usaria memória como mecanismo de armazenamento, a
configuração de hardware do aglomerado passou a ser menos relevante, dado que
todos os aglomerados oferecem nós com capacidade de processamento (CPU)
razoável, ao menos 4 GB de memória e placas de rede de 1 Gb/s. O aglomerado sol
foi escolhido predominantemente por questões operacionais -- ele tem um tamanho
suficiente (47 nós) e a concorrência pela reserva de seus nós é baixa.

Dessa forma, os valores fixados foram:

\begin{itemize}

\item Aglomerado: sol

\item Mecanismo de armazenamento: memória

\end{itemize}

O aglomerado escolhido usa topologia em estrela com cada nó ligado diretamente a
um comutador Foundry FastIron Super X.

%% ------------------------------------------------------------------------- %%
\subsection{Parâmetros restantes} \label{sec:parametros_restantes}

Os parâmetros inicialmente levantados que não foram considerados fatores foram
fixados. O valores definidos foram:

\paragraph{Capacidade dos centros de dados:}Os centros de dados têm a mesma
capacidade, com a mesma quantidade de nós e os nós têm a mesma configuração de
hardware, resultando em um sistema simétrico e homogêneo.

\paragraph{Algoritmo de particionamento das chaves:}O algoritmo padrão do Riak
foi usado (espalhamento consistente), configurado com 512 partições. Esse valor
satisfaz as duas condições descritas na documentação do Riak: ser uma potência
de 2 e resultar em ao menos 10 partições por nó (caso os experimentos finais
usassem mais do que 64 nós esse valor teria sido aumentado).

\paragraph{Fator de replicação ($N$):}3. Valor que resulta em um balanço
razoável entre desempenho, disponibilidade e durabilidade em aplicações reais
\cite{DeCandia2007}.

\paragraph{Limiar de migração (para consistência na linha do tempo):}3.  Valor
padrão usado pelo PNUTS \cite{Cooper2008}.

\paragraph{Interface de acesso:}HTTP. O Riak também dá suporte a Protocol
Buffers\footnote{\url{http://code.google.com/p/protobuf/}}, mais eficiente que a
interface HTTP. Apesar disso, a opção foi pelo uso de HTTP pois eficiência da
interface não era tão relevante para os experimentos dado que a carga sobre o
sistema era controlada, e implementar os parâmetros da consistência na linha do
tempo na interface HTTP era mais simples.

\paragraph{Nível de log:}WARN. Alguns experimentos exploratórios mostraram perda
de desempenho quando o  nível de log estava em INFO. De qualquer forma, como a
carga sobre o sistema era controlada, esse parâmetro era pouco relevante.

\paragraph{Configuração de hardware dos dispositivos de rede intermediários
(comutadores, roteadores, etc.)}O único dispositivo de rede no aglomerado usado
no estudo era um comutador (ver Subseção
\ref{sec:aglomerado_e_mecanismo_de_armazenamento}). Testes mostraram que não
existiam gargalos no comutador mesmo nos experimentos com maior consumo de
banda.

\paragraph{Topologia da rede:}Topologia da rede em estrela do aglomerado usado
nos experimentos.

\paragraph{Largura de banda da LAN:} 1 Gb/s. Essa é a largura de banda
disponível nas placas de rede dos nós do aglomerado e não foram encontrados
indícios de que o comutador seria um gargalo. Tomando o AWS como base, estudos
informais indicam que é essa a largura de banda observada dentro de um mesmo
centro de dados por instâncias com perfil de E/S ``Alto'' (por exemplo, uma
instância M1 Grande) \cite{Thorsten2007,Pujol2012}.

\paragraph{Latência da LAN:}Latência do aglomerado utilizado no estudo. Um teste
com ping com 60 amostras espaçadas em 5 s no aglomerado mediu 167 $\mu$s de
latência média.
% ping -i 5 -c 60 sol-20

\paragraph{Variação de latência da LAN:}Variação de latência do aglomerado
utilizado no estudo. A mesma medição feita para a latência mostrou desvio padrão
de 90 $\mu$s.

\paragraph{Largura de banda da WAN:} 100 Mb/s. Um estudo informal entre os
serviços EC2 e S3 da Amazon com 9 segmentos de rede entre eles (indício de que
estão em centros de dados diferentes) mediu 400 Mb/s \cite{Thorsten2007}. Outro
estudo cita que é comum medir 100 Mb/s como largura de banda entre zonas de
disponibilidade \cite{Pujol2012}.

\paragraph{Quantidade e características dos enlaces de WAN:} 1. Um único enlace
significa que o estudo usou dois centros de dados. Esse valor simplificou a
análise e a modificação do algoritmo de particionamento do Riak (ver
Seção~\ref{sec:sistema_de_armazenamento}).

\paragraph{Taxa de chegada de requisições}15 operações/s para cada thread de
cada instância do \emph{benchmark}. Esse valor foi usado pois esse parâmetro se
relaciona diretamente com a quantidade de threads por instância do
\emph{benchmark}. Assim, considerando que threads por instância foi inicialmente
considerado um fator, a taxa de chegada foi fixada.

Vale notar que a LAN nos experimentos era definida pela infraestrutura do
Grid5000 usada, mas a WAN foi emulada (ver Seção~\ref{sec:rede}). Dessa forma,
os parâmetros da LAN estavam limitados pela infraestrutura do estudo, enquanto
os da WAN foram usados como configuração do emulador.

%% ------------------------------------------------------------------------- %%
\section{Seleção dos Fatores} \label{sec:selecao_dos_fatores}

% Tabelas: \cellcolor[gray]{c} % c=0.9: 20-50, c=0.7: 51-80, c=0.5: 81-100

Os parâmetros que não foram fixados consequentemente eram candidatos a fatores
nos experimentos finais. Como a lista precisava ser reduzida pois ainda era
grande, experimentos fatoriais 2\textsuperscript{k} foram realizados. Dada a
meta do estudo, fatores de rede e de carga de trabalho foram priorizados,
portanto havia intenção de desconsiderar os fatores de sistema desde o início.
Mesmo assim, estudos fatoriais foram feitos para eles por dois motivos.
Primeiro, para verificar quais fatores eram mais influentes e portanto
representavam ameaças à validade se desconsiderados. Depois, para ter mais
informações sobre os valores a serem usados para eles.

Os fatores de sistema eram:

\begin{itemize}

\item Quantidade de nós do sistema

\item Quantidade de instâncias do \emph{benchmark}

\item Quantidade de threads por instância do \emph{benchmark}

\item Quantidade dos objetos armazenados

\item Tamanho dos objetos armazenados.

\end{itemize}

Os fatores de rede eram:

\begin{itemize}

\item Modelo de consistência

\item Latência da WAN

\item Variação da latência da WAN

\item Taxa de perda de pacotes na WAN

\item Taxa de duplicação de pacotes na WAN

\item Taxa de reordenação de pacotes na WAN

\item Variação de TCP

\end{itemize}

Os fatores de carga de trabalho eram:

\begin{itemize}

\item Relação leitura/escrita

\item Popularidade dos objetos

\item Localidade

\end{itemize}

Uma abordagem possível para a seleção final de fatores seria agrupar todos os
fatores levantados em um único projeto de experimentos fatoriais
2\textsuperscript{k}. O problema é que mesmo com apenas dois níveis por fator, a
quantidade final de experimentos seria proibitiva, dado que a quantidade de
fatores era 15.

A opção adotada para lidar com o excesso de fatores foi dividi-los em grupos
menores e realizar experimentos para cada grupo. O principal problema de fazer
essa separação é o fato de a comparação da influência de fatores de grupos
diferentes ser perdida. Por exemplo, localidade e quantidade de nós de sistema
foram tratados em estudos diferentes e cada um apareceu como o fator mais
influente do estudo de que fez parte. Como eles não fizeram parte do mesmo
estudo, a informação de qual deles é o mais influente foi perdida, bem como a
informação sobre a influência da interação entre eles. Se um fosse muito mais
influente do que o outro e a interação entre eles fosse baixa, a decisão de
fixar o menos influente não teria consequências. Mas sem essa informação, fixar
um deles representava ameaça à validade do estudo.

A maioria desses fatores era suscetível a interações com fatores de rede, como o
tamanho dos objetos armazenados, por exemplo. A latência de rede em particular
havia se mostrado muito influente em estudos exploratórios, fato confirmado
posteriormente pelo estudo para fatores de rede. Dado isso, a abordagem adotada
foi usar a latência como um representante da rede nos outros estudos fatoriais.
A partir disso foi possível concluir, por exemplo, que apesar de o tamanho dos
objetos armazenados aparecer como fator influente no estudo fatorial para ele,
desconsiderá-lo no estudo final não era uma ameaça à validade pois a latência
era um fator bem mais influente.

Existem outras situações em que desconsiderar um fator que aparece como
influente não implica necessariamente em ameaça à validade. O método de análise
de variação de um estudo 2\textsuperscript{k} mostra a importância relativa de
cada fator, o que não significa que esses fatores sejam de fato influentes. Por
exemplo, ao testar o desempenho de um software com duas CPUs e dois tamanhos de
memória diferentes (4 experimentos), um estudo fatorial vai indicar a influência
de um ou dos dois fatores mesmo que a maior diferença entre as respostas seja de
0,001\%. Nesse caso, a variação é pouco significativa, mas o estudo fatorial vai
indicar qual a influência relativa de cada fator nesses 0,001\% de variação.
Para tratar esses casos, também foram calculados os coeficientes de
variação\footnote{O coeficiente de variação é a divisão do desvio padrão pela
média e é uma maneira de representar a variabilidade dos dados desconsiderando
sua ordem de grandeza} (CVs) das respostas para estimar qual a influência
daquele conjunto de fatores e interações como um todo. Assim, quando o CV era
baixo (1\%, por exemplo), nenhum dos fatores usados no estudo era influente, já
que nenhuma combinação de fatores e níveis resultou em variação significativa da
resposta.

Os tempos de resposta das requisições remotas dominam a média dos tempos de
resposta pois são ordens de grandeza maiores que os das requisições locais. Por
isso, a análise da maioria dos estudos é feita por percentis em vez de médias --
percentis baixos representam requisições locais e percentis altos representam
requisições remotas. Também é feita a distinção entre escritas e leituras dada a
diferença de natureza dessas operações.

Três fatores receberam um tratamento diferente ao longo do experimento: modelo
de consistência, configuração de replicação (para consistência em momento
indeterminado) e versão requisitada nas leituras (para consistência na linha do
tempo). Isso foi feito pois as combinações entre esses fatores definem
configurações do sistema de armazenamento que resultam em proporções de
requisições locais e remotas diferentes. Assim, esses fatores foram tratados
como um único fator chamado modo, descrito na Subseção~\ref{sec:modo}. Os
fatores localidade e popularidade na consistência na linha do tempo impuseram a
necessidade de uma fase de aquecimento após a carga do sistema, o processo é
explicado na Subseção~\ref{sec:aquecimento}. Projetos de experimentos fatoriais
2\textsuperscript{k} foram realizados para cada um dos fatores restantes e estão
descritos nas subseções subsequentes.

%% ------------------------------------------------------------------------- %%
\subsection{Modo} \label{sec:modo}

Os modos adotados foram:

\begin{itemize}

\item \emph{ind1}: Consistência em momento indeterminado com $W$ = 1 e $R$ = 1

\item \emph{ind2}: Consistência em momento indeterminado com $W$ = 2 e $R$ = 1

\item \emph{lt\_qqer}: Consistência na linha do tempo com leituras de qualquer
versão

\item \emph{lt\_rec}: Consistência na linha do tempo com leituras da versão mais
recente

\end{itemize}

Todas as configurações usam $N = 3$ (ver Seção~\ref{sec:parametros_fixados}). O
algoritmo de particionamento garante que existe ao menos uma réplica em cada
centro de dados (ver Subseção~\ref{sec:sistema_de_armazenamento}). Assim,
existem sempre duas situações possíveis com relação à localização das réplicas
do ponto de vista do coordenador: uma local e duas remotas ou duas locais e uma
remota. Dado isso, o modo \emph{ind1} resulta em todas as leituras e escritas
locais. O modo \emph{ind2} resulta em todas as leituras locais e metade das
escritas locais e a outra metade remotas. O modo \emph{lt\_qqer} resulta em
todas as leituras locais e a quantidade de escritas dependente da localidade dos
acessos. Finalmente, o modo \emph{lt\_rec} resulta tanto em leituras quanto
escritas dependentes da localidade.

Os modos foram escolhidos de forma a representar situações encontradas em
sistemas de produção e ao mesmo tempo limitar a quantidade de níveis. Assim,
consistência na linha do tempo com leituras de versões específicas não foi
considerada já que ela é um meio termo entre leituras de ``versão mais recente'' e
leituras de ``qualquer versão''. Consistência em momento indeterminado com $W = 1$ e
$R = 2$ não foi considerada pois sua semântica é similar a $W = 2$ e $R = 1$,
mas teria seu desempenho prejudicado considerando que leituras predominam nas
relações leitura/escrita usadas nos experimentos (ver Subseção
\ref{sec:fatores_de_carga_de_trabalho}).

Esses modos implicam em trocas além de desempenho e consistência. A principal é
durabilidade, que para \emph{ind2} é mais alta do que para os outros casos, em
que a confirmação de escrita de uma única réplica é suficiente.

%% ------------------------------------------------------------------------- %%
\subsection{Aquecimento} \label{sec:aquecimento}

Como localidade era um fator, apenas a inserção de objetos na etapa de carga
(Seção~\ref{sec:execucao_e_analise_dos_experimentos}) não era suficiente para
que o sistema operasse no seu estado estacionário durante os experimentos para a
consistência na linha do tempo. Isso porque ao final da carga, cada objeto no
banco de dados tinha recebido apenas um acesso de cada centro de dados, nenhuma
réplica mestre teria migrado por efeito da localidade até esse momento. Por
isso, o aquecimento era necessário após a carga para a consistência na linha do
tempo. Já a consistência em momento indeterminado não era sujeita à influência
direta de localidade, portanto não precisava de aquecimento.

Uma forma de implementar o aquecimento seria usar a quantidade de atualizações
necessárias para levar o sistema para seu estado estacionário. O problema dessa
abordagem é a quantidade de requisições iria variar com a quantidade de objetos
armazenados. Por isso, o aquecimento foi parametrizado por passos, onde cada
passo correspondia a uma quantidade de atualizações igual a quantidade de
objetos armazenados.

A influência da popularidade também foi considerada pois ela afetava a
probabilidade de um determinado objeto ser acessado. Dado isso, um estudo foi
realizado para saber quantos passos seriam necessários para cada combinação de
localidade e popularidade. O estudo com 20000 objetos executou 30 passos,
medindo a quantidade de migrações ocorridas em cada um deles. Os resultados
desse estudo estão na Figura \ref{fig:aquecimento_do_sistema}.

\begin{figure}[!htb] \centering

\includegraphics[width=0.8\textwidth]{warmup.png}

\caption{Aquecimento do sistema.} \label{fig:aquecimento_do_sistema}
\end{figure}

A quantidade de migrações aumenta nos primeiros passos. Para localidade 50\%, a
quantidade de migrações estabiliza após o 3\textsuperscript{o} passo e a
popularidade não influencia. Já para localidade 90\%, a estabilização demora
cerca de 17 passos e as curvas são diferentes para popularidade apenas nos
primeiros passos. Com isso, a fase de aquecimento nos estudos foi configurada
para usar uma quantidade de passos de acordo com a localidade. Os valores para
quantidade de passos configurados foram:

\begin{itemize}

\item Localidade 50\%: 3

\item Localidade 90\%: 17

\end{itemize}

O aquecimento só levou em consideração a localização das réplicas pois o
mecanismo de armazenamento usado foi memória (ver Seção
\ref{sec:aglomerado_e_mecanismo_de_armazenamento}). Caso fosse disco, essa fase
também seria usada para aquecer o cache de disco.

%% ------------------------------------------------------------------------- %%
\subsection{Fatores de tamanho do sistema e \emph{benchmark}}
\label{sec:fatores_de_tamanho_do_sistema_e_benchmark}

As quantidade de nós de sistema e \emph{benchmark} não só podem influenciar as
respostas, como também afetam questões operacionais, dado que quanto mais nós
são usados, maiores as dificuldades de conseguir reservá-los no Grid5000.
Portanto, um estudo foi feito para definir a influência desses fatores e achar
valores que representassem um compromisso razoável entre tamanho dos
experimentos e as questões operacionais.

Os níveis selecionados para o estudo foram:

\begin{itemize}

\item Quantidade de nós do sistema: 8 e 16

\item Quantidade de instâncias do \emph{benchmark}: 2 e 4

\item Quantidade de threads em cada instância do \emph{benchmark}: 32 e 64

\end{itemize}

A quantidade de partições usadas pelo Riak deve ser uma potência de 2 (ver Seção
\ref{sec:parametros_fixados}). Uma forma de manter a simetria do sistema foi
adotar potências de 2 para os níveis da quantidade de nós do sistema, garantindo
assim a mesma quantidade de partições por nó. Fazer o mesmo para quantidade de
instâncias do \emph{benchmark} e quantidade de threads por instância foi uma
forma de balancear a carga média tanto por nó quanto por partição.

O estudo usou modo \emph{lt\_rec}, localidade de 50\% e latência de rede de 100
ms.  Esses valores foram escolhidos pois por meio deles obtém-se uma quantidade
balanceada de leituras e escritas locais e remotas. O resultado do estudo está
na Tabela \ref{tab:estudo_para_quantidade_de_nos_do_sistema}.

\begin{table}[!h] \begin{center} \begin{tabular}{|c|c|c|c|c|c|c|c|c|} \hline

Operação & Percentil & N & A & T & NA & NT & AT & NAT\\ \hline

leitura & 10 & \cellcolor[gray]{0.9} 30 & 18 & \cellcolor[gray]{0.9} 22 & 10 & 8
& 7 & 4 \\ \hline

leitura & 90 & \cellcolor[gray]{0.7} 65 & 13 & 15 & 3 & 4 & 0 & 0 \\ \hline

escrita & 10 & \cellcolor[gray]{0.5} 96 & 2 & 1 & 0 & 0 & 0 & 0 \\ \hline

escrita & 90 & \cellcolor[gray]{0.7} 65 & 15 & 13 & 3 & 3 & 0 & 0 \\ \hline

\end{tabular} \caption[Estudo para quantidade de nós do sistema.]{Estudo para
quantidade de nós do sistema. N representa a quantidade de nós do sistema, A
representa a quantidade de instâncias do \emph{benchmark} e T representa a
quantidade de threads usadas em cada instância do \emph{benchmark}.}
\label{tab:estudo_para_quantidade_de_nos_do_sistema} \end{center} \end{table}

Na maioria dos casos, o tamanho do sistema tem a maior influência nos resultados
e a quantidade de instâncias do \emph{benchmark} e a quantidade de threads não
são desprezíveis, ainda mais ao se considerar as interações entre elas. Apesar
disso, esses fatores foram desconsiderados devido ao excesso de fatores. Dessa
forma, os valores fixados foram:

\begin{itemize}

\item Quantidade de nós do sistema: 16 (maior valor)

\item Quantidade de instâncias do \emph{benchmark}: 4 (maior valor)

\item Quantidade de threads em cada instância do \emph{benchmark}: 32 (menor
valor)

\end{itemize}

Esses valores foram selecionados pois resultaram em uma configuração ``leve'',
evitando gargalos de rede e não sobrecarregando o sistema. Ao mesmo tempo, a
quantidade total de nós necessária para os experimentos se enquadrava nas
limitações de recursos do aglomerado.

Uma opção semelhante seriam 32 nós do sistema e 8 instâncias do
\emph{benchmark}, resultando em um total de 40 nós. Isso não foi feito por
questões operacionais.  Apesar de o aglomerado ter mais do que 40 nós, é muito
comum alguns poucos nós já estarem reservados por outros pesquisadores, além de
alguns nós apresentarem falhas no momento da implantação da imagem. Esse último
problema levou o autor a sempre reservar alguns nós além dos necessários para
garantir a quantidade mínima de nós para executar os experimentos. Além disso,
alguns limites de uso do Grid5000 são relativos ao tamanho do aglomerado usado.
Por exemplo, uma das regras diz que, entre 9:00 e 19:00, a quantidade de nós
reservados multiplicada pelo período da reserva deve ser menor ou igual a
quantidade total de nós do aglomerado multiplicada por 2 horas. Dessa forma,
experimentos que precisassem de 40 nós seriam mais difíceis de ser executados.

%% ------------------------------------------------------------------------- %%
\subsection{Fatores de banco de dados} \label{sec:fatores_de_banco_de_dados}

Um estudo foi feito para dimensionar o tamanho do banco de dados, que afeta o
uso de memória e de banda. Os experimentos consideraram a latência como fator
para verificar a importância relativa entre esses fatores e a rede.

Os níveis selecionados foram:

\begin{itemize}

\item Quantidade de objetos armazenados: 64000 e 256000

\item Tamanho dos objetos armazenados (bytes): 100 e 10000

\end{itemize}

O estudo usou modo \emph{lt\_rec} e localidade de 50\%. Esses valores foram
escolhidos pois através deles obtém-se uma quantidade balanceada de leituras e
escritas locais e remotas. O resultado do estudo está na Tabela
\ref{tab:estudo_para_quantidade_e_tamanho_dos_objetos_armazenados}.

\begin{table}[!h] \begin{center} \begin{tabular}{|c|c|c|c|c|c|c|c|c|} \hline

Operação & Percentil & Q & T & L & QT & QL & TL & QTL\\ \hline

leitura & 10 & 0 & \cellcolor[gray]{0.5} 100 & 0 & 0 & 0 & 0 & 0 \\ \hline

leitura & 90 & 0 & 0 & \cellcolor[gray]{0.5} 100 & 0 & 0 & 0 & 0 \\ \hline

escrita & 10 & 0 & \cellcolor[gray]{0.5} 100 & 0 & 0 & 0 & 0 & 0 \\ \hline

escrita & 90 & 0 & 0 & \cellcolor[gray]{0.5} 100 & 0 & 0 & 0 & 0 \\ \hline

\end{tabular} \caption[Estudo para quantidade e tamanho dos objetos
armazenados.]{Estudo para quantidade e tamanho dos objetos armazenados. Q
representa a quantidade de objetos armazenados, T representa o tamanho dos
objetos armazenados e L representa a latência.}
\label{tab:estudo_para_quantidade_e_tamanho_dos_objetos_armazenados}.
\end{center} \end{table}

A quantidade de objetos não afeta o desempenho do sistema. O tamanho dos objetos
não afeta o desempenho das requisições remotas. E apesar desse fator aparecer
com 100\% de influência nas requisições locais, o CV dessas requisições indica
que sua influência na prática não é tão grande -- 19\% para leituras e 16\% para
escritas. Além disso, o foco deste trabalho é o comportamento do sistema na WAN,
onde as requisições são duas ordens de grandeza maiores. Assim, os valores
fixados foram:

\begin{itemize}

\item Quantidade de objetos armazenados: 128000

\item Tamanho dos objetos armazenados (bytes): 500

\end{itemize}

Como o tempo de aquecimento depende da quantidade de objetos armazenados, quanto
menor essa quantidade, mais rápida é a execução dos experimentos. Por outro
lado, a opção foi por um número intermediário de forma a evitar um excesso de
conflitos. Já no caso do tamanho dos objetos armazenados, o valor foi escolhido
baseado em estudo dos sistemas de caching distribuído no Facebook, que relata
que 90\% dos objetos nesses sistemas são menores do que 500 bytes
\cite{Atikoglu2012}.

%TODO: comentar conflitos, resultados são estranhos confl : 5 44 44 1 2 5 1   |
%CV =  0.6548619

%% ------------------------------------------------------------------------- %%
\subsection{Fatores de rede} \label{sec:fatores_de_rede}

Dado o objetivo do trabalho, o estudo para fatores de rede era um dos mais
importantes da etapa de seleção de fatores. Mas antes dele, um estudo preliminar
foi feito para verificar as recomendações de otimização para WAN do tamanho dos
\emph{buffers} de transmissão e recepção.

Pelo BDP de um enlace, quanto maior a latência da rede, maior é a quantidade de
pacotes em trânsito. Um gargalo comum em WANs é o tamanho dos \emph{buffers} de
transmissão e recepção das pontas serem menores que o BDP. Recomendações sugerem
a configuração de \emph{buffers} com tamanho em bytes igual ao dobro do BDP
\cite{Jones2006,ESNet2012}. Em princípio essa otimização seria aplicada aos
estudos, mas experimentos com iperf mostraram ganhos de desempenho para
\emph{buffers} de até quatro vezes o BDP, portanto um estudo fatorial foi feito
para verificar esse fato. O estudo usou latência e reordenação de pacotes para
criar cenários que pressionassem os \emph{buffers} de forma diferente.

Os níveis selecionados foram:

\begin{itemize}

\item Proporção entre tamanho dos \emph{buffers} e BDP: 2 e 4

\item Latência da WAN (ms): 100 e 300

\item Taxa de reordenação de pacotes na WAN (\%): 0 e 5

\end{itemize}

O estudo usou modo \emph{lt\_rec} e localidade de 50\%. Esses valores foram
escolhidos pois através deles obtém-se uma quantidade balanceada de leituras e
escritas locais e remotas. Para a rede, a variação de latência foi de 50\%.  A
alta variabilidade ajuda a criar um cenário que pressiona os \emph{buffers} de
transmissão e recepção. O resultado do estudo está na Tabela
\ref{tab:estudo_para_tamanho_dos_buffers_de_transmissao_e_recepcao}.

\begin{table}[!h] \begin{center} \begin{tabular}{|c|c|c|c|c|c|c|c|c|} \hline

Operação & Percentil & L & O & B & LO & LB & OB & LOB\\ \hline

leitura & 10 & \cellcolor[gray]{0.5} 92 & 0 & 3 & 0 & 0 & 2 & 3\\ \hline

leitura & 90 & \cellcolor[gray]{0.5} 98 & 0 & 1 & 0 & 0 & 0 & 0\\ \hline

escrita & 10 & \cellcolor[gray]{0.5} 87 & 11 & 0 & 1 & 1 & 0 & 0\\ \hline

escrita & 90 & \cellcolor[gray]{0.5} 99 & 0 & 0 & 0 & 0 & 0 & 0\\ \hline

\end{tabular} \caption[Estudo para tamanho dos \emph{buffers} de transmissão e
recepção.]{Estudo para tamanho dos \emph{buffers} de transmissão e recepção. L
representa a latência, O representa a taxa de reordenação de pacotes e B
representa o tamanho dos \emph{buffers}.}
\label{tab:estudo_para_tamanho_dos_buffers_de_transmissao_e_recepcao}.

\end{center} \end{table}

Como o tamanho dos \emph{buffers} não afetou o desempenho, a opção foi por
configurá-los seguindo as recomendações, assim o valor fixado foi:

\begin{itemize}

\item Proporção entre tamanho dos \emph{buffers} e BDP: 2

\end{itemize}

Feito isso, o procedimento de otimização da WAN estava finalizado e os
experimentos para rede foram executados. Este estudo usou a mesma configuração
de modo e localidade que o estudo para tamanho de \emph{buffers}, pelo mesmo
motivo. Os níveis inicialmente selecionados para fatores de rede foram:

\begin{itemize}

\item Latência da WAN (ms): 100 e 300 

\item Variação da latência da WAN (\%): 1 e 60

\item Taxa de perda de pacotes na WAN (\%): 0,01 e 0,3

\item Taxa de duplicação de pacotes na WAN (\%): 0,05 e 5

\item Taxa de reordenação de pacotes na WAN (\%): 0,05 e 5

\item Variação de TCP: CUBIC e H-TCP

\end{itemize}

Os níveis da latências foram baseados em estudo que relata as latências entre os
centros de dados dos Amazon Web Services \cite{Sovran2011}. Os centros de dados
considerados são Califórnia (EUA -- Costa Oeste), Virginia (EUA -- Costa Leste),
Irlanda e Singapura. A menor latência observada foi 82 ms entre os centros de
dados dos EUA e a maior foi 277 ms entre Irlanda e Singapura.

O mesmo estudo usado para latência apresenta um gráfico com grandes variações de
latência, chegando a máximos de até 3 ordens de grandeza em alguns períodos
curtos. O projeto PingER\footnote{\emph{Ping End-to-end Reporting} (Relatório de
Ping Fim-a-fim) é um projeto de Stanford que monitora o desempenho fim-a-fim de
enlaces de Internet, em 700 sítios e 160 países.} \cite{Pinger2013}, por sua
vez, mostra em janeiro de 2013 uma média de latência de 238,062 ms com desvio
padrão de 142,996, o que resulta em uma variação de 60\%. Os 11 meses anteriores
apresentam valores semelhantes.

As taxas de perda foram escolhidas com base em medidas feitas pelo projeto
PingER, que mede desempenho de conexões fim-a-fim na Internet. A mediana das
perdas medidas em janeiro de 2013 foi 0,119\% e a mediana do último ano foi
0,178\%. O mesmo relatório mostra perdas bem mais altas em medições específicas,
mas este trabalho considerou que a WAN entre os dois centros de dados é de boa
qualidade, portanto não apresentaria taxas de perda muito altas.

O mesmo estudo mostra taxas de duplicação de pacotes muitos baixas (0\%). Embora
os valores usados neste estudo tenham sido muito grandes, duplicação de pacotes
não influenciou a resposta (ver abaixo).

Duas referências sobre reordenação de pacotes foram encontradas. A primeira, o
projeto PingER, mostra taxas muito baixas -- em janeiro de 2013, média de
0,006\% e mediana de 0\%. Estudo realizado em 2003 entre sítios na China mostra
taxas de reordenação de pacotes de 3,187\% \cite{Wang2004}. Os valores usados no
experimento foram maiores, mas mesmo assim reordenação de pacotes não
influenciou a resposta (ver abaixo).

Tanto H-TCP \cite{Leith2004} quanto CUBIC \cite{Ha2008} foram projetados com
foco em redes com largura de banda e latências grandes (BDP alto). Ambos já
estavam disponíveis no Linux usado nos experimentos, sendo que TCP CUBIC é o
padrão do kernel do Linux a partir da versão 2.6.19. Eles foram escolhidos pois
são citados nas referências sobre otimizações da pilha TCP para WANs
\cite{Jones2006,ESNet2012}.

Além das configurações de cada fator, o emulador de rede tinha outras duas
configurações fixas. O parâmetro largura de banda da WAN foi configurado com 100
Mb/s (ver Subseção~\ref{sec:parametros_restantes}). A variação da latência foi
configurada para obedecer uma distribuição normal, criando assim uma relação
entre o valor de latência da cada pacote e o anterior e evitando grandes
variações aleatórias de latência.

O resultado do estudo está na Tabela \ref{tab:estudo_para_fatores_de_rede}. Com
exceção dos fatores e da interação entre latência e variação de latência, todas
as outras colunas apresentavam valores nulos e foram suprimidas. As respostas
das requisições locais apresentaram CVs de 1\%, portanto as respectivas linhas
também foram suprimidas.

\begin{table}[!h] \begin{center} \begin{tabular}{|c|c|c|c|c|c|c|c|c|} \hline

Operação & Percentil & L & V & P & D & O & C & LV\\ \hline

leitura & 90 & \cellcolor[gray]{0.7} 72 & \cellcolor[gray]{0.9} 21 & 1 & 0 & 0 &
0 & 6\\ \hline

escrita & 90 & \cellcolor[gray]{0.7} 69 & \cellcolor[gray]{0.9} 23 & 1 & 0 & 0 &
0 & 6\\ \hline

\end{tabular}

\caption[Estudo para fatores de rede.]{Estudo para fatores de rede. L representa
a latência, V representa a variação da latência, P representa as taxa de perdas,
D representa a taxa de pacotes duplicados, O representa a taxa de pacotes fora
de ordem e C representa o algoritmo de congestionamento. A soma para escritas
não é 100\% devido a arredondamento.} \label{tab:estudo_para_fatores_de_rede}

\end{center} \end{table}

% Factors: delay delay_var loss dupl reorder congest 

% get - p10 : 54 1 1 7 1 2 14 0 6 1 0 0 4 1 0 0 0 0 0 0 0 0 5 1 0 0 0 0 0 0 0 0
% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0   | CV =
% 0.007921385 

% get - p90 : 77 18 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0   | CV =
% 0.5825256 

% upd - p10 : 67 3 0 6 0 2 7 0 4 1 0 0 3 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0
% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0   | CV =
% 0.006834625 

% upd - p90 : 70 24 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
% 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0   | CV =
% 0.6184648 

%requisições remotas: CVs 58\% (leituras) e 62\% (escritas)

A latência, a variação de latência e a interação de primeira ordem entre elas
respondem por 100\% dos resultados. Assim, os níveis escolhidos para esses
fatores nos experimentos foram:

\begin{itemize} \item Latência da WAN (ms): 0, 100, 200 e 300

\item Variação da latência da WAN (\%): 0 e 50

\end{itemize}

Níveis nulos de latência e variação da latência equivalem a ter todo o sistema
operando em uma rede local. Os resultados obtidos para esses casos foram usados
como auxílio na interpretação dos resultados, mas não foram considerados na
análise final dado que sistemas georeplicados, por definição, não operam nessas
condições.

Os valores fixados dos fatores desconsiderados foram:

\begin{itemize}

\item Taxa de perda de pacotes na WAN (\%): 0 

\item Taxa de duplicação de pacotes na WAN (\%): 0

\item Taxa de reordenação de pacotes na WAN (\%): 0

\item Algoritmo de congestionamento: CUBIC

\end{itemize}

Taxas de perda, duplicação e reordenação  de pacotes foram ignoradas no estudo
final. O algoritmo de congestionamento foi fixado como CUBIC, pois esse é o
padrão no sistema Linux utilizado nos experimentos.

Apesar da taxa de reordenação de pacotes ser fixada, a ocorrência de alguns
pacotes fora de ordem é possível dada a variação da latência. Por exemplo, com
uma latência de 100 ms e uma variação de 50\%, é possível que o emulador aplique
atrasos de 120ms para um pacote e 80 ms para um outro no mesmo milissegundo, o
que faz com que o segundo pacote seja transmitido antes do primeiro. Mas a
ocorrência de grandes diferenças de latência entre pacotes consecutivos é rara,
dado que o emulador foi configurado para aplicar uma correlação na variação da
latência usando distribuição normal.

Um comentário final é que o mesmo estudo havia sido realizado anteriormente com
níveis de perda de pacotes 0,01\% e 1\%. Nesse estudo, a perda de pacotes era
mais influente até do que a variação da latência. Mas como redes normalmente não
apresentam taxas de perda de pacotes tão altas quanto 1\%, o estudo foi refeito
com nível máximo de 0,1\% e a perda de pacotes não afetou o resultado nesse
caso.

%% ------------------------------------------------------------------------- %%
\subsection{Fatores de carga de trabalho}
\label{sec:fatores_de_carga_de_trabalho}

Juntamente com o estudo para fatores de rede, o estudo para fatores de carga de
trabalho era um dos mais importantes, dado o objetivo deste trabalho. Os
experimentos também consideraram a latência como fator para verificar a
importância relativa entre os fatores de carga de trabalho e a rede.

A partir disso, os níveis selecionados para carga de trabalho foram:

\begin{itemize}

\item Relação leitura/escrita: 2:1 e 10:1

\item Popularidade dos objetos: uniforme (a taxa de chegada de requisições média
para cada objeto é a mesma) e concentrada (a taxa de chegada segue uma
distribuição Pareto)

\item Localidade (\%): 50 e 90

\end{itemize}

A relação leitura/escrita 2:1 representa uma carga balanceada entre os dois
tipos de operações e a 10:1 representa uma carga intensiva de leituras. A
consistência na linha do tempo pode tornar um sistema sob cargas com um maior
número de escritas inviável pois as escritas se tornam indisponíveis em caso de
falha. Assim, este estudo considera situações em que ela é competitiva quando
comparada com a consistência em momento indeterminado, por isso as relações
leitura/escrita usadas resultavam em mais leituras que escritas. Além disso, ao
atualizar um objeto na consistência em momento indeterminado, é necessário o
envio do relógio-vetor, por isso uma leitura\footnote{É possível fazer
atualizações sem relógio-vetor, mas isso cria versões concorrentes do mesmo
objeto.} é realizada pelo \emph{benchmark} antes de toda atualização. Isso
restringe a quantidade de escritas a um máximo de 50\% da carga de trabalho.

A popularidade dos objetos uniforme representa uma taxa de chegada de
requisições média igual entre os objetos e concentrada representa uma taxa de
chegada que segue uma distribuição Pareto.

Os níveis de localidade foram escolhidos de forma a ter situações sem influência
de localidade (50\%) e com localidade alta (90\%). O valor de localidade alta é
baseado no relatado em estudo feito pelo Yahoo! em seus sistemas de produção
\cite{Cooper2008}.

Como os modos possuem comportamentos diferentes para requisições locais e
remotas, os experimentos foram executados para cada modo. O resultado para
requisições locais apresentaram CVs em torno de 0,02 para todos os modos. Isso
indica que requisições locais não sofrem influência de nenhum dos fatores. Já
requisições remotas apresentaram CVs de aproximadamente 50\% e influência da
latência de 100\% para \emph{ind2}, \emph{lt\_qqer} e \emph{lt\_rec}
(\emph{ind1} não tem requisições remotas).

A análise da relação leitura/escrita e localidade não usou percentis, mas sim a
média do tempo de resposta de todas as requisições (leituras e escritas). Isso
porque o primeiro fator diz respeito à composição entre leituras e escritas e o
segundo à composição entre requisições locais e remotas, portanto esses fatores
não fazem sentido nos percentis separados por tipo de requisição. Por exemplo,
com localidade 50\% percebe-se que o percentil 70 representa requisições
remotas, enquanto com localidade 90\% o mesmo percentil representa requisições
locais. Se a análise fosse feita por percentis, essa informação se perderia e
localidade nunca teria influência. O resultado do estudo está na Tabela
\ref{tab:estudo_para_fatores_de_carga_de_trabalho}

\begin{table}[!h] \begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|} \hline

Modo & R & X & P & L & RX & RP & RL & XP & XL & PL & RXP & RXL & RPL & XPL &
RXPL\\ \hline

\emph{ind1} & 19 & 12 & 2 & 31 & 0 & 3 & 2 & 4 & 6 & 6 & 4 & 0 & 0 & 8 & 1\\
\hline

\emph{ind2} & 50 & 0 & 0 & 39 & 0 & 0 & 11 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
\hline

\emph{lt\_qqer} & 25 & 30 & 0 & 19 & 9 & 0 & 6 & 0 & 8 & 0 & 0 & 3 & 0 & 0 & 0\\
\hline

\emph{lt\_rec} & 0 & 53 & 0 & 34 & 0 & 0 & 0 & 0 & 13 & 0 & 0 & 0 & 0 & 0 & 0\\
\hline

\end{tabular} \caption[Estudo para fatores de carga de trabalho.]{Estudo para
fatores de carga de trabalho. R representa a relação leitura/escrita, X
representa a localidade, P representa a popularidade e L representa a latência
de rede.} \label{tab:estudo_para_fatores_de_carga_de_trabalho}.  \end{center}
\end{table}

Como esperado, localidade e latência influenciam as respostas em geral. Uma
observação é o fato de inclusive \emph{ind1} ser afetada por latência. Isso
provavelmente é resultado dos mecanismos de replicação e correção de leituras
serem afetados pela latência.

O impacto de popularidade dos objetos é praticamente nulo. Talvez em uma
situação em que o sistema recebesse uma carga maior, como no caso de um teste de
sobrecarga, esse fator passasse a ser influente. Como não é o caso, ele foi
desconsiderado e fixado no valor que simplifica o entendimento dos resultados.
Em trabalhos futuros, experimentos podem ser realizados com o sistema sob carga
mais alta para verificar se a influência de popularidade aumenta.

Apesar de alguns modos aparentemente sofrerem impacto considerável da relação
leitura/escrita, esse impacto é consequência da relação entre requisições locais
e remotas. Para \emph{ind1}, tanto leituras quanto escritas são locais e a
relação leitura/escrita e suas interações com outros fatores impacta pouco esse
modo.  Para \emph{lt\_rec}, leituras e escritas são locais ou remotas dependendo
da localidade e a relação leitura/escrita não impacta esse modo. Para
\emph{ind2}, todas as leituras são locais e metade das escritas é remota,
portanto quando a relação leitura/escrita muda, a relação entre requisições
locais e remotas muda proporcionalmente -- como esperado, esse modo é impactado
pela relação leitura/escrita. A mesma observação vale para \emph{lt\_qqer}, que
tem todas as leituras locais e escritas dependendo da localidade, e também sofre
impacto da relação leitura/escrita.

Caso o mecanismo de armazenamento fosse disco ao invés de memória, a relação
leitura/escrita provavelmente sofreria impacto de fato. Isso porque escritas
seriam afetadas pelo tempo de escrita no disco, enquanto leituras poderiam ser
mais rápidas pois parte delas seriam servidas a partir do cache de disco.  Mas
como não é esse o caso, a diferença relevante é a relação entre requisições
locais e remotas.

Dessa forma, só foram escolhidos níveis para localidade:

\begin{itemize}

\item Localidade (\%): 50 e 90

\end{itemize}

Os valores fixados dos fatores desconsiderados foram:

\begin{itemize}

\item Relação leitura/escrita: 2:1

\item Popularidade dos objetos: uniforme

\end{itemize}

O valor da relação leitura/escrita é um balanço razoável entre leituras e
escritas. O valor de popularidade é o mais simples para a interpretação dos
resultados.

%% ------------------------------------------------------------------------- %%
\section{Fatores selecionados} \label{sec:fatores_selecionados}

Os fatores selecionados nos estudos 2\textsuperscript{k} compuseram o estudo
final e são apresentados junto com seus níveis na
Tabela~\ref{tab:fatores_e_niveis_do_estudo_final}.

\begin{table}[!h] \begin{center} \begin{tabular}{|l|c|c|} \hline

\multicolumn{1}{|c|}{Fator} & \multicolumn{1}{|c|}{Níveis} &
\multicolumn{1}{|c|}{Total de níveis}\\ \hline

Modo & \emph{ind1}, \emph{ind2}, \emph{lt\_qqer} e \emph{lt\_rec} & 4\\ \hline

Latência da WAN (ms) & 0, 100, 200 e 300 & 4\\ \hline

Variação da latência da WAN (\%) & 0 e 60 & 2\\ \hline

Localidade & 0,5 e 0,9 & 2\\ \hline

\end{tabular}

\caption{Fatores e níveis do estudo final.}
\label{tab:fatores_e_niveis_do_estudo_final}

\end{center} \end{table}

Esse número de fatores e níveis resultou em um total de 64 experimentos.
