%% ------------------------------------------------------------------------- %%
\chapter{Método e Aspectos Técnicos} \label{cap:metodo_e_aspectos_tecnicos}

As atividades envolvidas neste estudo se dividiram em três etapas. A primeira,
descrita neste capítulo, contemplou a definição do estudo propriamente dita e
dos aspectos técnicos de implementação dos experimentos. A segunda etapa teve
por objetivo definir quais características do sistema, do ambiente e da carga de
trabalho seriam consideradas e quais seriam desconsideradas no estudo e está
descrita no capítulo \ref{cap:parametros_e_fatores}. A terceira etapa
compreendeu a execução dos experimentos seguida da análise dos resultados e se
encontra no capítulo \ref{cap:analise_dos_resultados}.

As definições das metas, métricas e técnica de avaliação do estudo se encontram
na seção \ref{sec:definicao_do_estudo}. As descrições do sistema de
armazenamento e do benchmark usados, bem como do ambiente em que operaram nos
experimentos, se encontram na seção \ref{sec:aspectos_tecnicos}.

%% ------------------------------------------------------------------------- %%
\section{Definição do Estudo} \label{sec:definicao_do_estudo}

Um estudo experimental começa pela definição de metas e procedimentos a serem
usados. O método usado neste trabalho se baseia na abordagem proposta por Jain
\cite{Jain1991}. Apesar das seleções de parâmetros e fatores fazerem parte da
definição do estudo, esses passos estão descritos em um capítulo à parte
(capítulo \ref{cap:parametros_e_fatores}) dadas suas complexidade e importância.

A subseção \ref{sec:nomenclatura} define termos usados ao longo deste trabalho.
A subseção \ref{sec:metas_do_estudo} descreve as metas e o contexto do estudo. A
subseção \ref{sec:metricas} define quais os critérios usados na avaliação de
desempenho. A seguir, a subseção \ref{sec:tecnica_de_avaliacao} apresenta a
técnica escolhida para o estudo. Por último, a subseção
\ref{sec:trabalhos_relacionados} lista outros trabalhos com foco semelhante a
este.
 
%% ------------------------------------------------------------------------- %%
\subsection{Nomenclatura} \label{sec:nomenclatura}

A literatura sobre experimentos apresenta alguns termos importantes para a
comunicação de objetivos, procedimentos e resultados. Termos usados
frequentemente neste e nos próximos capítulos são:

\begin{itemize} \item Variáveis de resposta: Resultados de um experimento
(variáveis dependentes). Como este estudo é uma análise de desempenho, as
variáveis de resposta são as métricas, que são os critérios usados em uma
comparação de desempenho.

\item Parâmetros: Características do sistema, do ambiente de operação e da carga
de trabalho que afetam o desempenho do sistema.

\item Fatores: Parâmetros que são variados nos experimentos (variáveis
independentes) e cujo efeito no desempenho é analisado. Parâmetros que não são
fatores possuem um único valor em todos os experimentos (variáveis fixas e
constantes).

\item Níveis: Valores assumidos pelos fatores nos experimentos.

\item Interação entre fatores: Se o desempenho sempre varia da mesma forma ao se
alterar o nível de um determinado fator, não há interação entre esse e os demais
fatores. Mas se o desempenho varia de formas diferentes dependendo do nível de
outro(s) fator(es), existe interação entre eles.

\item Ordem de uma interação entre fatores: A quantidade de fatores envolvidos
na interação -- por exemplo, uma interação de terceira ordem é uma interação
entre três fatores.

\item Projeto dos experimentos: Especificação do número de experimentos e das
combinações de fatores e níveis usados.

\end{itemize}

%% ------------------------------------------------------------------------- %%
\subsection{Metas do estudo} \label{sec:metas_do_estudo}

A meta deste estudo foi comparar o desempenho de um sistema de armazenamento
geo-replicado usando consistência em momento indeterminado e consistência na
linha do tempo. A hipótese era que um sistema usando consistência na linha do
tempo apresenta desempenho igual ou superior a um usando consistência em momento
indeterminado para cargas de trabalho específicas, apesar de ser um modelo
baseado em cópia primária.

O modelo usado nos experimentos foi um único sistema distribuído entre centros
de dados ligados por uma WAN. Nesse cenário, uma requisição local é aquela
atendida no mesmo centro de dados em que chega e possui baixo tempo de resposta
(da ordem de poucos milissegundos). Já uma requisição remota é aquela que chega
em um determinado centro de dados e é encaminhada para ser atendida em outro, e
normalmente possui tempo de resposta alto (da ordem de dezenas ou centenas de
milissegundos). O modelo usado neste estudo possibilitou diferentes combinações
entre requisições locais e remotas dependendo do modelo de consistência usado e
da sua configuração (ver subseção \ref{sec:modo}).

Por limitações de escopo e recurso, este estudo analisa o sistema apenas do
ponto de vista do desempenho. Isso significa que o estudo não considera outros
atributos de qualidade como disponibilidade e manutenibilidade. Assim, o escopo
está limitado à operação normal do sistema, não levando em consideração
condições excepcionais, como falha de nós ou sobrecarga do sistema. Essas e
outras condições podem ser estudadas em trabalho futuros (seção
\ref{sec:trabalhos_futuros}).

%% ------------------------------------------------------------------------- %%
\subsection{Métricas} \label{sec:metricas}

A principal métrica é o tempo de resposta das requisições (em s). Quanto menor o
tempo de resposta, melhor é o desempenho de um modelo de consistência. Como
requisições locais e remotas apresentam tempos de resposta bem diferentes,
percentis são usados em vez da média na maior parte das análises.

Além do tempo de resposta, outras métricas observadas foram vazão (em
operações/s), quantidade de migrações e quantidade de conflitos (ambas dadas
pela porcentagem com relação ao total de operações do experimento). Vazão não é
considerada uma meta principal pois o benchmark usa uma taxa de requisições
fixada ao invés de usar a máxima possível, de forma a diminuir possíveis
influências de sobrecarga do sistema. A quantidade de migrações, exclusiva da
consistência na linha do tempo, oferece uma visão da dinâmica de um sistema que
use esse modelo de consistência. A quantidade de conflitos proporciona uma noção
da frequência com que cliente leem valores desatualizados. Uma diferença entre
conflitos nos dois modelos é que na consistência na linha do tempo eles são
causados apenas por atualizações que ainda não chegaram a todas as réplicas,
portanto serão automaticamente resolvidos em algum momento no futuro. Já na
consistência em momento indeterminado eles podem ser mais graves, dado que esse
modelo permite atualizações concorrentes divergentes.

%% ------------------------------------------------------------------------- %%
\subsection{Técnica de avaliação} \label{sec:tecnica_de_avaliacao}

Existem três técnicas comumente usadas na análise de desempenho de sistemas:
simulação, modelagem analítica e medição \cite{Jain1991}. Dada a complexidade
dos sistemas considerados neste estudo e do ambiente em que operam, é difícil
criar simuladores ou modelos que considerem muitos dos parâmetros que afetem seu
desempenho. Para serem viáveis nesse contexto, essas técnicas fazem uso de
diversas simplificações que afetam a precisão dos resultados do estudo. Por
outro lado, as principais dificuldades para o uso de medição são a necessidade
de um sistema pronto para ser usado, o tempo disponível para o estudo e as
ferramentas disponíveis. No caso deste estudo, nenhum dos três representava
empecilho, portanto medição foi escolhida como técnica para este estudo.

Dada a técnica de avaliação selecionada, este estudo precisava de um sistema
implementado para que as medições fossem feitas. Mas considerando que o objetivo
era comparar dois modelos de consistência e não sistemas que os implementassem,
os experimentos foram planejados e executados de forma a isolar tanto quanto
possível questões específicas do sistema. Além disso, era importante testar os
modelos em diferentes condições da rede, portanto os experimentos usaram uma WAN
emulada. Os nós do sistema foram agrupados como se estivessem em centros de
dados diferentes, ligados pela WAN emulada. A carga de trabalho foi executada
por um benchmark que simulava clientes localizados em cada um dos centros de
dados. Cada experimento era definido por um modelo de consistência e sua
configuração, uma configuração de rede (latência, perda de pacotes, etc) e uma
carga de trabalho (relação leitura/escrita, localidade, etc). Detalhes sobre o
sistema e o benchmark usados e o ambiente em que eles operaram nos experimentos
estão na seção \ref{sec:aspectos_tecnicos}.

%% ------------------------------------------------------------------------- %%
\subsection{Trabalhos relacionados} \label{sec:trabalhos_relacionados}

Uma abordagem comum na literatura de sistemas distribuídos é a proposta de um
novo conceito e a implementação de um sistema que use esse conceito seguida de
uma análise de seu desempenho. Tanto o artigo sobre o Dynamo \cite{DeCandia2007}
quanto o sobre o PNUTS \cite{Cooper2008} apresentam análises de desempenho,
sendo que apenas o segundo faz uma análise baseada na carga de trabalho. Existe
uma segunda publicação com experimentos com o PNUTS que analisa o consumo de
banda de diferentes políticas de replicação em uma WAN \cite{Kadambi2011}.

Existem muitos trabalhos que apresentam análises de desempenho de sistemas de
armazenamento que usam replicação sobre WANs. Na maior parte dos casos o
objetivo desses sistemas é provar outros conceitos além da eficiência do modelo
de consistência escolhido por eles. O COPS usa consistência causal+ e implementa
transações \cite{Lloyd2011}. O Scatter propõe uma arquitetura ao mesmo tempo
escalável e com consistência forte \cite{Glendenning2011}. O Zeno usa
consistência em momento indeterminado e é tolerante a falhas bizantinas
\cite{Singh2009}. O Windows Azure provê um sistema de armazenamento na nuvem com
consistência forte \cite{Calder2011}. O Megastore usa Paxos para implementar
consistência forte \cite{Baker2011}. Nenhum desses trabalhos apresenta
comparações com outros sistemas ou com outros modelos de consistência. Como eles
não usam uma aplicação para execução de testes ou ambiente comum, é difícil
fazer qualquer comparação a partir desses trabalhos.

Beyer et al. realizaram testes para analisar a relação entre as diferentes
configurações de consistência no Cassandra e sua disponibilidade e desempenho
\cite{Beyer2011}. Como esperado, eles notam que configurações que oferecem
consistência mais rígida apresentam pior desempenho.  Renesse e Schneider
apresentam resultados experimentais comparando desempenho e disponibilidade de
replicação mestre-escravo e replicação em cadeia, cada uma delas usando
consistência forte e consistência em momento indeterminado
\cite{VanRenesse2004}. Nenhum desses dois experimentos leva em consideração
operação sobre WAN nem diferentes cargas de trabalho. Yu e Vahdat realizaram uma
análise sobre a relação entre disponibilidade e níveis de consistência em
sistemas replicados em WANs \cite{Yu2001}. Eles comparam a disponibilidade de um
sistema usando consistência forte e consistência contínua, usando diferentes
protocolos de consistência como cópia primária e votação, por exemplo. Esse
trabalho não testa consistência em momento indeterminado nem consistência na
linha do tempo e não observa o desempenho dos modelos de consistência
analisados.

Uma publicação com uma proposta mais próxima da deste trabalho é a comparação
feita entre Cassandra, HBase, PNUTS e MySQL particionado horizontalmente usando
diferentes cargas de trabalho \cite{Cooper2010}. Os resultados servem como uma
comparação entre esses sistemas, mas dizem menos sobre seus modelos de
consistência, dado que os sistemas apresentam arquiteturas e configurações
diferentes. Além disso, os testes são feitos em uma rede local, não em uma WAN.

%% ------------------------------------------------------------------------- %%
\section{Aspectos Técnicos} \label{sec:aspectos_tecnicos}

Uma vez que medição foi escolhida como técnica de avaliação de desempenho para o
estudo, o passo seguinte era o planejamento técnico dos experimentos. Esse
planejamento envolveu predominantemente atividades de programação e
administração de sistemas, como implementação da consistência na linha do tempo
e preparação de scripts para a execução dos experimentos.

O sistema de armazenamento usado como objeto de estudo nos experimentos é
descrito na subseção \ref{sec:sistema_de_armazenamento}. A carga sobre o sistema
é definida pelo benchmark, descrito na subseção \ref{sec:benchmark}. O ambiente
dos experimentos é definido pela plataforma escolhida para executá-los, descrita
na subseção \ref{sec:ambiente}. A forma como a WAN é emulada é descrita na
subseção \ref{sec:rede}. A estrutura para execução e análise dos experimentos é
descrita na subseção \ref{sec:execucao_e_analise_dos_experimentos}.

%% ------------------------------------------------------------------------- %%
\subsection{Sistema de armazenamento} \label{sec:sistema_de_armazenamento}

Uma abordagem para a comparação dos dois modelos de consistência seria o uso de
um sistema de armazenamento já existente que implementasse ambos, mas tal
sistema não foi encontrado. A partir disso, uma outra abordagem seria o uso de
sistemas diferentes, cada um implementando um modelo de consistência. Apesar de
existirem experimentos que usam essa abordagem
\cite{Cooper2008,Stonebraker2007,Pavlo2009}, dois problemas foram identificados.
O primeiro é que o desempenho de cada sistema é afetado por parâmetros
particulares do sistema que não o modelo de consistência, como a tecnologia
utilizada, detalhes de configuração, entre outros. No caso de uso de mais de um
sistema, esses fatores, pouco importantes para este estudo, precisariam ser
levados em conta. O segundo problema é que apesar de existirem sistemas de
armazenamento de software livre / código aberto que implementam consistência em
momento indeterminado, não foram encontrados sistemas que implementassem
consistência na linha do tempo.

Assim, decidiu-se usar um único sistema para os experimentos. Uma opção para tal
era implementar um sistema de armazenamento distribuído específico para os
experimentos. O problema dessa abordagem é que esse tipo de sistema é bastante
complexo, já que precisa prover funcionalidades como controle de entrada e saída
dos nós no aglomerado, algoritmos de particionamento, etc. Desenvolver todas
essas funcionalidades inviabilizaria este trabalho devido ao alto custo em tempo
para implementação.

Para evitar a implementação completa de um sistema de armazenamento, algumas
opções de software livre / código aberto foram analisadas. A seleção das opções
foi feita considerando modelos de consistência, estabilidade da solução e
simplicidade de desenvolvimento. Como não foram encontrados sistemas de
armazenamento de software livre / código aberto que implementem consistência na
linha do tempo, as soluções avaliadas foram aquelas que implementam consistência
em momento indeterminado. Os sistemas encontrados foram Dynomite
\cite{Dynomite}, Cassandra \cite{Lakshman2010}, Voldemort \cite{Voldemort} e
Riak \cite{Riak}. Todos eles usam basicamente a mesma arquitetura do Dynamo,
provendo gerenciamento de entrada e saída de nós no aglomerado, relógios vetor
para identificação e resolução de conflitos entre diferentes réplicas dos
objetos \cite{Lamport1978} e espalhamento consistente para o particionamento dos
objetos \cite{Karger1997a}.

O Dynomite foi descartado pois o projeto foi abandonado pela comunidade em um
estado ainda instável. O Cassandra por outro lado possui estabilidade e uma
comunidade bastante ativa, mas é mais complexo que os outros sistemas dado que
também implementa características de SGBDs orientados a colunas
\cite{Chang2006}. Dos dois sistemas restantes, o Riak foi escolhido por ser
implementado em Erlang, linguagem focada no desenvolvimento de sistemas
distribuídos, apresentando assim maior facilidade para o desenvolvimento do
modelo de consistência na linha do tempo. Um indício dessa facilidade é que o
riak\_kv, o módulo do Riak usado na implementação do novo modelo de
consistência, apresenta aproximadamente 20 mil linhas de código contra
aproximadamente 85 mil do Voldemort. Além disso, existe um benchmark para o Riak
bastante completo (ver subseção \ref{sec:benchmark}). O Voldemort também possui
benchmark semelhante, mas ele oferece menos opções de configuração.

%% ------------------------------------------------------------------------- %%
\subsubsection{Implementação da consistência na linha do tempo no Riak}

A implementação da consistência na linha do tempo é incompleta e está toda no
módulo riak\_kv. Para os experimentos, a distinção entre leituras e escritas era
importante. Mas a distinção entre os tipos de escrita (inserção, atualização ou
remoção) não era tão importante dado que eles se comportam basicamente da mesma
forma do ponto de vista de tráfego de rede local versus remoto. Assim, apenas
atualizações foram implementadas de forma completa e eficiente, distinguindo a
localização de cada nó com relação aos centros de dados. As inserções para uma
dada chave ocorrem sempre pela mesma réplica, mesmo que isso signifique
encaminhar para outro centro de dados uma requisição que em princípio poderia
ser tratada localmente. Esse procedimento eliminou a necessidade de
implementação de um mecanismo para evitar conflitos de inserção. Apesar de
inserções serem ineficientes, isso não afetou os resultados, dado que os
experimentos usam inserção apenas na carga do sistema (ver o fluxo de trabalho
na subseção \ref{sec:execucao_e_analise_dos_experimentos}). Remoções não foram
implementadas.

O PNUTS conta com uma heurística que explora a localidade de requisições,
simples mas importante para o desempenho da consistência na linha do tempo: a
réplica mestre migra para o centro de dados de onde vieram as últimas escritas.
Essa heurística foi implementada no Riak para este estudo.

A implementação da consistência na linha do tempo foi baseada na da consistência
em momento indeterminado já disponível no Riak. Durante a implementação houve a
preocupação de manter o código das duas o mais próximo possível de forma a
eliminar diferenças dos tempos de execução dos dois modelos.

%% ------------------------------------------------------------------------- %%
\subsubsection{Outras modificações implementadas no Riak}

Além do riak\_kv, outro módulo alterado foi o riak\_core, responsável pelo
roteamento de requisições em um aglomerado de Riak. Quando o Riak recebe uma
requisição, ele define qual o nó responsável por tratá-la através do algoritmo
de espalhamento consistente, que se baseia no valor da chave do objeto. O Riak
foi projetado para ser implantado em um único centro de dados\footnote{A versão
Enterprise do Riak implementa replicação entre centros de dados, mas é paga.},
portanto o algoritmo não leva em consideração os centros de dados no momento de
decidir para qual das réplicas a requisição deve seguir. Dessa forma, algumas
modificações foram necessárias no riak\_core para que ele priorizasse nós do
mesmo centro de dados em que a requisição chegou. Além disso, modificações foram
feitas para garantir que existisse ao menos uma réplica de cada objeto em cada
centro de dados. A implementação é muito simples e pouco versátil, funcionando
apenas para o cenário do estudo, de apenas dois centros de dados (ver seção
\ref{sec:parametros_fixados}) e baseada nos nomes dos nós para saber em qual
centro de dados cada um deles se encontra.

Outras alterações menores foram o tratamento de parâmetros extras na interface
HTTP, necessários para a consistência na linha do tempo, e a implementação de
estatísticas de migrações.


%% ------------------------------------------------------------------------- %%
\subsection{Benchmark} \label{sec:benchmark}

% artigos que usam o termo benchmark, em itálico
% http://sbrc2012.dcc.ufmg.br/app/pdfs/p-05/wcga/WCGA-ST3-2.pdf
% http://www2.dbd.puc-rio.br/pergamum/tesesabertas/0521501_10_cap_04.pdf

O benchmark usado foi o Basho Bench \cite{Basho}, específico para o Riak. Ele
provê configurações para quantidade de clientes concorrentes (threads), relação
leitura/escrita, popularidade dos objetos acessados, entre outras. O benchmark
originalmente não é distribuído, portanto foi modificado pois mais de uma
instância dele precisava ser executada simultaneamente nos experimentos. Além de
evitar gargalos no benchmark, isso era importante para a implementação de
localidade. Além disso, foi necessária a implementação de um script para a
consolidação dos dados obtidos pelas diversas instâncias do Basho Bench.

Outro benchmark considerado foi o YCSB \cite{Cooper2010}.  Apesar de possuir
mais flexibilidade que o Basho Bench nas suas configurações, ele não estava
preparado para acessar o Riak, acesso esse que precisaria ser implementado. Além
disso, ele também não oferecia muitas das funcionalidades necessárias para os
experimentos, que precisariam ser implementadas.

%% ------------------------------------------------------------------------- %%
\subsection{Ambiente} \label{sec:ambiente}

Os experimentos foram executados no
Grid5000\footnote{\url{http://www.grid5000.fr/}}, uma plataforma para criação,
execução e monitoramento de experimentos de sistemas paralelos e distribuídos. A
plataforma possui mais de 5000 cores distribuídos em 9 sítios na França e um no
Brasil.

Outras plataformas como o OpenCirrus\footnote{\url{http://opencirrus.org/}} e
PlanetLab\footnote{\url{http://www.planet-lab.org/}} também foram consideradas,
mas foram descartadas por uma questão de conveniência, já que o autor deste
trabalho utilizou o Grid5000 em dois estágios de mestrado de respectivamente
quatro meses e um mês pelo INRIA na França. A experiência no ambiente adquirida
nesse período foi reutilizada neste trabalho, tornando o projeto e a execução
dos experimentos mais produtivos. O Amazon Web Services (AWS)
\footnote{\url{http://aws.amazon.com/}} também foi considerado, mas foi
descartado por se tratar de ambiente virtualizado, o que dificultaria a análise
dos resultados e a reprodutibilidade dos experimentos.

A operação no Grid5000 se dá através do acesso ssh ao frontend de cada sítio.
Nele o usuário encontra seu diretório home, onde ele armazena seus scripts e
dados dos experimentos, e tem acesso a ferramentas específicas da
infraestrutura. Como o Grid5000 é compartilhado por diversos pesquisadores, ele
oferece um conjunto de ferramentas (OAR\footnote{\url{http://oar.imag.fr/}}) e
regras para que um pesquisador reserve nós exclusivamente para ele por um
determinado período de tempo. Além dos nós, é possível reservar IPs para compor
sub-redes, recurso utilizado nos experimentos (ver subseção \ref{sec:rede}).
Outra ferramenta bastante utilizada é o
kadeploy\footnote{\url{http://kadeploy.imag.fr/}}, responsável pela implantação
de imagens nos nós reservados pelo usuário.

%% ------------------------------------------------------------------------- %%
\subsubsection{Imagem}

A imagem usada nos experimentos é um Debian GNU/Linux 6.0 (Squeeze) com kernel
2.6.32-5-amd64 baseado em uma imagem pré-configurada disponibilizada pelo
Grid5000 (squeeze-x64-base). Além do conteúdo da imagem base, a imagem usada nos
experimentos possui o Riak e o Basho Bench modificados e algumas ferramentas de
monitoração e análise de desempenho como
sysstat\footnote{\url{http://sebastien.godard.pagesperso-orange.fr/}},
bwm-ng\footnote{\url{http://www.gropp.org/?id=projects&sub=bwm-ng}} e
iperf\footnote{\url{http://iperf.sourceforge.net/}}. Uma única imagem foi usada,
a distinção entre nós executando instâncias do Riak ou do Basho Bench foi feita
através dos scripts que gerenciam os experimentos (subseção
\ref{sec:execucao_e_analise_dos_experimentos}).

%% ------------------------------------------------------------------------- %%
\subsection{Rede} \label{sec:rede}

Os sítios do Grid5000 são conectados por redes de alta velocidade. Suas redes
apresentam latências da ordem de centenas de nanosegundos entre nós de um mesmo
aglomerado e da ordem de 20 ms entre sítios, e portanto não caracterizam uma
WAN. De qualquer forma, mesmo que caracterizassem, ter controle sobre esses
valores era necessário para medir o desempenho do sistema em diferentes
condições de rede e possibilitar a reprodutibilidade dos experimentos.

Por isso, os experimentos emulam uma WAN pelo uso da ferramenta traffic control
(tc). Ela é usada na manipulação das filas de saída de pacotes de uma interface
de rede em sistemas Linux, priorizando um determinado tipo de tráfego, por
exemplo. Mais especificamente para emulação da WAN, o
netem\footnote{\url{http://www.linuxfoundation.org/collaborate/workgroups/networking/}}
foi usado. Ele provê funcionalidade para inserção de latência de rede, variação
da latência, perda de pacotes, pacotes duplicados, corrompidos e/ou fora de
ordem.  Existem outras ferramentas como o
dummynet\footnote{\url{http://info.iet.unipi.it/~luigi/dummynet/}} e o
NISTNet\footnote{\url{http://snad.ncsl.nist.gov/itg/nistnet/}}, mas elas foram
desconsideradas dado que o netem já vem integrado ao tc e satisfazia os
requisitos funcionais dos experimentos.

Existem recomendações sobre otimizações de sistemas Linux para quando esses se
comunicam através de WANs. Durante os experimentos, sempre que os parâmetros da
WAN foram alterados, um script para ajuste da pilha TCP foi usado (para mais
detalhes, ver seção \ref{sec:fatores_de_rede}).

%% ------------------------------------------------------------------------- %%
\subsubsection{Centros de dados}

Os experimentos foram planejados para usar dois centros de dados simulados (ver
seção \ref{sec:parametros_fixados}). Para simular os centros de dados, os nós
que compunham o sistema eram divididos em dois conjuntos CD1 e CD2, cada um
representando um centro de dados. Além dos nós, duas sub-redes SR1 e SR2 eram
reservadas. Cada nó de CD1 recebia, além de seu IP da rede do Grid5000, um IP de
SR1, o mesmo valendo para CD2 e SR2.

Sistemas Linux usam o arquivo /etc/hosts como fonte primária para resolução de
nomes, consultando um DNS apenas quando não encontram um nome definido ali (o
que é a situação mais comum). Todos os nós no Grid5000 possuem um nome
registrado no DNS que aponta para o seu IP da rede do Grid5000. Nos
experimentos, dois arquivos hosts1 e hosts2 eram criados e substituíam o
/etc/hosts dos nós de CD1 e CD2 respectivamente. O conteúdo de hosts1 eram os
nomes dos nós de CD2 sendo resolvidos para os IPs de SR2, o mesmo valendo parae
hosts2, CD1 e SR1. Com isso, os nós de CD1 resolviam os nomes dos nós de CD2
para os IPs de SR2 e vice-versa. O resultado dessa configuração é que todas as
requisições que saíam de um centro de dados para o outro usavam o IP da sub-rede
de destino, enquanto as requisições para o mesmo centro de dados usavam o IP da
rede do Grid5000.

A partir dessa configuração foi possível adicionar um filtro baseado em
sub-redes ao tc de modo que as características de WAN eram aplicadas às
requisições que saíam para o outro centro de dados, enquanto as requisições para
o mesmo centro de dados saíam inalteradas.

%TODO: dummynet: Marta Carbone and Luigi Rizzo, Dummynet Revisited, ACM SIGCOMM
%Computer Communication Review, 40(2) pg.12-20, March 2010

%% ------------------------------------------------------------------------- %%
\subsection{Execução e análise dos experimentos}
\label{sec:execucao_e_analise_dos_experimentos}

A automatização dos experimentos foi feita em dois conjuntos de scripts. O
primeiro (cmb) foi usado para gerenciamento e execução dos experimentos --
reserva de nós, implantação da imagem, gerenciamento do sistema de
armazenamento, configuração e execução do benchmark e coleta dos resultados. Os
scripts se localizavam no frontend do Grid5000 e foram escritos em bash.  Esses
scripts definem o fluxo de trabalho do estudo, descrito a seguir.  O segundo
conjunto (cmb-local) foi usado na análise dos dados, se localizava no computador
do autor e era composto por scripts em bash, Ruby e R.

%% ------------------------------------------------------------------------- %%
\subsubsection{Fluxo de trabalho dos experimentos}

A execução de um estudo compreendia diversas etapas, um script correspondendo a
cada uma delas. O fluxo de trabalho propriamente dito também estava definido em
um script, que invocava os outros, e é apresentado na Figura
\ref{fig:fluxo_de_trabalho_da_execucao_do_estudo}. Cada etapa presente no
fluxograma está descrita a seguir com o nome do script responsável entre
parênteses.

\begin{figure}[!htb] \centering

\begin{tikzpicture}[node distance = 2cm, auto]
    % Place nodes
    \node [block] (reserve) {Reserva dos nós};

    \node [block, right of=reserve, node distance=8em] (deploy) {Implantação da
imagem nos nós};

    \node [block, below of=deploy] (srvs) {Configuração dos nós};

    \node [block, below of=srvs] (riak) {Configuração do Riak};

    \node [block, below of=riak] (start) {Inicialização do Riak};

    \node [block, below of=start] (load) {Carga e aquecimento do sistema};

    \node [block, below of=load] (wan) {Configuração da WAN emulada};

    \node [block, below of=wan, node distance=10em] (run) {Execução de um
experimento};

    \node [decision, right of=run, node distance=10em] (loop) {Último
experimento?};
    
    \node [decision, above of=loop, node distance=10em] (reconf) {Consistência
ou localidade mudaram?};

    \node [block, right of=loop, node distance=10em] (stop1) {Término do Riak};

    \node [block, right of=riak, node distance=10em] (stop2) {Término do Riak};

    \node [block, right of=stop1, node distance=8em] (end) {Fim};

    % Draw edges
    \path [line] (reserve) -- (deploy);

    \path [line] (deploy) -- (srvs);

    \path [line] (srvs) -- (riak);

    \path [line] (riak) -- (start);

    \path [line] (start) -- (load);

    \path [line] (load) -- (wan);

    \path [line] (wan) -- (run);

    \path [line] (run) -- (loop);

    \path [line] (loop) -- node [near start] {não} (reconf);

    \path [line] (loop) -- node [near start] {sim}(stop1);

    \path [line] (reconf) -- node [near start] {não} (wan);

    \path [line] (reconf) -- node [near start] {sim}(stop2);

    \path [line] (stop2) -- (riak);

    \path [line] (stop1) -- (end);

\end{tikzpicture}

\caption{Fluxo de trabalho da execução do estudo.}
\label{fig:fluxo_de_trabalho_da_execucao_do_estudo} \end{figure}

\paragraph{Reserva dos nós (reserve)}Nessa etapa, escolhe-se o aglomerado, a
quantidade de nós, o período da reserva e o instante em que ela ocorrerá (pode
ser imediatamente ou em algum momento futuro). O script basicamente é uma forma
mais simples de executar o oarsub, ferramenta de reserva de nós do Grid5000. O
Grid5000 disponibiliza uma aplicação web em que é possível ver as reservas de
nós atuais em cada aglomerado.

\paragraph{Implantação da imagem nos nós (deploy)}Essa etapa usa a lista de nós
definida na reserva e lida com situações em que os nós não foram corretamente
implantados, algo relativamente comum. Se não fosse esse tratamento, o script
seria apenas uma forma mais simples de usar o kadeploy, ferramenta para
implantação de imagens do Grid5000.

\paragraph{Configuração dos nós (srvs)}Essa etapa consiste em separar os nós
reservados entre nós de Riak e instâncias do benchmark, a partir das quantidades
de cada um definidas para o estudo. Nesse momento, os nós de Riak também são
dividos entre os centros de dados a serem usados e os IPs das sub-redes são
alocados (script net).

\paragraph{Configuração do Riak (riak)}Essa etapa consiste no envio dos arquivos
de configuração do Riak para cada nó. Nesse momento ocorre a configuração do
modelo de consistência a ser usado em um dado experimento.

\paragraph{Inicialização do Riak (start)}Essa etapa corresponde à inicialização
das instâncias de Riak em cada nó e à entrada de cada uma no aglomerado de
Riaks.

\paragraph{Carga e aquecimento do sistema (load)}Essa etapa consiste em popular o banco de
dados do Riak antes dos experimentos. Para a consistência na linha do tempo,
a fase de aquecimento do sistema é necessária (detalhes na subseção \ref{sec:aquecimento}).

\paragraph{Configuração da WAN emulada}Nessa etapa as interfaces de rede dos nós
são configuradas com latência de rede, perda de pacotes, etc. Além disso, as
otimizações para WAN são aplicadas (script tune-tcp).

\paragraph{Execução de um experimento}Essa etapa começa pela aquisição de
informações do sistema, como as condições de memória e disco dos nós e latência
da LAN. Após isso, a execução do benchmark propriamente dita ocorre. Por fim,
arquivos com os resultados dos experimentos, logs e arquivos de configuração são
salvos para serem usados na análise dos resultados depois.

\paragraph{Término do Riak}Essa etapa é responsável por encerrar o Riak.
